{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack, save_npz, load_npz\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-22 03:41:25--  http://deepyeti.ucsd.edu/jianmo/amazon/sample/meta_All_Beauty.json.gz\n",
      "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
      "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2022-07-22 03:41:25 ERROR 404: Not Found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://deepyeti.ucsd.edu/jianmo/amazon/sample/meta_All_Beauty.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32892\n",
      "{'category': [], 'tech1': '', 'description': [\"Loud 'N Clear Personal Sound Amplifier allows you to turn up the volume on what people around you are saying, listen at the level you want without disturbing others, hear a pin drop from across the room.\"], 'fit': '', 'title': \"Loud 'N Clear&trade; Personal Sound Amplifier\", 'also_buy': [], 'tech2': '', 'brand': 'idea village', 'feature': [], 'rank': '2,938,573 in Beauty & Personal Care (', 'also_view': [], 'details': {'ASIN: ': '6546546450'}, 'main_cat': 'All Beauty', 'similar_item': '', 'date': '', 'price': '', 'asin': '6546546450', 'imageURL': [], 'imageURLHighRes': []}\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with gzip.open('meta_All_Beauty.json.gz') as f:\n",
    "    for l in f:\n",
    "        data.append(json.loads(l.strip()))\n",
    "    \n",
    "# total length of list, this number equals total number of products\n",
    "print(len(data))\n",
    "\n",
    "# first row of the list\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32892\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "32892\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df3 = df.fillna('')\n",
    "df4 = df3[df3.title.str.contains('getTime')] # unformatted rows\n",
    "df5 = df3[~df3.title.str.contains('getTime')] # filter those unformatted rows\n",
    "print(len(df4))\n",
    "print(len(df5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>tech1</th>\n",
       "      <th>description</th>\n",
       "      <th>fit</th>\n",
       "      <th>title</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>tech2</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>rank</th>\n",
       "      <th>also_view</th>\n",
       "      <th>details</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>similar_item</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>asin</th>\n",
       "      <th>imageURL</th>\n",
       "      <th>imageURLHighRes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[Loud 'N Clear Personal Sound Amplifier allows...</td>\n",
       "      <td></td>\n",
       "      <td>Loud 'N Clear&amp;trade; Personal Sound Amplifier</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>idea village</td>\n",
       "      <td>[]</td>\n",
       "      <td>2,938,573 in Beauty &amp; Personal Care (</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'ASIN: ': '6546546450'}</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6546546450</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[No7 Lift &amp; Luminate Triple Action Serum 50ml ...</td>\n",
       "      <td></td>\n",
       "      <td>No7 Lift &amp;amp; Luminate Triple Action Serum 50...</td>\n",
       "      <td>[B01E7LCSL6, B008X5RVME]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>872,854 in Beauty &amp; Personal Care (</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'Shipping Weight:': '0.3 ounces (', 'ASIN: ':...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>class=\"a-bordered a-horizontal-stripes  a-spa...</td>\n",
       "      <td></td>\n",
       "      <td>$44.99</td>\n",
       "      <td>7178680776</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[No7 Stay Perfect Foundation now stays perfect...</td>\n",
       "      <td></td>\n",
       "      <td>No7 Stay Perfect Foundation Cool Vanilla by No7</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>No7</td>\n",
       "      <td>[]</td>\n",
       "      <td>956,696 in Beauty &amp; Personal Care (</td>\n",
       "      <td>[B01B8BR0O8, B01B8BR0NO, B014MHXXM8]</td>\n",
       "      <td>{'Shipping Weight:': '3.5 ounces (', 'ASIN: ':...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>$28.76</td>\n",
       "      <td>7250468162</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Wella Koleston Perfect Hair Colour 44/44 Mediu...</td>\n",
       "      <td>[B0041PBXX8]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1,870,258 in Beauty &amp; Personal Care (</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'\n",
       "    Item Weight: \n",
       "    ': '1.76 ounces', 'Sh...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7367905066</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[Lacto Calamine Skin Balance Daily Nourishing ...</td>\n",
       "      <td></td>\n",
       "      <td>Lacto Calamine Skin Balance Oil control 120 ml...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Pirmal Healthcare</td>\n",
       "      <td>[]</td>\n",
       "      <td>67,701 in Beauty &amp; Personal Care (</td>\n",
       "      <td>[3254895630, B007VL1D9S, B00EH9A0RI, B0773MBG4...</td>\n",
       "      <td>{'Shipping Weight:': '12 ounces (', 'ASIN: ': ...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>$12.15</td>\n",
       "      <td>7414204790</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category tech1                                        description fit  \\\n",
       "0       []        [Loud 'N Clear Personal Sound Amplifier allows...       \n",
       "1       []        [No7 Lift & Luminate Triple Action Serum 50ml ...       \n",
       "2       []        [No7 Stay Perfect Foundation now stays perfect...       \n",
       "3       []                                                       []       \n",
       "4       []        [Lacto Calamine Skin Balance Daily Nourishing ...       \n",
       "\n",
       "                                               title  \\\n",
       "0      Loud 'N Clear&trade; Personal Sound Amplifier   \n",
       "1  No7 Lift &amp; Luminate Triple Action Serum 50...   \n",
       "2    No7 Stay Perfect Foundation Cool Vanilla by No7   \n",
       "3  Wella Koleston Perfect Hair Colour 44/44 Mediu...   \n",
       "4  Lacto Calamine Skin Balance Oil control 120 ml...   \n",
       "\n",
       "                   also_buy tech2              brand feature  \\\n",
       "0                        []             idea village      []   \n",
       "1  [B01E7LCSL6, B008X5RVME]                               []   \n",
       "2                        []                      No7      []   \n",
       "3              [B0041PBXX8]                               []   \n",
       "4                        []        Pirmal Healthcare      []   \n",
       "\n",
       "                                    rank  \\\n",
       "0  2,938,573 in Beauty & Personal Care (   \n",
       "1    872,854 in Beauty & Personal Care (   \n",
       "2    956,696 in Beauty & Personal Care (   \n",
       "3  1,870,258 in Beauty & Personal Care (   \n",
       "4     67,701 in Beauty & Personal Care (   \n",
       "\n",
       "                                           also_view  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2               [B01B8BR0O8, B01B8BR0NO, B014MHXXM8]   \n",
       "3                                                 []   \n",
       "4  [3254895630, B007VL1D9S, B00EH9A0RI, B0773MBG4...   \n",
       "\n",
       "                                             details    main_cat  \\\n",
       "0                           {'ASIN: ': '6546546450'}  All Beauty   \n",
       "1  {'Shipping Weight:': '0.3 ounces (', 'ASIN: ':...  All Beauty   \n",
       "2  {'Shipping Weight:': '3.5 ounces (', 'ASIN: ':...  All Beauty   \n",
       "3  {'\n",
       "    Item Weight: \n",
       "    ': '1.76 ounces', 'Sh...  All Beauty   \n",
       "4  {'Shipping Weight:': '12 ounces (', 'ASIN: ': ...  All Beauty   \n",
       "\n",
       "                                        similar_item date   price        asin  \\\n",
       "0                                                                  6546546450   \n",
       "1   class=\"a-bordered a-horizontal-stripes  a-spa...       $44.99  7178680776   \n",
       "2                                                          $28.76  7250468162   \n",
       "3                                                                  7367905066   \n",
       "4                                                          $12.15  7414204790   \n",
       "\n",
       "                                            imageURL  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  [https://images-na.ssl-images-amazon.com/image...   \n",
       "4  [https://images-na.ssl-images-amazon.com/image...   \n",
       "\n",
       "                                     imageURLHighRes  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3  [https://images-na.ssl-images-amazon.com/image...  \n",
       "4  [https://images-na.ssl-images-amazon.com/image...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how those unformatted rows look like\n",
    "df5.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget http://deepyeti.ucsd.edu/jianmo/amazon/sample/All_Beauty.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'All_Beauty.json.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11220/1843170705.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'All_Beauty.json.gz'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mdata2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"write\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'All_Beauty.json.gz'"
     ]
    }
   ],
   "source": [
    "data2 = []\n",
    "with gzip.open('All_Beauty.json.gz') as f:\n",
    "    for l in f:\n",
    "        data2.append(json.loads(l.strip()))\n",
    "    \n",
    "# total length of list, this number equals total number of products\n",
    "print(len(data2))\n",
    "\n",
    "# first row of the list\n",
    "print(data2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings_beauty3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A39HTATAQ9V7YF</td>\n",
       "      <td>205616461</td>\n",
       "      <td>5</td>\n",
       "      <td>1369699200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3JM6GV9MNOF9X</td>\n",
       "      <td>558925278</td>\n",
       "      <td>3</td>\n",
       "      <td>1355443200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1Z513UWSAAO0F</td>\n",
       "      <td>558925278</td>\n",
       "      <td>5</td>\n",
       "      <td>1404691200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1WMRR494NWEWV</td>\n",
       "      <td>733001998</td>\n",
       "      <td>4</td>\n",
       "      <td>1382572800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3IAAVS479H7M7</td>\n",
       "      <td>737104473</td>\n",
       "      <td>1</td>\n",
       "      <td>1274227200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UserId  ProductId  Rating   Timestamp\n",
       "0  A39HTATAQ9V7YF  205616461       5  1369699200\n",
       "1  A3JM6GV9MNOF9X  558925278       3  1355443200\n",
       "2  A1Z513UWSAAO0F  558925278       5  1404691200\n",
       "3  A1WMRR494NWEWV  733001998       4  1382572800\n",
       "4  A3IAAVS479H7M7  737104473       1  1274227200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>238228.000000</td>\n",
       "      <td>2.382280e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.181053</td>\n",
       "      <td>1.333672e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.322361</td>\n",
       "      <td>7.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.087552e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.305396e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.360454e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.384646e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.406074e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rating     Timestamp\n",
       "count  238228.000000  2.382280e+05\n",
       "mean        4.181053  1.333672e+09\n",
       "std         1.322361  7.117489e+07\n",
       "min         1.000000  9.087552e+08\n",
       "25%         4.000000  1.305396e+09\n",
       "50%         5.000000  1.360454e+09\n",
       "75%         5.000000  1.384646e+09\n",
       "max         5.000000  1.406074e+09"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserId       0\n",
       "ProductId    0\n",
       "Rating       0\n",
       "Timestamp    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f5b29ec3410>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of the rating\n",
    "with sns.axes_style('white'):\n",
    "    g = sns.catplot(\"Rating\", data=ratings, aspect=2.0,kind='count')\n",
    "    g.set_ylabels(\"Total number of ratings\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based collaborative filtering system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ProductId</th>\n",
       "      <th>1304139212</th>\n",
       "      <th>1304139220</th>\n",
       "      <th>130414089X</th>\n",
       "      <th>130414643X</th>\n",
       "      <th>1304146537</th>\n",
       "      <th>130414674X</th>\n",
       "      <th>1304168522</th>\n",
       "      <th>1304174778</th>\n",
       "      <th>1304174867</th>\n",
       "      <th>1304174905</th>\n",
       "      <th>...</th>\n",
       "      <th>B000052YPE</th>\n",
       "      <th>B000052YPF</th>\n",
       "      <th>B000052YPG</th>\n",
       "      <th>B000052YPH</th>\n",
       "      <th>B000052YPM</th>\n",
       "      <th>B000052YPU</th>\n",
       "      <th>B000052YPV</th>\n",
       "      <th>B000052YPY</th>\n",
       "      <th>B000052YQ0</th>\n",
       "      <th>B000052YQ2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A00205921JHJK5X9LNP42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A024581134CV80ZBLIZTZ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A03056581JJIOL5FSKJY7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A03099101ZRK4K607JVHH</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0505229A7NSH3FRXRR4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 886 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ProductId              1304139212  1304139220  130414089X  130414643X  \\\n",
       "UserId                                                                  \n",
       "A00205921JHJK5X9LNP42           0           0           0           0   \n",
       "A024581134CV80ZBLIZTZ           0           0           0           0   \n",
       "A03056581JJIOL5FSKJY7           0           0           0           0   \n",
       "A03099101ZRK4K607JVHH           0           0           0           0   \n",
       "A0505229A7NSH3FRXRR4            0           0           0           0   \n",
       "\n",
       "ProductId              1304146537  130414674X  1304168522  1304174778  \\\n",
       "UserId                                                                  \n",
       "A00205921JHJK5X9LNP42           0           0           0           0   \n",
       "A024581134CV80ZBLIZTZ           0           0           0           0   \n",
       "A03056581JJIOL5FSKJY7           0           0           0           0   \n",
       "A03099101ZRK4K607JVHH           0           0           0           0   \n",
       "A0505229A7NSH3FRXRR4            0           0           0           0   \n",
       "\n",
       "ProductId              1304174867  1304174905  ...  B000052YPE  B000052YPF  \\\n",
       "UserId                                         ...                           \n",
       "A00205921JHJK5X9LNP42           0           0  ...           0           0   \n",
       "A024581134CV80ZBLIZTZ           0           0  ...           0           0   \n",
       "A03056581JJIOL5FSKJY7           0           0  ...           0           0   \n",
       "A03099101ZRK4K607JVHH           0           0  ...           0           0   \n",
       "A0505229A7NSH3FRXRR4            0           0  ...           0           0   \n",
       "\n",
       "ProductId              B000052YPG  B000052YPH  B000052YPM  B000052YPU  \\\n",
       "UserId                                                                  \n",
       "A00205921JHJK5X9LNP42           0           0           0           0   \n",
       "A024581134CV80ZBLIZTZ           0           0           0           0   \n",
       "A03056581JJIOL5FSKJY7           0           0           0           0   \n",
       "A03099101ZRK4K607JVHH           0           0           0           0   \n",
       "A0505229A7NSH3FRXRR4            0           0           0           0   \n",
       "\n",
       "ProductId              B000052YPV  B000052YPY  B000052YQ0  B000052YQ2  \n",
       "UserId                                                                 \n",
       "A00205921JHJK5X9LNP42           0           0           0           0  \n",
       "A024581134CV80ZBLIZTZ           0           0           0           0  \n",
       "A03056581JJIOL5FSKJY7           0           0           0           0  \n",
       "A03099101ZRK4K607JVHH           0           0           0           0  \n",
       "A0505229A7NSH3FRXRR4            0           0           0           0  \n",
       "\n",
       "[5 rows x 886 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=ratings.head(10000)\n",
    "matrix = df.pivot_table(values='Rating', index='UserId', columns='ProductId', fill_value=0)\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9697, 886)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>UserId</th>\n",
       "      <th>A00205921JHJK5X9LNP42</th>\n",
       "      <th>A024581134CV80ZBLIZTZ</th>\n",
       "      <th>A03056581JJIOL5FSKJY7</th>\n",
       "      <th>A03099101ZRK4K607JVHH</th>\n",
       "      <th>A0505229A7NSH3FRXRR4</th>\n",
       "      <th>A05492663T95KW63BR75K</th>\n",
       "      <th>A059547920Q3LZVFHLPI3</th>\n",
       "      <th>A07410232KYRFR25CIUGJ</th>\n",
       "      <th>A082796624UNM47DSAI6K</th>\n",
       "      <th>A0864963DOAY7LXGS5I6</th>\n",
       "      <th>...</th>\n",
       "      <th>AZW1HXXYAC15B</th>\n",
       "      <th>AZWRTJPN7NXT</th>\n",
       "      <th>AZWTXHXZXFAYP</th>\n",
       "      <th>AZYQEFB9Y5N22</th>\n",
       "      <th>AZZHB6U54UDYW</th>\n",
       "      <th>AZZHJZP4GQPPZ</th>\n",
       "      <th>AZZNK89PXD006</th>\n",
       "      <th>AZZOFVMQC0BJG</th>\n",
       "      <th>AZZQXL8VDCFTV</th>\n",
       "      <th>AZZTJQ7CQZUD8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProductId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1304139212</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304139220</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130414089X</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130414643X</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304146537</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9697 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "UserId      A00205921JHJK5X9LNP42  A024581134CV80ZBLIZTZ  \\\n",
       "ProductId                                                  \n",
       "1304139212                      0                      0   \n",
       "1304139220                      0                      0   \n",
       "130414089X                      0                      0   \n",
       "130414643X                      0                      0   \n",
       "1304146537                      0                      0   \n",
       "\n",
       "UserId      A03056581JJIOL5FSKJY7  A03099101ZRK4K607JVHH  \\\n",
       "ProductId                                                  \n",
       "1304139212                      0                      0   \n",
       "1304139220                      0                      0   \n",
       "130414089X                      0                      0   \n",
       "130414643X                      0                      0   \n",
       "1304146537                      0                      0   \n",
       "\n",
       "UserId      A0505229A7NSH3FRXRR4  A05492663T95KW63BR75K  \\\n",
       "ProductId                                                 \n",
       "1304139212                     0                      0   \n",
       "1304139220                     0                      0   \n",
       "130414089X                     0                      0   \n",
       "130414643X                     0                      0   \n",
       "1304146537                     0                      0   \n",
       "\n",
       "UserId      A059547920Q3LZVFHLPI3  A07410232KYRFR25CIUGJ  \\\n",
       "ProductId                                                  \n",
       "1304139212                      0                      0   \n",
       "1304139220                      0                      0   \n",
       "130414089X                      0                      0   \n",
       "130414643X                      0                      0   \n",
       "1304146537                      0                      0   \n",
       "\n",
       "UserId      A082796624UNM47DSAI6K  A0864963DOAY7LXGS5I6  ...  AZW1HXXYAC15B  \\\n",
       "ProductId                                                ...                  \n",
       "1304139212                      0                     0  ...              0   \n",
       "1304139220                      0                     0  ...              0   \n",
       "130414089X                      0                     0  ...              0   \n",
       "130414643X                      0                     0  ...              0   \n",
       "1304146537                      0                     0  ...              0   \n",
       "\n",
       "UserId      AZWRTJPN7NXT  AZWTXHXZXFAYP  AZYQEFB9Y5N22  AZZHB6U54UDYW  \\\n",
       "ProductId                                                               \n",
       "1304139212             0              0              0              0   \n",
       "1304139220             0              0              0              0   \n",
       "130414089X             0              0              0              0   \n",
       "130414643X             0              0              0              0   \n",
       "1304146537             0              0              0              0   \n",
       "\n",
       "UserId      AZZHJZP4GQPPZ  AZZNK89PXD006  AZZOFVMQC0BJG  AZZQXL8VDCFTV  \\\n",
       "ProductId                                                                \n",
       "1304139212              0              0              0              0   \n",
       "1304139220              0              0              0              0   \n",
       "130414089X              0              0              0              0   \n",
       "130414643X              0              0              0              0   \n",
       "1304146537              0              0              0              0   \n",
       "\n",
       "UserId      AZZTJQ7CQZUD8  \n",
       "ProductId                  \n",
       "1304139212              0  \n",
       "1304139220              0  \n",
       "130414089X              0  \n",
       "130414643X              0  \n",
       "1304146537              0  \n",
       "\n",
       "[5 rows x 9697 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = matrix.T\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(886, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "SVD = TruncatedSVD(n_components=10)\n",
    "decomposed_matrix = SVD.fit_transform(X)\n",
    "decomposed_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(886, 886)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation Matrix\n",
    "\n",
    "correlation_matrix = np.corrcoef(decomposed_matrix)\n",
    "correlation_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9790773161'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.index[311]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = \"9790773161\"\n",
    "\n",
    "product_names = list(X.index)\n",
    "product_ID = product_names.index(i)\n",
    "product_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(886,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_product_ID = correlation_matrix[product_ID]\n",
    "correlation_product_ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9788072208',\n",
       " '9788077927',\n",
       " '9790770839',\n",
       " '9790770898',\n",
       " '9790774443',\n",
       " '9790779399',\n",
       " '9790789831',\n",
       " 'B00000JGVY',\n",
       " 'B00004TZYD']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recommend = list(X.index[correlation_product_ID > 0.90])\n",
    "\n",
    "# Removes the item already bought by the customer\n",
    "Recommend.remove(i) \n",
    "\n",
    "Recommend[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity Based System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This recommendation system would be ideal for new customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11220/1358811489.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnewdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ProductId\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ratings' is not defined"
     ]
    }
   ],
   "source": [
    "newdf=ratings.groupby(\"ProductId\").filter(lambda x:x['Rating'].count() >=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_perproduct = newdf.groupby(by='ProductId')['Rating'].count().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductId\n",
       "9790790961    4.271429\n",
       "9790799829    2.640000\n",
       "B00004TMFE    3.445255\n",
       "B00004TUBL    4.634409\n",
       "B00004TUBV    4.269006\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.groupby('ProductId')['Rating'].mean().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='ProductId'>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAFCCAYAAAAdVQ0pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABFG0lEQVR4nO2dedhcRZX/P98skLCFLQRIkICCELYAERAQZZOICKggwYU4w4gKCIzOaFBxYcTB+TGOosAMKhJUlogoAUXACCIaCAECCYGQQFgCCGFTcGEJ5/fHqU5uOv12V/e9efO+9Pk8Tz99u+6t03XvrXtu1alTp2RmBEEQBN3BgFVdgCAIgqD3CKUfBEHQRYTSD4Ig6CJC6QdBEHQRofSDIAi6iEGrugCt2HDDDW306NGruhhBEAT9ittvv/1pMxten97nlf7o0aOZOXPmqi5GEARBv0LSw43Sw7wTBEHQRYTSD4Ig6CJC6QdBEHQRfd6mHwRBUOSVV15h0aJF/OMf/1jVRekTDBkyhFGjRjF48OCs40PpB0HQr1i0aBFrr702o0ePRtKqLs4qxcx45plnWLRoEVtssUVWnjDvBEHQr/jHP/7BBhts0PUKH0ASG2ywQVu9nlD6QRD0O0LhL6PdaxFKPwiCoIsIm34QBP2a0ZN+Wam8h858d8tjBg4cyA477MCrr77KFltswY9+9CPWXXfdHo+fNWsWjz/+OAcffDAAU6dOZe7cuUyaNKmqYmfT75R+qxucc8OCIAjKMHToUGbNmgXAxIkTOeecc/jCF77Q4/GzZs1i5syZS5X+oYceyqGHHtobRV2BMO8EQRCU4K1vfSuPPfYYADNmzGDPPfdk5513Zs8992TevHm8/PLLfOlLX+Kyyy5j7NixXHbZZVx44YWceOKJAHz0ox/lpJNOYs8992TLLbfk8ssvB+C1117j+OOPZ7vttuOQQw7h4IMPXrqvDKH0gyAIOmTJkiVMmzZtaat9m2224aabbuLOO+/k9NNP5/Of/zyrrbYap59+OkcddRSzZs3iqKOOWkHOE088wc0338zVV1+91ORzxRVX8NBDDzF79my+//3vM3369ErK3O/MO0EQBKuav//974wdO5aHHnqIXXfdlQMPPBCAP//5z0ycOJH58+cjiVdeeSVL3uGHH86AAQMYM2YMTz75JAA333wzRx55JAMGDGDjjTdm3333raTs0dIPgiBok5pN/+GHH+bll1/mnHPOAeC0005j3333Zc6cOVx11VXZ/vOrr7760m0zW+67akLpB0EQdMiwYcM4++yzOeuss3jllVf485//zMiRIwG48MILlx639tpr88ILL7Qle++99+ZnP/sZr732Gk8++SQ33nhjJWUO804QBP2aVe2xt/POO7PTTjtx6aWX8tnPfpaJEyfyzW9+k/3222/pMfvuuy9nnnkmY8eO5dRTT82S+/73v59p06ax/fbbs/XWW7P77rszbNiw0uXVyupCVMW4ceOsuIhKuGwGQXdz7733su22267qYvQKL774ImuttRbPPPMMu+22G3/4wx/YeOONVziu0TWRdLuZjas/Nlr6QRAEfZRDDjmE559/npdffpnTTjutocJvl1D6QRAEfZSq7PhFYiA3CIJ+R183S/cm7V6Llkpf0pslzSp8/iLpFEnrS7pe0vz0vV4hz6mSFkiaJ+mgQvqukmanfWcrQuUFQdAmQ4YM4ZlnngnFz7J4+kOGDMnO09K8Y2bzgLEAkgYCjwE/ByYB08zsTEmT0u/PSRoDTAC2AzYFfiNpazNbApwHHAfcAvwKGA9ck13aIAi6nlGjRrFo0SIWL168qovSJ6itnJVLuzb9/YEHzOxhSYcB70jpk4Ebgc8BhwGXmtlLwEJJC4DdJD0ErGNm0wEkXQQcTij9IAjaYPDgwdmrRAUr0q5NfwJwSdoeYWZPAKTvjVL6SODRQp5FKW1k2q5PXwFJx0maKWlmvM2DIAiqI1vpS1oNOBT4aatDG6RZk/QVE83ON7NxZjZu+PDhuUUMgiAIWtBOS/9dwB1m9mT6/aSkTQDS91MpfRGwWSHfKODxlD6qQXoQBEHQS7Sj9I9mmWkHYCowMW1PBK4spE+QtLqkLYCtgBnJBPSCpD2S184xhTxBEARBL5A1kCtpDeBA4OOF5DOBKZKOBR4BjgQws3skTQHmAq8CJyTPHYBPAhcCQ/EB3BjEDYIg6EWylL6Z/Q3YoC7tGdybp9HxZwBnNEifCWzffjGDIAiCKogZuUEQBF1EKP0gCIIuIpR+EARBFxFKPwiCoIsIpR8EQdBFhNIPgiDoIkLpB0EQdBGh9IMgCLqIUPpBEARdRCj9IAiCLiKUfhAEQRcRSj8IgqCLCKUfBEHQRYTSD4Ig6CJC6QdBEHQRofSDIAi6iFD6QRAEXUQo/SAIgi4ilH4QBEEXkaX0Ja0r6XJJ90m6V9JbJa0v6XpJ89P3eoXjT5W0QNI8SQcV0neVNDvtO1uSVsZJBUEQBI3Jbel/G/i1mW0D7ATcC0wCppnZVsC09BtJY4AJwHbAeOBcSQOTnPOA44Ct0md8RecRBEEQZNBS6UtaB9gH+AGAmb1sZs8DhwGT02GTgcPT9mHApWb2kpktBBYAu0naBFjHzKabmQEXFfIEQRAEvUBOS39LYDHwQ0l3Svq+pDWBEWb2BED63igdPxJ4tJB/UUobmbbr01dA0nGSZkqauXjx4rZOKAiCIOiZHKU/CNgFOM/Mdgb+SjLl9EAjO701SV8x0ex8MxtnZuOGDx+eUcQgCIIghxylvwhYZGa3pt+X4y+BJ5PJhvT9VOH4zQr5RwGPp/RRDdKDIAiCXqKl0jezPwGPSnpzStofmAtMBSamtInAlWl7KjBB0uqStsAHbGckE9ALkvZIXjvHFPIEQRAEvcCgzOM+BfxE0mrAg8A/4S+MKZKOBR4BjgQws3skTcFfDK8CJ5jZkiTnk8CFwFDgmvQJgiAIeokspW9ms4BxDXbt38PxZwBnNEifCWzfRvmCIAiCCokZuUEQBF1EKP0gCIIuIpR+EARBFxFKPwiCoIsIpR8EQdBFhNIPgiDoIkLpB0EQdBGh9IMgCLqIUPpBEARdRCj9IAiCLiKUfhAEQRcRSj8IgqCLCKUfBEHQRYTSD4Ig6CJC6QdBEHQRofSDIAi6iFD6QRAEXUQo/SAIgi4iS+lLekjSbEmzJM1MaetLul7S/PS9XuH4UyUtkDRP0kGF9F2TnAWSzk4LpAdBEAS9RDst/X3NbKyZ1dbKnQRMM7OtgGnpN5LGABOA7YDxwLmSBqY85wHHAVulz/jypxAEQRDkUsa8cxgwOW1PBg4vpF9qZi+Z2UJgAbCbpE2AdcxsupkZcFEhTxAEQdAL5Cp9A66TdLuk41LaCDN7AiB9b5TSRwKPFvIuSmkj03Z9+gpIOk7STEkzFy9enFnEIAiCoBWDMo/by8wel7QRcL2k+5oc28hOb03SV0w0Ox84H2DcuHENjwmCIAjaJ6ulb2aPp++ngJ8DuwFPJpMN6fupdPgiYLNC9lHA4yl9VIP0IAiCoJdoqfQlrSlp7do28E5gDjAVmJgOmwhcmbanAhMkrS5pC3zAdkYyAb0gaY/ktXNMIU8QBEHQC+SYd0YAP0/elYOAi83s15JuA6ZIOhZ4BDgSwMzukTQFmAu8CpxgZkuSrE8CFwJDgWvSJwiCIOglWip9M3sQ2KlB+jPA/j3kOQM4o0H6TGD79osZBEEQVEHMyA2CIOgiQukHQRB0EaH0gyAIuohQ+kEQBF1EKP0gCIIuIpR+EARBFxFKPwiCoIsIpR8EQdBFhNIPgiDoIkLpB0EQdBGh9IMgCLqIUPpBEARdRCj9IAiCLiKUfhAEQRcRSj8IgqCLCKUfBEHQRYTSD4Ig6CJC6QdBEHQRofSDIAi6iGylL2mgpDslXZ1+ry/peknz0/d6hWNPlbRA0jxJBxXSd5U0O+07W2m19SAIgqB3aKelfzJwb+H3JGCamW0FTEu/kTQGmABsB4wHzpU0MOU5DzgO2Cp9xpcqfRAEQdAWWUpf0ijg3cD3C8mHAZPT9mTg8EL6pWb2kpktBBYAu0naBFjHzKabmQEXFfIEQRAEvUBuS/9bwGeB1wppI8zsCYD0vVFKHwk8WjhuUUobmbbr01dA0nGSZkqauXjx4swiBkEQBK1oqfQlHQI8ZWa3Z8psZKe3JukrJpqdb2bjzGzc8OHDM/82CIIgaMWgjGP2Ag6VdDAwBFhH0o+BJyVtYmZPJNPNU+n4RcBmhfyjgMdT+qgG6UEQBEEv0bKlb2anmtkoMxuND9D+1sw+DEwFJqbDJgJXpu2pwARJq0vaAh+wnZFMQC9I2iN57RxTyBMEQRD0Ajkt/Z44E5gi6VjgEeBIADO7R9IUYC7wKnCCmS1JeT4JXAgMBa5JnyAIgqCXaEvpm9mNwI1p+xlg/x6OOwM4o0H6TGD7dgsZBEEQVEPMyA2CIOgiQukHQRB0EaH0gyAIuohQ+kEQBF1EKP0gCIIuIpR+EARBFxFKPwiCoIsIpR8EQdBFhNIPgiDoIkLpB0EQdBGh9IMgCLqIUPpBEARdRCj9IAiCLiKUfhAEQRcRSj8IgqCLCKUfBEHQRYTSD4Ig6CJC6QdBEHQRLZW+pCGSZki6S9I9kr6a0teXdL2k+el7vUKeUyUtkDRP0kGF9F0lzU77zk4LpAdBEAS9RE5L/yVgPzPbCRgLjJe0BzAJmGZmWwHT0m8kjQEmANsB44FzJQ1Mss4DjgO2Sp/x1Z1KEARB0IqWSt+cF9PPweljwGHA5JQ+GTg8bR8GXGpmL5nZQmABsJukTYB1zGy6mRlwUSFPEARB0Atk2fQlDZQ0C3gKuN7MbgVGmNkTAOl7o3T4SODRQvZFKW1k2q5Pb/R/x0maKWnm4sWL2zidIAiCoBlZSt/MlpjZWGAU3mrfvsnhjez01iS90f+db2bjzGzc8OHDc4oYBEEQZNCW946ZPQ/ciNvin0wmG9L3U+mwRcBmhWyjgMdT+qgG6UEQBEEvkeO9M1zSuml7KHAAcB8wFZiYDpsIXJm2pwITJK0uaQt8wHZGMgG9IGmP5LVzTCFPEARB0AsMyjhmE2By8sAZAEwxs6slTQemSDoWeAQ4EsDM7pE0BZgLvAqcYGZLkqxPAhcCQ4Fr0qfXGT3pl033P3Tmu3upJEEQBL1LS6VvZncDOzdIfwbYv4c8ZwBnNEifCTQbDwiCIAhWIjEjNwiCoIsIpR8EQdBFhNIPgiDoIkLpB0EQdBGh9IMgCLqIUPpBEARdRCj9IAiCLiKUfhAEQRcRSj8IgqCLyAnDENTRKowDRCiHIAj6JtHSD4Ig6CJC6QdBEHQRofSDIAi6iFD6QRAEXUQo/SAIgi4ilH4QBEEXEUo/CIKgiwilHwRB0EXE5KxVRKzTGwTBqqCl0pe0GXARsDHwGnC+mX1b0vrAZcBo4CHgA2b2XMpzKnAssAQ4ycyuTem7smxh9F8BJ5uZVXtK3UO8OIIgaJcc886rwGfMbFtgD+AESWOAScA0M9sKmJZ+k/ZNALYDxgPnShqYZJ0HHAdslT7jKzyXIAiCoAUtW/pm9gTwRNp+QdK9wEjgMOAd6bDJwI3A51L6pWb2ErBQ0gJgN0kPAeuY2XQASRcBhwPXVHc6QbtEbyEIuou2BnIljQZ2Bm4FRqQXQu3FsFE6bCTwaCHbopQ2Mm3Xpzf6n+MkzZQ0c/Hixe0UMQiCIGhCttKXtBbwM+AUM/tLs0MbpFmT9BUTzc43s3FmNm748OG5RQyCIAhakOW9I2kwrvB/YmZXpOQnJW1iZk9I2gR4KqUvAjYrZB8FPJ7SRzVID/oxEWY6CPoXOd47An4A3Gtm3yzsmgpMBM5M31cW0i+W9E1gU3zAdoaZLZH0gqQ9cPPQMcB3KjuToN8S4wpB0HvktPT3Aj4CzJY0K6V9Hlf2UyQdCzwCHAlgZvdImgLMxT1/TjCzJSnfJ1nmsnkNMYgbVES8OIIgjxzvnZtpbI8H2L+HPGcAZzRInwls304BgyAIguqIMAxBEARdRCj9IAiCLiKUfhAEQRcRSj8IgqCLCKUfBEHQRURo5SBIhNtn0A2E0g+CiojZyUF/IMw7QRAEXUS09IOgD1GFiSnMVEEzQukHQbAC8eJ4/RLmnSAIgi4iWvpBEFRODGr3XULpB0HQJ+kL4xtVvLx6Q0Y7L9Aw7wRBEHQRofSDIAi6iFD6QRAEXUQo/SAIgi4ilH4QBEEX0VLpS7pA0lOS5hTS1pd0vaT56Xu9wr5TJS2QNE/SQYX0XSXNTvvOTguuB0EQBL1ITkv/QmB8XdokYJqZbQVMS7+RNAaYAGyX8pwraWDKcx5wHLBV+tTLDIIgCFYyLZW+md0EPFuXfBgwOW1PBg4vpF9qZi+Z2UJgAbCbpE2AdcxsupkZcFEhTxAEQdBLdGrTH2FmTwCk741S+kjg0cJxi1LayLRdn94QScdJmilp5uLFizssYhAEQVBP1QO5jez01iS9IWZ2vpmNM7Nxw4cPr6xwQRAE3U6nSv/JZLIhfT+V0hcBmxWOGwU8ntJHNUgPgiAIepFOlf5UYGLanghcWUifIGl1SVvgA7YzkgnoBUl7JK+dYwp5giAIgl6iZcA1SZcA7wA2lLQI+DJwJjBF0rHAI8CRAGZ2j6QpwFzgVeAEM1uSRH0S9wQaClyTPkEQBEEv0lLpm9nRPezav4fjzwDOaJA+E9i+rdIFQRAElRIzcoMgCLqIUPpBEARdRCj9IAiCLiKUfhAEQRcRSj8IgqCLCKUfBEHQRYTSD4Ig6CJC6QdBEHQRofSDIAi6iFD6QRAEXUQo/SAIgi4ilH4QBEEXEUo/CIKgiwilHwRB0EWE0g+CIOgiQukHQRB0EaH0gyAIuohQ+kEQBF1EKP0gCIIuoteVvqTxkuZJWiBpUm//fxAEQTfTq0pf0kDgHOBdwBjgaEljerMMQRAE3Uxvt/R3AxaY2YNm9jJwKXBYL5chCIKga5GZ9d6fSUcA483sX9LvjwC7m9mJdccdBxyXfr4ZmNdE7IbA0yWL1hdk9IUy9BUZfaEMVcjoC2XoKzL6Qhn6iozeKsPmZja8PnFQyT9uFzVIW+GtY2bnA+dnCZRmmtm4UoXqAzL6Qhn6ioy+UIYqZPSFMvQVGX2hDH1FxqouQ2+bdxYBmxV+jwIe7+UyBEEQdC29rfRvA7aStIWk1YAJwNReLkMQBEHX0qvmHTN7VdKJwLXAQOACM7unpNgsM1A/kNEXytBXZPSFMlQhoy+Uoa/I6Atl6CsyVmkZenUgNwiCIFi1xIzcIAiCLiKUfhAEQRcRSj8IgqCLCKXfT5E0VlKjeQ/tyFinyb43lJGdZKxXVkZ/oYr7EQS9QQzkApI2NLPsGXKS1q9LMuB56+BiJllmZs+1mW8msAVwB/AH4I/ALWb2lzZk3GFmu6TtaWa2f6N9LWR8vzbDui59M+AaM9s+sywH4PGYAGaa2R+zTsLzDgNOBQ4HajMQnwKuBM40s+czZKwDjDCz+en3kcDQtPtaM3uyRf7S9yPJ2QQ4gcK1AP7PzJ5pQ8ZQ4EN1Mi5PoU/aokT9PAifhzPNzB4qpP+zmV2QkX8/M/tt2t7CzBYW9r3PzK7IkDEIOBZ4L7Ap/pw+jteLH5jZK5nnsj3wWfx6GjAX+G8zuzsj7+a4bvhz+r0vXk8fBr6be08kbYOHrBlZOI+pZnZvTv4i/aqlL2kHSbdIelTS+cWWpKQZmTLeJWmhpJsl7SzpHuBWSYsk7d9SgHM7/iDdnj53AE9J+o2k0RlleIOkSyUtBm4FbpP0VEprmR8gzcbbDDgDeBk4CZgv6S5J52aeR7FlWv8iy221DpL0Y0lL65KkbYGbgLNaFkDaTNIdwGnAaFxx/qekX0taXdIKL5QGTAGeA95hZhuY2QbAvintp5nncRawV+H3fwJvAfYBvtoqcxX3Q9LbgRnAEuBCYDKwOvDbNLflRxkydgDuBd4GPIQrl4OAP0haV9LXMmSUqp+Svg58AdgBmCbpU4XdJzbOtQLFuvOzun1fzJTxI2As8BXgYODd+L3cCfhxjgBJhwE/B24E/hn4F+B3wM/SvlZMAdZMssbi9fGRVIbcevE5PE6Z8PpxW9q+pKNIxWbWbz7AzcB4YF3g34B7gDemfXdmypgFbAu8FXgG2COlbwvcUbJ87wN+nXHcdOAoYGAhbSA+We2WDv53TWB/4EvAAuDBzHx3NNpu9LuJDOE+wz9N57An8Cjw7sz8U4GPNkg/Bn+ZtiwHMK+TfXXH3Unq+dbXJ+DmXrofM4CdG6SPBf4CTM6QcQNwYIP0A/AZ8deu7PoJzAYGpe11gV8B/1N/XVvdj0bbbcpoVi/uz5RxFzC6Qfpo4K6M/HcXts8C/ittDyjuayHjfmBwg/TVgPnt1E0z63dKf1bd732B+cAebSipoqJ7tJn8DsuYo6R6vFG5NxH4IPBd/EU4DTgT78Zu3EZZFwGfBj5T2K79fjRXTpL1beD3eCtmjzby9fjwpTJtlCHjOrz7PaKQNgL4HPCbzHLMrvu9fWF7Ti/dj7nN6gUwIEPGfU32LQTWWNn1E7i37vdA4Ad4w+CezGtRRYPkFuDI4nVLyvYo4NYK7kmP+xrVK7wRc1Dhd67Svw8PnlafvjmZjZrip7cDrpVFkoZZso+Z2Q2S3o93/+rNEz3xvKSPA+sAz0n6V7wLdgDwYsnCrUWeyez21OWfjLeKwU0DE/EWZw7n45Xhf4GbzOz+NosL8D1g7QbbAN/PESDpO7iNUbjN8w7gg5I+CGBmJ7UQ0fB6JXPR383sqYxiHAVMAn4naUQqz5N4L+IDOecBvCZpYzP7Uyr3nFSOkcBrGfmruB+StJ7V2c+TXf1VM8spxwBJq5vZS3UyhgCvmNnfMmSUrZ8PSHq7mf0OwMyWAMcm09L7M/IDbClpKl6vatuk31tkypgAfAM4V1Ltmq4H/Dbty+EVSW8ws0eKiclW/2pG/t9KmgI8Ufjv2thN7hjLKbiZbD7L7scbgDeRby5bSr8ayE2K5EEzu6Uu/Q3AaWb2sQwZm+E2wddw+97R+GDPw8C/WcbAiKRPN0heDzgUOMc8Smiz/Kul/6wNzAhv1U7FB5heapK9JmMgbhfcM33ejFes6cB0S4NgObQ7kF2Xd2Kz/WY2uUX+/wHWAk4xs7+mtDWB/8GV/smdlKtdJH0YOBnv5dQU2y54l/xsM2tqT6/ifshDin8MN13ekZJ3xRXXD1rVqyTji3jP90RLA6jJDn82cJuZ/UeGjEb181HgKjLqZxpIxsz+3mDfSDN7LKMMb2+2v/ZCyUXSBri+a6ueSzoc+C/g6/j4neFjPZOASWb28xb5hTdKNgGm1M5d0s54L/bazHIMwNcjKeqL29ILtS36m9L/gJlNWYny16wpnhbHfbkuyfDxgZvMbPZKKVwLUgv3COBfgS3MbGBGnkOAHwKv4C/BD1gbXjNJxoCeWqCS1rUWnjOSBuODph/FX7yGd1snA5+3DO+GBi9hw2ON32wFr48MOeOBzwPbJRn34N4/1+TKKMhq+36kfIfgpqrtUtI9wP8zs6va+O8Tk4w1UtJfgbPM7Du5MprIHmRmTVu46QU41MxeTL/3wO3P4Pb4F8qWo1Mkfd3MPt9mnp3wxsB2uMKdg3vv3LUSitisHMNxj6hXgYW169u2nH6m9K/Gg8Qdb2YPlpAzEn/z3m1mL0vaCO9CfdTMNs3IP7FRCzYpsIvM7OgW+WsmkYZkmESQtCPLWpV74g/VdNxV8A9mNjNDxt24or9P0u74IFPTFlYDGXcAnzSzW+vS/wVX2ltmyhmKd1eFr66WY4ao5a1/CYOb+w4CvmJml2bIGJdzzZrkL30/qkDSCEvupZLWBmhXyUq6Cu8pPFyXfgDwLWvhhivpLOApM/uv9HshriiH4Pb4z7VTngbyrzGzd2Ucd3Z9EvAR4CLIfs4+g5/zkrr0DfDn5dgW+V+g8bMuL4L1OFemIGMM3lMbjZt17gQ2wr2ITq6Zu3PpVzZ9Mzskdbd+Keli4DwK9lYze7aVDEmn4O5kC4DVJX0b+CZeEXbNLMrJyW66tLudTBK/wAcyW1GFArgQVyjX4Kath5sf3pBXzew+ADO7taYk2uQk4Hy5y+zn8Fb6uXj3c59cIckUsFwvSdKBZnZ9Rt6GLpXJFv4b3N2tFd9LYzKXAJfkmPnquBD3z+/4flTRGADukjQbuBj4mbU5TyBxKXCDpB/gpo3hwLdwhdPUnJfYHzeB1HjezN6TTB2/zymApJ7miAj3Zsrhfbir5XUsc0GegJtpcnkzPsZxgpn9IZXteODfceeFppjZ0mdK0p1mtnMb/13jAmCimc2TtBtwgpntLulj+AD5Ee0I61ct/Rqpu3UT7oddOwHLaVVKmgvsbWbPprGABcA+9eMELWSsD/wa+LGZnZ26Xb/CJ6K09JstaxKpO34NvIUMPpLfcjygkHcR/sKr8enibzP75gqZGssZiI+PnIAPhh9rZtfllqOJ3EfMrNTM4HYeNElvxpXCUfgg2yXApTkKXNK/p2MfbXVsExlFhfpVYLkeTKvxkSRjIO6UMAH3TZ+On8fURjb2JnKG4Qp/f2AwPv/ge5ahMCTdZWY7FX6/s1YfJM0ys7EZMpbgLdlG80X2MLOhDdLrZawN/AfeKv53M3tM0oO5vc+CnD1xz6x7gG1wT6rPmNkTbcrJmvDYIF/99SxOqpxrZmN6zr0i/aqlL2l1fBD2COBDZnZ1B2L+UesRmNkjku5vR+GnfM+mru41kjbFB7zOM7P67mRPzJTUo0kEyHl5DQb+H95dfQj3gtlI0nfM7ExJO5tZK0+Leo+d+t+5HIkPiJ+HK5yj5Mu55fS8elpER8AGHZSlKHs/vGGQhZnNw5XtV1PDYgLuffEnM9ureW42Bf6YTBmXAD9td9CwqNQlnZKj5BvIWIKvV3FtGpB9F34e35bPuv5Qpqgx+MDhDGAc7gI7CB//acVqktaumZUKCn8YbuLJ4V7g45ZmSBeRlPViTf9/iqRdgR9L+iWdTUidg0+IGo/Xy7YVfkkekHQa7gr8PnyuUU0HtK3D+5XSB+7G3TN3aafVUseoOlvfRsXfmXa+96XN8/GW8TRgUS3dWk8Rr8Ik8t/4QN3o2sMlDyVwlqTz8Ara1LWtJ7NIO0j6DfB34AAzWyjpC7gb2W2SvmGtPU7eBnyYFd1lhSudnDLMZkWzyPr4VPVjcmTUyRuAtw5H4BOtFrfKY2b/Kh9Q3gdXsqdJugt/Afy8g8HL0l3wNF41F1egu7IsLENTJH0f91w63symJ9PlV3HT0SkZvbjvAZdJ+oQlV0e5i+N5aV8OX6FnBf2pHtIbYma3pwbA8fg8imzkXl2nA/8HvBH30DpH0v24t19Tl+KCrgBYt+53jq4Anwn8+fS5C/cyA3/+26/f/cm8I2mMmc1N2+sAtGuzVEkXwyTjh81F2D9nyChlEpG0ANiqvrud5D4NvKtVDybZBG80s/nJ3voD3I/6YdyG2NInW9J7rYHbmqSNcQ+Hpi1LSdfgA2I3NNh3k5m1fAkmhVLEgGcswxOrTs7b8B7L4Xjr7lLcLt7WQFmSVTOznAm82czWaJGlPn9HpoCU9w24iepo/KV1KW56yhqnkM9dObvB4OUOwLlm9rYMGZ/AldSaKelF3BPqvOwTKYmk68zsnSVlXAmcVDTxpWflE7jJqGmvvApdUTnW5myuVf3B33KP4S6Sz+FTlCekfZtl5P/Aqj6HVI4JwAO4/+8MXOGu30b+ZjNZc6eYzyFN78ZnlN6Om1QOAH7f5vmsAeyYPqv38rW8OpV/zRIyHsUHYj9FYWZvh7J2wG3gC/DYNadk5nsBD7fwAu6W95fC779kyvgj/tI+CxjXYfnHwrKQFCWvxVrA2h3mHQhsWPi9GnAcdTN+m+S/cyXXu+ErU37hf/YGjin8vhyf5PVbYL+25fVGoSs8+S/jA6ZbFtK2xCeNfA539Wsl42p8EHbLEuW4sLA9sYP8v0ll3iL9VlI2DwDHZcr4RbEiFNI/DFyZKWNWYfti3P2r9jt3qvtg3LPj2fTSuBN/KU9K+1eIJZMpdyA+bpNz7GG4GeUp4DK8pb5am/+3ecm6uRUeNG4u7oX0hTJ1rEQ5PlVWYePeZc8A1+NmlncC67SRf/fa8Xik0q+m+v4NYFimjAnAn3ET3e+AfXHz589x826OjAdxG3jDT2+cS1ldkfJNA8YUfs/GzXX7kBHrawV5vV0pS1bG+cCQBulD8e7joZlyDsftnKcBG+L23/XJbGmzfDCotoO0Ae/tIX1j4CeZMkbircgbcfv+WenhmAGMzJRxBz5fYQgetmC7wr7c1tTZeMiGtQtp6+DjHefhk0ia5V8HD4v83aRcai/Ah8l8edXVg6OSYvgT7uq2QvCxHvLuWNgejDsMTMV7Yjnxah7EW/c7lKjfQ/D5It/FW7SDOpBRKmhgQc4awDtwE83VqX7chZt3WuW9h2UB187HGwV74422KzL/fw7wprS9C/BST89NExnPpDrwwwafCzJllDqXsroi5but7vcVhe0/tC2vigrSWx8qiKZYOH4nvCXxEB6IaiEVRKdcBddkv6QkTwL2bzPvIXir/E+4O14t/e3ALzNlLKBByxJvqT9Hi+BreGzzC4GP4zGQrsdfXmNLXpcd8V7Hkg7u6X+nMr0dDwdxUUb+t1ZwLy/DQ/5+HO/JfbsDGZXWRzqIGEqhwVBfHjKDGjbI12MguU6uBbB7poxS51KFrqB5ALyW1o36T3/z3lkkaX8zm1ZMTCPzLeN5pGOrcPuseQCJFb2BsBYeQA28TQwffL0Bny7/j9yCmMd0qQVxyg06V8t7dRoEXduWD/J1G95izuE1S7WvTvYSSYuttTvslma2Ayz1GnkaeIN1MFVfHvrgA7hpYBM8quM/5WYvbO8PvMXMXpF0E97CbcU5eIsUSdPN7K3ZBV/GmMK1+AHea2uXHSU1cm5oZwboB/FZxWPxFvZteK9yb0sB6VowR9I/mdkPcY+fcWY2U9LW5Ll8gnvVFcNrrFX8bXlzSJqtCfFTfLJZK8qeSyldkbhP0rvN7JfFRHnIjnkZ+Zejvyn9k4ArJd3M8sGP9sKDneVQhdvnvxe2O5lde0iDtPXx2Y7fwYNuNUXSF83sa2l7DN4yHJw8C46yujkATdgLb5E/J+kDuJ3wATIXeADmSjrGzC6qK9+HcRNaK5Y+OOlFsbBdhZ+8kI7GZ09eAXzW0uzJNhgm6b24m+DqllZVMjOTtMJLrVExCtu5vuj1FK/Fq+ps9cXZ1tmszyJlI4b+Cz4v4Iv4S3x68q1/NO3LoYo5JB9psi/34pY9l7K6Ajx+0y8lHcHygfj2pLEuaUq/ctkEkIeI/SDLgh/dg9vBs1rHRbfPEmVYaYHflDmDVMvPyvslvvTaNfJp2t8ysz0zZJyDm0GG4C2GtfBB7j3xBTRaTuSRxzG6AvfVL76Ih+I22KY9MPnMy7+y7CEcCvyN9lqmP8QHcn9jeeGHe5JRZJKZPZlcT39ihaUke8h/F24DH4D3vN5BQbFY3kS12rUg5e3kWnTs6lmQUUkEV/mM2C3xxuUia7HkZG+iNmd7r+pzSRaKD7F8IL6L27EKLJXV35R+DXW4dmcLmeeb2XEZx1US+K0H2ctNuW5yXFHpL/eiaOPFMdfMxqQX6WN4qNclqbdwd83UkFnu/Si8iOtNcCsTrRinxYCnrURIhA7K8BAeB6pRC9Kszan/JcrxkpmtXrHMtiKGtjIz5rwAk5yy6+xeRc/BzvYzszUb7MtG0lrWItJlkzIAYGa5FgokrYt7iYG7Zbc9fwT6mdJPk07+Cx+8/DN+89bBW1aTihWjiYyeKqTw5c9GZZblcDwkcNuB3xooKfB4/B8GXjSzljMOJT2Pxx8SHj99c0uRKSXNsYwFyeteHMu1EDttMUp6E95KvLedHpWWXxj9NjOb3kbeGxokr4/7dR9tZrMy5QzDZzIXF5++1tqIhVQlqRdVU7CPW4uQxilP1gu/hYxSEUPloSgMr5ub4Nex9jLMegFK+k/c9HgH8B689/qdtC+rbqrimPwN5LfsLVRRBnk4jfNx1+SFeG9yc9xL7RPW5oL3/U3pT8ddpi63NFswdUWPxCfA7JEhYwnuDlhskdUq6EgzW61hxsaydqKDwG8NlJTh7mU3AufX7MktZNRXptvN7MVaq8zMzsmQUQu4JrwVVxscE349N8uQcQNwpJk9LekjuBvsTbh/8/nWIoa7fFGbK/EJSLen/94FNxcdBnzEzLJW8WogexzwTcub1XsM7oZ3HcucAkYBBwJfrR+zaCJncP39U+YiNZJOxSfLnZ5+P4I3bgbj6+P+Z4aMmpmpoc0608x0B0nBA3+0ziK41mR19BKSOzvsnMY21sUbV/PMw12UfrG1UY5GCyaBX98vmFlbzhMdluF0PATEJ2xZyJW1ceeBh83stLbk9TOlP9/Mtmp3X/1xuGvjCiGQJT2aqeiKHkD/bm16AEnavMyDVBVqHId+KZYRm6fYq5B0GzDezJ6RR/+8xcx2bJF/Ku53fGFd+jG4zzplbNRttArn4W58z9elr4evp7p1i/z7Aj8CVsddRT9uaQGXNspwB/A2W7aC2J1mtnNq2PzOzPbOkPES/tJapWamQnk67THea2bbFn4PxFu76+BeTtv1mHlZnmH4HJDD8fDQ4BP4rsRDQjyfIeMfeGDDRr2sfzWzdVvkH5fyP5bKcgE+5jUfn4h5Z0YZ5gC7Wd0aE/JQ4Lfk9OqXwyr06V3ZHzyGyLl4K3LT9Nk9pU3JlHECsFMP+z6VKWMePmlnaIfnsQBfbq3tyTcFGSeSpqjjoZVvAp7HXeu271RuB+W4kzQZDHc5HZK2B5KxCDYVLIzeJP8IvAeUc+z9NJhhCQwjbzHw20iT2/DGwHzSHAUywwGwoh/4RwvbueeR9V8tZMzGvdxqn7vwWaFfpMHkyHbOqY18VwNvb5D+NdxNOEfGtfhM/Y0LaRunZ+/6TBl/BHbtYd+jGfln4JFOj8Y9fo5I6fvjg+I5ZehxAXUKC6/nfvpbS7+KtWVX6H53UI4xuOKujaYbPv3+4swyrI1H7tsPf9Hc1EEZ7rHU2kneO983s59LegdwhrUOBYxWXFloOSwv4ug78G5mbXH6XXAPoLfh9vCzWuRfYGZvapA+AO/O5/TeGi0+sj5ujz7ZMpYalAfi+xJu3ikuPn0g8B9W1xNpkL8+5vl2uFfTJHxRlZyW/v34i6PePLQ6MCfzWtxpPZg+JL3FzG7LkLF5g+SaS/Ga1mIt6jqTyHJrNECej72qWWd3npm9ud19dce9GQ/et4J5ToVVyprkX3o/6scA2nC4aGayu8EyHD+Wk9eflH4z2qjQte7dJfgFa/sCJKV/Jd4KKNqh98JDQWQNYMrjfE/DX1w1zw+zFiaRlHdppZV0m5m9pbDv7kwZL+PT3aew/GAbkBdxNMkZhrvRbk1yacNDKNyXkfd/KLkwulaMnFobI7nNWoS+rZOzHr7EYrFBca1leIhJmgkcYoXJS5JG4S3WN1phBaUmMr6Ot0RPtGWD8mviYRn+ZGanZsh4Nv3fc3Xp78QbRi3Nly3kt1RULcyGZmnMIuO/VqPDhlXKfx0e52qyLVtCcgS+HvOBZnZAjpwypHHIL+M9xrPwRsgv0pjcf5vZuAwZD1GlZ1i7XYO+9MG9PU7Hu9IzM/NsgE9zvwF/qL9F5pTsgoxpNIjpgkenvCFTxn54N/osPO795rVPZv4z8FABW+LxUU7BW6b/BFzdxrX4RLoW1+OTTdYrcT/WoY3AXCnP4HQNnsZfoLfj8evPos2gaRXXrQ2A99JD176He79Tg/Rh+IBfjoyBeCjm+mtxJpmmQHxi3ywKESDxF/JCCvGFSlyXuzKOGdVk33sy/6fWm56MT8o8OW0voBB8rIWM9fDAaPfhAQGfxScMfoP8OFtlYzLthJuZrsFX3fo2boa9B9izN+v00jKtij8tWek2x7vMd6WH4ml8IZFOZG2aKtN0fBbqGZn5eowDQkagMnxs4veUCM6V5HwUt+E/jXu/zE2VcVgHskYC/4a3+D/SZt5TWBbu+lnaDHedjhuKhyTeMedhaqNs12QedzVpLAR3M3wCj6Y4l8zQyA1ktjUewbIw17VrsQMdjBvhM1Fnp/M4JSm90W3k36XBZ388UNl3MvLPa/R/eIPkgcwylG5YVVR/SsVkqqgMA4G1Cr/3wGfO70MHYav7lXlH0h/xllNtUYj58mn7TVeIaiFzLTzU6qeBTcxsREae+3GF/VJd+hB8YKWp7VXSx8wsdwWhlY583sDRuP36drzbmWui+gq+wtWJliaqSdoSb9HcDHzMGtjsC/nf19M+yFtZSM0X0b7azDbJkFEcI/k8sI2ZHZPGX/5grb2Q6l33hF/LnXEzao6rZM30eDG+uE3HD6ekI/GQHo/gC+o800beG+qSauayG8lwKZZ0MH7/D7a03GFyR/1gKsuijDLcZ2bb9LBvOc+eXCTtjdfVOZa5YFGdTX4Wy2Iy1eb1tKoXq+GxoB43s99oWVyjuXiQwxz37LOAp8zsv9LvhbhZdgj+UvpczrnU6G+xdxbjvtMjcBes+XSwrFxSzu/BFd1e+MDjqfggXg4XAT+TdKKlCWGSRuNhhn/UKrOZfU/SNiwbkDa8hT3VMlc3Sv+5Dt6Nf6AufUczuzsj/1fx2B334i/SUy1jAlAdH8JfgEung5vZg/I4PovxB70Z76nbLg66Gj4Y2orb6HkR7XUz8sPywbP2Jy3rZ2YvSMoJ7fA0Pv+jyEh8cpGRse4xsC3u+fMl4EeSLgcusfw4SjX/dsOvxRq4meqGpKSslZLCD9o39/96yP+r5Dp6jXwS47/gbor7WP4M+gGSVu+hYZWltyTNMLPd0vbHcM+9nwNflrSLmZ2ZIaZsTKYfpvKukcae1sLr9P6452H9eFQj9sevX43nzew96Z7+PiP/8vRWN6nCrs4wfM3I63E75XO4D2tu/otxX93L8QesLRe0gpwT8VbU0yx74HNdPj+L210n4bNwP5y2Z5EWH8mQ8QH8RTELtw++pbAvdwGU13Ab6WyWd9ObTRM3sToZVYa7vrPDezEHXzqy0b6WbnXpuKvwENXvTXVq3ZQ+lDzX03/DGw87FNIWdnI+KW+npsfNm30yZRzT7NPGOeydno2p7T5nuO38agpmImB0kvWldusT3jAYnrbXJNPVkRXj8I9I6Rvj4SFa5b87fQ/C1yQYmH7XQp3klOGuut/vLGzPartudVop+8IHb/GfhHvR5D7cE+lw+bYe5K3drjzc5j24QfpqZPiE1242bo4C77LeR1oNKFd5VqQgptEgjj8+UP3bNq9Lpz7dR+Dr0Dbad3imjI3wqJJX1j1U++ILYOfIGIWH7P1mqhdZ6zM0kbdWUrSzgCfLyGrzf7/T4PNdvGHzakb+4rKPL+NB5Npa9jHJKTasnqGNhlXKfxc+mLsBdY4euc9IBddyTnqu10vnv35KH0L+QkX3NtIxeAO4/XUGeqsi9cLF3byNY9+It8y+jQ/OfII2Bz+Ton1L2h6DjwkcnJn3vkblTco2q3VMXUsFH7S7HX8J5rb0D2qy78hMGdvhvYUL8ZbyibTpZVGQtcoWpMFj+Fcl6z3ALbibZbt5h+BhRa7AW4aT8ck9AzPz1xRuo8/iVK7sxXbwFumH8d7fZWR4ANGgQVPyerbdsEr5HsJXNFuYvjdO6WuRv5jLW1h+ctcxeMPgbDI8gPDwJg+mF9ZJeCPpe+l6fjmzDJ/Gl4l9QyFt85T2mXavS38byJ3abL9lRKyTdBL+UP4OOBhvRT2Hd+uPN7MbM2R8GX8QB+Fmpt3xQa4DcL/uM1rkH4+3nOaz/ESgN+EDor/OKMMfcS+bBwppa+Nx9fe2jEiL8jhENwEftrrJLmpj+rxKhLvW8lEI90nlWUrOPU1ytiEtIWmFyIeSxmdez2LwuZ+Z2ftz/reJvKG4v/ycNvJcjNehm/AxlqtzrmEb8gcC2+P3punUfUmDcO+wz+AeYv9pZlkLdrRTd5rIqA2APmZm0woDoPeSGZ+qiew1cDPNwoxj7wAOMLNnJe2D35dP4QvMbGtmR2TI2BTAzB6XxxE6AHjEzLIXyZH0Cdw1uxYZ9EU8lMR5uTKWyupnSn8xriQvwSti/WSinIh1s/Gl+Jakm/8rM3uHPILnlZY3Q242ftNXx5caHGVmf0kP+q2WNzFqAN5bKE4Eus1SILmM/DsBfzWzBXXpg4EPmNlPMmTciYew+BLwaTP7aXFfzrXoQe6G+CzGlpVL1UQhPAkfpLsXvy8nm9mVaV9u3Jul51vm3HuQXVt5qdVxE/E4RG2vGpZZjrXMg/J93Mz+r8lxJ+DjCdNwxdJWnKgqrp+kn5AGQHG/9uIAqMxsYkn5LcMip+OWzrSWrz+x2My+kn7PMrOxK7sM9Xnw8++4jvQ3752NcbfCo/GW5S9x74Z72pQzCFiCK+21AczskaQwc3g1Kee/SXrAzP6SZPw909MDM3stuV69TPLeyVX4iY/hL7/llH5qAbVU+MsOt+9J+h3wk+Rqd4L5bNCs1oCkPfDJQ88C/4F7L22Ie18c06qVXVPqqbfwpvS/D7TZwv0YPonqxeRFdbmk0Wb2bRp79DQsSg/bVfBVfBCwFfeRypsaEKfiLp9zga9bh/HTC8zFTQQ9KvzEd3Bnh72Bq7RsBa9cD6Dh6jk6JZa31OEOZrZj6nE8BmyaGmo/Jm/5ylbMJW+5xIGSBpl7te2PL1hfo6z+zCqDpN1x+/9fcL01Kbkpd1Qv+pXST0rx18Cv5fFIjgZulHS6tQjhW+D7wG2SbsHNCd8AkDQcV1w5vCxpjaQcd60lysMRtFT6ksbig4bD8Ba+8PUzn8dNTHf0nHsp84GzJG2C21ovscy48fWY2f2S3ooHs7pTHuEyl+/i3c5h+LoG7zKzW5K55RL8fvVIeqi/jntkPYy7xo2Sr2T1hcxu/MBai8nMHpLHA7pcHkMmV+nvJF9bVsBQLVtntqbomq5aJaknF1nhDgc5XIDP4AQfb/obXj9rE6OazmlI5WgWCnitzHJ0PO8lMTD9V+61b8SAZOJZE2/tD8Ofz9XxmbEtqehaXAL8TtLTeLjv3yfZb8LDXvdGGUrXi+X+uD+ZdwCSsn83rvBH4y5cF9TbpFvI2A73iZ5jGfFhGpXBGsT/SGaNTcxsdov8s/DQu7fWpe8B/J+1EUApKbYJ6TMEr6SXWsa6po264UlhXoC7t+XEi1naxdWK4XBbdvPlsXfWxsPU1mKFr4OHYciNvfNb3Dw1q5A2KJ3Hh6zFSk9VIOlJPG7Pc/W78Jj0m2bIWHr96s1SuaYElQwFXAUV2fT/FbedD8SdLQ7DB0T3wNfTyAn7Xcm1SM/lJsB1tiw+1Nb4LNmmDbQqylBFvVgOq3CUfWV/cE+G2/EWaanwwXjraxe8+zyigrId2saxPbplAgtKlGFnPNTxkszjD+8hfT3y5wvc0Wi70e+ergWp8VGXPrDZdao7dhQFD4u6fXv1Rr0AfoAPoDfad3GmjJ8C/5S2fwiMS9tb4+M9OTJKhQJOx/XkAZTlcklF7pCk8Olpe13cNbedOTmlr0UPebPi9lR4P0rXi+KnX7X0k728tnB0seBZXfAkYyzLTCvFFZKeJ9O0ohVDBwgPL3w8tA4dIA9p/EZ8Zm/Ne2cz3B1soZmd2KoMBVmD8SX+JuDdvd/hpp5ftCFjBIWZwdbGos9afmHz2kLepN9DzKxpV1zS/dbDAiXN9rVRvtwBu53xZS87rhdlSebBb+NhqZ/GXz6Pps9JZtbSli0PBfysmS1usK9lKOAqkLS+ubdLx/WqB7mHmllTD76640tfC0l74Sbh13AT5NfwZ7fmMNF0Wc+KylC6Xiwnrz8p/SqowrQi6VXcVv0Uy+yWR+CzfM3M/jlDxrtosC6Amf0q8zxqA9rvxhdquBT4haXuZ6aMsfT8AvykZazqUxZJv8A9Vi6qS/8w/lBlLxzdg/yW65im42ZRgcmtCkUnd73dkhSmujcUdSvaUbh9oWFVFZJm4Gt4rIXP2j7czG5OA6nfsYx1KyosSyX14nWj9Nto0TVbcrHhgh4NjnsL7rFyOfC/ZmYqGfitXeRBsS7B7Zu5A9D1MmZR0dhCXf71c8skX/z7CnyQ7HZcWb4F7zW81/IWyyi9jmnZerGyegodtG4H4Urqvbh5xPBwHVfi8fRzAnyV7cnOom80rKq4FnfaMlfe+jGrlmMXVZShB7nZz9gKeV9HSj+3RVeJaUXuZ/8pfP3Nz+GDp1mLGRQqwuEsH3CtVytCRS/AUt3fgpz9KEzuMrNpeWdR2WBZqXpRkaJr5IVxLm20biVdgr9oJuO9R/CXz0TcFn1UhoxSCrevNKwquhZFP/3Di2ZTFdaHXsll+KKZfS1tj8EnYA7G781R9XWupbz+pPSraNElOaVMK3WyRuKxtce1ofSrqAh74oOHHSvbKl6AK6P720Hr9o94TJbbG+zLWuw+HdtxvahI0VXRum22RGDWGElZhdsXGlYpfxXX4lDgN7biouRvBN5vKdzxSi5Dcbb4L4Hvmtk1knYDvmVme7aSsZy8fqb0V7k7WhVUVBEqUbYVjC2U7f5W0brtC4OXVbxAq2jd3oK7OP7MzF5LaQPweD6fNrPdM+WUVbirtGGV8lVyLcpQRRnqlP7S563R7yysAteq3vpQjfvTIHy5xGvwMMJ3pe1PkBkoqiDj153IwINeHQkMKKQNAI7CwzjklOHOwva9dft6LXAZhbCv1LmA4vMgWuV/FQ+hewHLwte+kL4v6MXzqKJevAsfwLwqndP/khmEr64enIwvYbkbbUbqxOeuXIYHV7sfd4l9KqVt0cF1GYmvoVwqYuiq+FRxLSp41qsow/P4fKSrkpw1CvtaPmP1n/7W0q/C/akK00opGfJQAd/Aww8/h7eEhuEP+iTLCwRVytaYjis9tlBB97eK1m0VA3al60WVdNq6rZOxAd6bf7rSwrX+3yrqVaUDoJ1eiyrrRYkyvL0u6XbzkCMjgCPM7Jy25PUnpV8FFZlWSssoHN9pRSilbNOxfULRVWBKqOJFXuqerqzB+U6Q+3WPryvHtWb2fGb+Ugq3LzSsCnLKXosq9EWpMlRNv1L6FbXoqrCxVSFjlVeEiip0ZS2yErbbKs6j1D2tSNFVUb+PAb6ML/1ZdB09EPiq1c2HWBnn0lcaVhVdi7L1oooyVNugaNcetCo/uF/6eXj8jVHps0dKuyxTxmjK29hKycAH9x5I5f5i+vxvSstajo6StsYko4qxhdL3pIJ6UcV5lL2nzZaNvL8X6/c80lKPdenrtVGOUudS0f2oQkYV16J0vaigDJU+Y20dvKo/VTxYdXk2ADYsWaa2ZfSVilC2QldxT6jm5VX6PCq4p5UoqTLXsnYcDVaBw8eMcmMZlTqXiupVFTJKX4sK6kUV96NSvdevQisDz0k6ksZdredyhdSbViS1bVopKUM0jtn+GmSHo93FVuz+LgJukdQywiZ4GGL8QS4z6Ff2nvwINyV8hRVNCT+ula8ZFZ1H2Xs6AR+cP1dS/eD8hMwiVFG/zwDukHQdy6/KdiC+3kEOpc6livtR0T2t4lqUrRdVlKESvVejv9n0R1Pe66UKG1spGfIVkr6U8q9QEczswowyVOWPXXagazQl7klVg+IVnEfpelGQ1eng/GhK1u8kZz08zHPRR/5aM2tfQXR+LqXHrCqSUepaVKQvypZhNBXUi6Xy+pPSL1KiMs4Ddq+vOOnG3JqjZCqSscorQpWKLslr+55UNChexYNZxT0traQKsipzt1Qby1cW8nR8Ln2hYdVEblvXoop6UbYMdXlL14t+p/QraNHdD7zF6pYYS3JnWg9T6auW0UBmr1eEqip0SQUxmvIvryoUdql7WpWSqqB+97h8Je4kkLNIfNmebF9pWFVxLcrWi9JlKPxfJQ2KfmXT76Ey7gt8XVLug1WFja2UjGYVQRnryhbklB2bKD22UPaeVGS7rWKMpGy9+AI+W/z55QqWlBQenqEpFdXvUstXVnQuVdyPKmRUcS3K1ovSZaioXiyT159a+hW2TEvbPMvIkDSTZRXhfOoqgmXE0qioC13F2MIqN4tUcR6FMnd6T6voQVZxLWdZieUrqziXiupVFTJKX4t0bJl6UcX9qNTE1K9a+lTz9ifdrEuXCnXTyvPtFKSkjEFmdl3Kd7qZ3ZJk3idln0bplqWZTZY0leUr9I3AqW28AEvdkypaMRWdR9l7WkUPsor6/Vph++91+3JbeKXOpYr7UdE9reJalK0XVZShEr23VFg/a+lX8favws5XSoaWj5pXv9Bx1qLSK2NcIeVvd6Cr1D1ZGQNlKX+751FFvSg7OF9F/S61fGVV59JAXsdjVp3KqOJaVPCsV1GGSnqyS7E2HftX9QefwDQB+Azwb2l7vTbyzwTeyTIf1z1S+jZkLuhcVgawhGULTb/K8gtPv5JZhoksm9X7+fSpzer9aKaMPfDW0xX4QuBzgD/hk2DG98Y9oZrJK6XPo4p60UDmhrDiou8rs36vrE8751LR/aikblZw3pXXiw7LUVm9WKUVqaKL0daDBcwqbNeHJM66iVXI6AsVYWVV6DYVRBUvrype5KXu6cpSUp28OCqoV6XOpaL70VeUbal6sRLL1XG9WCUFLnGiVbQg7mi03ej3ypTRFypCFRW6ontS9uVVxXmUuqcVKbrXReu2ovtRWkZF12KVP+tV14teuXAVnnwVD1YVppXSMvpCRaiiQldxTxrIbPflVcV5lLqnFSm610XrtqL7scqVbRX1oqIyVFoveuXCVXjypSrj6+nTh16Ape5JRS+vvvBgVqHoSl3LvnIuFdWrVX5P+8qn6nrR31w2K3HBep1Q2u3TzAZWUI6y96T05JWKzqMsO0n6C8lLI22Tfg/JlNFX6nepc6nifvSRe9pXqLRe9DelX8WD9XrhdaEgqGbOwiqnIiXVJ+p3KNw+R6X1ol8p/aiMy/F6URB95eW1yon6HTSi6nrRryZnBa8/qppMFARBHqH0gyAIuogBq7oAQRAEQe8RSj8IgqCLCKUfvO6RtETSLElzJP1U0holZN0oaVwH+daVdHzh92hJc6r8jyDIIZR+0A383czGmtn2wMvAJ4o7JfWG18y6wPGtDgqClU0o/aDb+D3wJknvkHSDpIuB2ZKGSPqhpNmS7pS0L4CkoZIulXS3pMtwDyPSvhcL20dIujBtj5D0c0l3pc+eeHjeN6Yex/8rFqjZfwRB1fQrP/0gKIOkQcC7WDbLdzdgezNbKOkzAGa2Q5oNfJ2krYFPAn8zsx0l7QjckfFXZwO/M7P3pl7EWsCk9F9jU1lGF47v5D+CoCOipR90A0MlzcLjFT0C/CClz7BlC6/vjS+QgZndBzwMbA3sA/w4pd8N3J3xf/vhoaIxsyVWt9BNAzr5jyDoiGjpB93A32st7BopxMNfi0lN8vc0maWYXnYWdEyYCXqFaOkHgXMT8CGAZNZ5AzCvLn17YMdCniclbStpAPDeQvo03GSDpIGS1sGjQ66d8d/1/xEElRJKPwicc4GBkmYDl+Grdr2Em2nWknQ38FlgRiHPJOBqPDroE4X0k4F9k6zbge3M7BngD8ltdLmB3Bb/EQSVEmEYgiAIuoho6QdBEHQRofSDIAi6iFD6QRAEXUQo/SAIgi4ilH4QBEEXEUo/CIKgiwilHwRB0EX8f/jezJw4F9LhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "popular_products = pd.DataFrame(newdf.groupby('ProductId')['Rating'].count())\n",
    "most_popular = popular_products.sort_values('Rating', ascending=False)\n",
    "most_popular.head(20).plot(kind = \"bar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Matrixization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sparse matrix is needed for the Factor Matrization method. There needs to be one-hot encoding on customer_id and product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.drop(['Timestamp'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A39HTATAQ9V7YF</td>\n",
       "      <td>205616461</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3JM6GV9MNOF9X</td>\n",
       "      <td>558925278</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1Z513UWSAAO0F</td>\n",
       "      <td>558925278</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1WMRR494NWEWV</td>\n",
       "      <td>733001998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3IAAVS479H7M7</td>\n",
       "      <td>737104473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238223</th>\n",
       "      <td>A1F1CLG22Z98BY</td>\n",
       "      <td>B000F4GINO</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238224</th>\n",
       "      <td>ABNARV2XL4GL7</td>\n",
       "      <td>B000F4GINO</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238225</th>\n",
       "      <td>A2RQFD8Y8F72TV</td>\n",
       "      <td>B000F4GINO</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238226</th>\n",
       "      <td>A1U70HGMKIDBJV</td>\n",
       "      <td>B000F4GINO</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238227</th>\n",
       "      <td>A3PFJBHWWNZKXD</td>\n",
       "      <td>B000F4GINO</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238228 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                UserId   ProductId  Rating\n",
       "0       A39HTATAQ9V7YF   205616461       5\n",
       "1       A3JM6GV9MNOF9X   558925278       3\n",
       "2       A1Z513UWSAAO0F   558925278       5\n",
       "3       A1WMRR494NWEWV   733001998       4\n",
       "4       A3IAAVS479H7M7   737104473       1\n",
       "...                ...         ...     ...\n",
       "238223  A1F1CLG22Z98BY  B000F4GINO       5\n",
       "238224   ABNARV2XL4GL7  B000F4GINO       5\n",
       "238225  A2RQFD8Y8F72TV  B000F4GINO       3\n",
       "238226  A1U70HGMKIDBJV  B000F4GINO       5\n",
       "238227  A3PFJBHWWNZKXD  B000F4GINO       5\n",
       "\n",
       "[238228 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.drop_duplicates(['UserId', 'ProductId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<238228x224116 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 476456 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(handle_unknown = \"ignore\")\n",
    "ohe_cols = [\"UserId\", \"ProductId\"]\n",
    "ohe_features = ohe.fit_transform(ratings[ohe_cols])\n",
    "ohe_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<238228x224116 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 476456 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A39HTATAQ9V7YF</td>\n",
       "      <td>205616461</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3JM6GV9MNOF9X</td>\n",
       "      <td>558925278</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1Z513UWSAAO0F</td>\n",
       "      <td>558925278</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1WMRR494NWEWV</td>\n",
       "      <td>733001998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3IAAVS479H7M7</td>\n",
       "      <td>737104473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UserId  ProductId  Rating\n",
       "0  A39HTATAQ9V7YF  205616461       5\n",
       "1  A3JM6GV9MNOF9X  558925278       3\n",
       "2  A1Z513UWSAAO0F  558925278       5\n",
       "3  A1WMRR494NWEWV  733001998       4\n",
       "4  A3IAAVS479H7M7  737104473       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_feature_names = ohe.get_feature_names()\n",
    "df_ohe = pd.DataFrame(data = ohe_features.toarray(), index=range(len(ratings)), columns=ohe_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 3., 5., ..., 3., 5., 5.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y is the target label needed for the task\n",
    "y = ratings[\"Rating\"].values.astype(\"float32\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack([ohe_features], format=\"csr\", dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elements: 53390706448\n",
      "Non-zero elements: 476456\n",
      "Sparsity: 99.9991 %\n"
     ]
    }
   ],
   "source": [
    "total = X.shape[0] * X.shape[1]\n",
    "non_zero = X.nnz\n",
    "sparsity = (total - non_zero) / total\n",
    "\n",
    "print(\"Total elements:\", total)\n",
    "print(\"Non-zero elements:\", non_zero)\n",
    "print(\"Sparsity:\", round(sparsity*100, 4), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_A00144702V3Q8N2EJ3S2G</th>\n",
       "      <th>x0_A00161083VTAXZ0YOD8GL</th>\n",
       "      <th>x0_A00205921JHJK5X9LNP42</th>\n",
       "      <th>x0_A00222842T0ZYI86C9LHU</th>\n",
       "      <th>x0_A00275441WYR3489IKNAB</th>\n",
       "      <th>x0_A00295401U6S2UG3RAQSZ</th>\n",
       "      <th>x0_A0038640S18JE5Y497U6</th>\n",
       "      <th>x0_A004205218STRNUW6PPPA</th>\n",
       "      <th>x0_A00473363TJ8YSZ3YAGG9</th>\n",
       "      <th>x0_A00507042PSBBTBJBSHDA</th>\n",
       "      <th>...</th>\n",
       "      <th>x1_B000F4EPM0</th>\n",
       "      <th>x1_B000F4EPMK</th>\n",
       "      <th>x1_B000F4EPNE</th>\n",
       "      <th>x1_B000F4EPP2</th>\n",
       "      <th>x1_B000F4EPS4</th>\n",
       "      <th>x1_B000F4GIMA</th>\n",
       "      <th>x1_B000F4GIMK</th>\n",
       "      <th>x1_B000F4GIMU</th>\n",
       "      <th>x1_B000F4GIN4</th>\n",
       "      <th>x1_B000F4GINO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238223</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238224</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238225</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238226</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238227</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238228 rows × 224116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x0_A00144702V3Q8N2EJ3S2G  x0_A00161083VTAXZ0YOD8GL  \\\n",
       "0                            0.0                       0.0   \n",
       "1                            0.0                       0.0   \n",
       "2                            0.0                       0.0   \n",
       "3                            0.0                       0.0   \n",
       "4                            0.0                       0.0   \n",
       "...                          ...                       ...   \n",
       "238223                       0.0                       0.0   \n",
       "238224                       0.0                       0.0   \n",
       "238225                       0.0                       0.0   \n",
       "238226                       0.0                       0.0   \n",
       "238227                       0.0                       0.0   \n",
       "\n",
       "        x0_A00205921JHJK5X9LNP42  x0_A00222842T0ZYI86C9LHU  \\\n",
       "0                            0.0                       0.0   \n",
       "1                            0.0                       0.0   \n",
       "2                            0.0                       0.0   \n",
       "3                            0.0                       0.0   \n",
       "4                            0.0                       0.0   \n",
       "...                          ...                       ...   \n",
       "238223                       0.0                       0.0   \n",
       "238224                       0.0                       0.0   \n",
       "238225                       0.0                       0.0   \n",
       "238226                       0.0                       0.0   \n",
       "238227                       0.0                       0.0   \n",
       "\n",
       "        x0_A00275441WYR3489IKNAB  x0_A00295401U6S2UG3RAQSZ  \\\n",
       "0                            0.0                       0.0   \n",
       "1                            0.0                       0.0   \n",
       "2                            0.0                       0.0   \n",
       "3                            0.0                       0.0   \n",
       "4                            0.0                       0.0   \n",
       "...                          ...                       ...   \n",
       "238223                       0.0                       0.0   \n",
       "238224                       0.0                       0.0   \n",
       "238225                       0.0                       0.0   \n",
       "238226                       0.0                       0.0   \n",
       "238227                       0.0                       0.0   \n",
       "\n",
       "        x0_A0038640S18JE5Y497U6  x0_A004205218STRNUW6PPPA  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "238223                      0.0                       0.0   \n",
       "238224                      0.0                       0.0   \n",
       "238225                      0.0                       0.0   \n",
       "238226                      0.0                       0.0   \n",
       "238227                      0.0                       0.0   \n",
       "\n",
       "        x0_A00473363TJ8YSZ3YAGG9  x0_A00507042PSBBTBJBSHDA  ...  \\\n",
       "0                            0.0                       0.0  ...   \n",
       "1                            0.0                       0.0  ...   \n",
       "2                            0.0                       0.0  ...   \n",
       "3                            0.0                       0.0  ...   \n",
       "4                            0.0                       0.0  ...   \n",
       "...                          ...                       ...  ...   \n",
       "238223                       0.0                       0.0  ...   \n",
       "238224                       0.0                       0.0  ...   \n",
       "238225                       0.0                       0.0  ...   \n",
       "238226                       0.0                       0.0  ...   \n",
       "238227                       0.0                       0.0  ...   \n",
       "\n",
       "        x1_B000F4EPM0  x1_B000F4EPMK  x1_B000F4EPNE  x1_B000F4EPP2  \\\n",
       "0                 0.0            0.0            0.0            0.0   \n",
       "1                 0.0            0.0            0.0            0.0   \n",
       "2                 0.0            0.0            0.0            0.0   \n",
       "3                 0.0            0.0            0.0            0.0   \n",
       "4                 0.0            0.0            0.0            0.0   \n",
       "...               ...            ...            ...            ...   \n",
       "238223            0.0            0.0            0.0            0.0   \n",
       "238224            0.0            0.0            0.0            0.0   \n",
       "238225            0.0            0.0            0.0            0.0   \n",
       "238226            0.0            0.0            0.0            0.0   \n",
       "238227            0.0            0.0            0.0            0.0   \n",
       "\n",
       "        x1_B000F4EPS4  x1_B000F4GIMA  x1_B000F4GIMK  x1_B000F4GIMU  \\\n",
       "0                 0.0            0.0            0.0            0.0   \n",
       "1                 0.0            0.0            0.0            0.0   \n",
       "2                 0.0            0.0            0.0            0.0   \n",
       "3                 0.0            0.0            0.0            0.0   \n",
       "4                 0.0            0.0            0.0            0.0   \n",
       "...               ...            ...            ...            ...   \n",
       "238223            0.0            0.0            0.0            0.0   \n",
       "238224            0.0            0.0            0.0            0.0   \n",
       "238225            0.0            0.0            0.0            0.0   \n",
       "238226            0.0            0.0            0.0            0.0   \n",
       "238227            0.0            0.0            0.0            0.0   \n",
       "\n",
       "        x1_B000F4GIN4  x1_B000F4GINO  \n",
       "0                 0.0            0.0  \n",
       "1                 0.0            0.0  \n",
       "2                 0.0            0.0  \n",
       "3                 0.0            0.0  \n",
       "4                 0.0            0.0  \n",
       "...               ...            ...  \n",
       "238223            0.0            1.0  \n",
       "238224            0.0            1.0  \n",
       "238225            0.0            1.0  \n",
       "238226            0.0            1.0  \n",
       "238227            0.0            1.0  \n",
       "\n",
       "[238228 rows x 224116 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into Training and Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An 80-20 split is done so that data can be split into training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (190582, 224116)\n",
      "Shape of y_train: (190582,) \n",
      "\n",
      "Shape of X_test: (47646, 224116)\n",
      "Shape of y_test: (47646,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=73)           \n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape, \"\\n\")\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to csv.\n",
    "ratings.to_csv(\"fm_preprocessed.csv\", index=False)\n",
    "\n",
    "# save_npz: Save a sparse matrix for X_train and X_test to a file using .npz format.\n",
    "# np.savez: Save array for y_test into a single file in uncompressed .npz format.\n",
    "save_npz(\"X_train.npz\", X_train) \n",
    "save_npz(\"X_test.npz\", X_test)\n",
    "np.savez(\"y_train.npz\", y_train) \n",
    "np.savez(\"y_test.npz\", y_test)\n",
    "\n",
    "# Save the feature dimension to a text file.\n",
    "feature_dim = X.shape[1]\n",
    "with open(\"feature_dim.txt\", \"w\") as f:\n",
    "    f.write(str(feature_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages to load for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack, save_npz, load_npz\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load array and sparse matrices.\n",
    "\n",
    "X_train = load_npz(\"X_train.npz\")\n",
    "X_test = load_npz(\"X_test.npz\")\n",
    "\n",
    "y_train = np.load(\"y_train.npz\")\n",
    "y_test = np.load(\"y_test.npz\")\n",
    "y_train = y_train.f.arr_0\n",
    "y_test = y_test.f.arr_0\n",
    "\n",
    "# Example of sparse matrix for X_test\n",
    "# pd.DataFrame(X_test.todense())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224116"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dim = 0\n",
    "\n",
    "# Read the saved feature dimension.\n",
    "with open(\"feature_dim.txt\", \"r\") as f:\n",
    "    feature_dim = int(f.read())\n",
    "    \n",
    "feature_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data into recordIO-protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Factorization Machine algorithm only supports the recordIO-protobuf format with float 32. Therefore, the data needs to be converted to S3 protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sparse RecordIO file.\n",
    "\n",
    "def write_sparse_recordio_file (filename, X, y=None):\n",
    "    with open(filename, 'wb') as f:\n",
    "        smac.write_spmatrix_to_sparse_tensor (f, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload file to S3.\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-uploading-files.html\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.upload_fileobj\n",
    "\n",
    "def upload_to_s3(filename, bucket, prefix, key):\n",
    "    with open(filename,'rb') as f: # Read in binary mode\n",
    "        boto3.Session().resource('s3').Bucket(bucket).Object(f\"{prefix}/{key}\").upload_fileobj(f)\n",
    "        return f\"s3://{bucket}/{prefix}/{key}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the train and test RecordIO files.\n",
    "\n",
    "write_sparse_recordio_file(\"fm_train.recordio\", X_train, y_train)\n",
    "write_sparse_recordio_file(\"fm_test.recordio\", X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker version: 2.99.0\n",
      "Region: us-east-1\n",
      "Bucket: sagemaker-us-east-1-942306542108\n",
      "train file location: s3://sagemaker-us-east-1-942306542108/fm/fm_train.recordio\n",
      "test file location: s3://sagemaker-us-east-1-942306542108/fm/fm_test.recordio\n",
      "model output location: s3://sagemaker-us-east-1-942306542108/fm/output\n"
     ]
    }
   ],
   "source": [
    "# Uploading the train and test RecordIO files to S3.\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "prefix = \"fm\"\n",
    "train_key = \"fm_train.recordio\"\n",
    "test_key = \"fm_test.recordio\"\n",
    "output_location = f\"s3://{bucket}/{prefix}/output\"\n",
    "\n",
    "train_file_location = upload_to_s3(\"fm_train.recordio\", bucket, prefix, train_key)\n",
    "test_file_location = upload_to_s3(\"fm_test.recordio\", bucket, prefix, test_key)\n",
    "\n",
    "print(\"SageMaker version:\", sagemaker.__version__)\n",
    "print(\"Region:\", region)\n",
    "print(\"Bucket:\", bucket)\n",
    "print(\"train file location:\", train_file_location)\n",
    "print(\"test file location:\", test_file_location)\n",
    "print(\"model output location:\", output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training job and tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fm-job-v5'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = 'fm-job-v5'\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint uri: None\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/aws-samples/amazon-sagemaker-managed-spot-training/blob/main/xgboost_built_in_managed_spot_training_checkpointing/xgboost_built_in_managed_spot_training_checkpointing.ipynb\n",
    "    \n",
    "use_spot_instances = False\n",
    "max_run = 3600                                   # set to 60 mins\n",
    "max_wait = 3600 if use_spot_instances else None  # set to 60 mins (must be equal or greater than max_run)\n",
    "   \n",
    "checkpoint_s3_uri = (f\"s3://{bucket}/{prefix}/checkpoints/{job_name}\" if use_spot_instances\n",
    "                     else None)\n",
    "    \n",
    "print(f\"Checkpoint uri: {checkpoint_s3_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::942306542108:role/service-role/AmazonSageMaker-ExecutionRole-20220622T113338'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:1'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container = sagemaker.image_uris.retrieve(\"factorization-machines\", region=region)\n",
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(    \n",
    "    container,\n",
    "    role,\n",
    "    instance_count = 1,\n",
    "    instance_type = \"ml.m4.xlarge\",   # Or \"ml.c5.xlarge\",\n",
    "    output_path = output_location,\n",
    "    sagemaker_session = sess,\n",
    "    base_job_name = job_name,\n",
    "    use_spot_instances = use_spot_instances,\n",
    "    max_run = max_run,\n",
    "    max_wait = max_wait,\n",
    "    checkpoint_s3_uri = checkpoint_s3_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_dim': 224116,\n",
       " 'num_factors': 64,\n",
       " 'predictor_type': 'regressor',\n",
       " 'epochs': 83,\n",
       " 'mini_batch_size': 1000}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines-hyperparameters.html\n",
    "\n",
    "estimator.set_hyperparameters(\n",
    "    feature_dim = feature_dim,\n",
    "    num_factors = 64,  \n",
    "    predictor_type = \"regressor\",\n",
    "    epochs = 83,      \n",
    "    mini_batch_size = 1000,  \n",
    ")\n",
    "\n",
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-29 07:25:17 Starting - Starting the training job...\n",
      "2022-07-29 07:25:44 Starting - Preparing the instances for trainingProfilerReport-1659079517: InProgress\n",
      ".........\n",
      "2022-07-29 07:27:01 Downloading - Downloading input data...\n",
      "2022-07-29 07:27:42 Training - Downloading the training image......\n",
      "2022-07-29 07:28:42 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/jsonref.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:87: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:120: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:41 INFO 139730530932544] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-conf.json: {'epochs': 1, 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0'}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:41 INFO 139730530932544] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'epochs': '83', 'feature_dim': '224116', 'mini_batch_size': '1000', 'num_factors': '64', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:41 INFO 139730530932544] Final configuration: {'epochs': '83', 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0', 'feature_dim': '224116', 'num_factors': '64', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:41 WARNING 139730530932544] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:41 INFO 139730530932544] Using default worker.\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:41 INFO 139730530932544] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:28:41.531] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:28:41.541] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 21, \"num_examples\": 1, \"num_bytes\": 67700}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:41 INFO 139730530932544] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:41 INFO 139730530932544] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:41 INFO 139730530932544] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:41 INFO 139730530932544] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:41 INFO 139730530932544] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079721.5187328, \"EndTime\": 1659079721.5819063, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 45.88150978088379, \"count\": 1, \"min\": 45.88150978088379, \"max\": 45.88150978088379}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079721.582146, \"EndTime\": 1659079721.5822074, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[07:28:41] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.206339.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[07:28:41] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.206339.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:42 INFO 139730530932544] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=4.347669319948908\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:42 INFO 139730530932544] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=18.902228515625\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:42 INFO 139730530932544] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=4.12823974609375\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:28:45.751] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 3377, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:45 INFO 139730530932544] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.7841042667483373\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:45 INFO 139730530932544] #quality_metric: host=algo-1, epoch=0, train mse <loss>=3.183028034629622\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:45 INFO 139730530932544] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=1.4030059274403837\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079721.5820408, \"EndTime\": 1659079725.752495, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 83.0, \"count\": 1, \"min\": 83, \"max\": 83}, \"update.time\": {\"sum\": 4169.815301895142, \"count\": 1, \"min\": 4169.815301895142, \"max\": 4169.815301895142}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:45 INFO 139730530932544] #progress_metric: host=algo-1, completed 1.2048192771084338 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079721.5826375, \"EndTime\": 1659079725.7528222, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 191582.0, \"count\": 1, \"min\": 191582, \"max\": 191582}, \"Total Batches Seen\": {\"sum\": 192.0, \"count\": 1, \"min\": 192, \"max\": 192}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:45 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=45699.39597129422 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:45 INFO 139730530932544] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.3603451997562972\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:45 INFO 139730530932544] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.8505390625\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:45 INFO 139730530932544] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=1.10081396484375\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:28:48.423] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 2668, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:48 INFO 139730530932544] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.3275266919200321\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:48 INFO 139730530932544] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.762327117760144\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:48 INFO 139730530932544] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=1.0676507427754827\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079725.7526054, \"EndTime\": 1659079728.4238818, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2670.6955432891846, \"count\": 1, \"min\": 2670.6955432891846, \"max\": 2670.6955432891846}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:48 INFO 139730530932544] #progress_metric: host=algo-1, completed 2.4096385542168677 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079725.7531571, \"EndTime\": 1659079728.424094, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 382164.0, \"count\": 1, \"min\": 382164, \"max\": 382164}, \"Total Batches Seen\": {\"sum\": 383.0, \"count\": 1, \"min\": 383, \"max\": 383}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:48 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71350.9904077338 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:48 INFO 139730530932544] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.3534451753851862\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:48 INFO 139730530932544] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.8318138427734374\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:48 INFO 139730530932544] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=1.096617431640625\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:28:51.062] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 2635, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:51 INFO 139730530932544] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.3198554720609423\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:51 INFO 139730530932544] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.742018467129213\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:51 INFO 139730530932544] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=1.0604537350320067\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079728.423942, \"EndTime\": 1659079731.0628853, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2638.5269165039062, \"count\": 1, \"min\": 2638.5269165039062, \"max\": 2638.5269165039062}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:51 INFO 139730530932544] #progress_metric: host=algo-1, completed 3.6144578313253013 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079728.424323, \"EndTime\": 1659079731.0632067, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 572746.0, \"count\": 1, \"min\": 572746, \"max\": 572746}, \"Total Batches Seen\": {\"sum\": 574.0, \"count\": 1, \"min\": 574, \"max\": 574}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:51 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72216.56879447591 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:51 INFO 139730530932544] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.3460528958542082\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:51 INFO 139730530932544] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=1.8118583984375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:51 INFO 139730530932544] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=1.091452880859375\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:28:53.676] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 2609, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:53 INFO 139730530932544] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.3119324338465008\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:53 INFO 139730530932544] #quality_metric: host=algo-1, epoch=3, train mse <loss>=1.7211667109784032\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:53 INFO 139730530932544] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=1.053079867537733\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079731.0629892, \"EndTime\": 1659079733.6776125, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2613.917350769043, \"count\": 1, \"min\": 2613.917350769043, \"max\": 2613.917350769043}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:53 INFO 139730530932544] #progress_metric: host=algo-1, completed 4.819277108433735 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079731.063545, \"EndTime\": 1659079733.677966, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 763328.0, \"count\": 1, \"min\": 763328, \"max\": 763328}, \"Total Batches Seen\": {\"sum\": 765.0, \"count\": 1, \"min\": 765, \"max\": 765}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:53 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72891.74306936543 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:53 INFO 139730530932544] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.3386013737088844\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:53 INFO 139730530932544] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=1.7918536376953125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:53 INFO 139730530932544] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=1.0860518798828125\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:28:56.286] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 2605, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:56 INFO 139730530932544] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=1.3039546692055253\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:56 INFO 139730530932544] #quality_metric: host=algo-1, epoch=4, train mse <loss>=1.700297779342891\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:56 INFO 139730530932544] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=1.0456057304661937\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079733.677723, \"EndTime\": 1659079736.2875373, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2609.1699600219727, \"count\": 1, \"min\": 2609.1699600219727, \"max\": 2609.1699600219727}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:56 INFO 139730530932544] #progress_metric: host=algo-1, completed 6.024096385542169 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079733.6783276, \"EndTime\": 1659079736.2878938, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 953910.0, \"count\": 1, \"min\": 953910, \"max\": 953910}, \"Total Batches Seen\": {\"sum\": 956.0, \"count\": 1, \"min\": 956, \"max\": 956}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:56 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=73026.55712009504 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:56 INFO 139730530932544] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.3311259295177054\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:56 INFO 139730530932544] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.771896240234375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:56 INFO 139730530932544] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=1.0806141357421875\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:28:58.943] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 2653, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:58 INFO 139730530932544] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=1.2958854243329574\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:58 INFO 139730530932544] #quality_metric: host=algo-1, epoch=5, train mse <loss>=1.6793190329986092\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:58 INFO 139730530932544] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=1.0379293813655515\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079736.2876344, \"EndTime\": 1659079738.9443562, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2656.0635566711426, \"count\": 1, \"min\": 2656.0635566711426, \"max\": 2656.0635566711426}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:58 INFO 139730530932544] #progress_metric: host=algo-1, completed 7.228915662650603 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079736.2882526, \"EndTime\": 1659079738.94466, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1144492.0, \"count\": 1, \"min\": 1144492, \"max\": 1144492}, \"Total Batches Seen\": {\"sum\": 1147.0, \"count\": 1, \"min\": 1147, \"max\": 1147}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:58 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71739.92775092453 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:58 INFO 139730530932544] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.3235392799558077\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:58 INFO 139730530932544] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.7517562255859376\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:28:58 INFO 139730530932544] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=1.07513525390625\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:01.770] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 2823, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:01 INFO 139730530932544] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=1.2876291844032248\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:01 INFO 139730530932544] #quality_metric: host=algo-1, epoch=6, train mse <loss>=1.6579889165269142\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:01 INFO 139730530932544] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=1.0299544604236543\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079738.9444516, \"EndTime\": 1659079741.772496, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2827.4664878845215, \"count\": 1, \"min\": 2827.4664878845215, \"max\": 2827.4664878845215}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:01 INFO 139730530932544] #progress_metric: host=algo-1, completed 8.433734939759036 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079738.944984, \"EndTime\": 1659079741.7728415, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1335074.0, \"count\": 1, \"min\": 1335074, \"max\": 1335074}, \"Total Batches Seen\": {\"sum\": 1338.0, \"count\": 1, \"min\": 1338, \"max\": 1338}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:01 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=67390.42842488135 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:01 INFO 139730530932544] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=1.3157412545132592\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:01 INFO 139730530932544] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=1.731175048828125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:01 INFO 139730530932544] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=1.0695804443359376\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:04.618] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 2842, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:04 INFO 139730530932544] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=1.2790914196330607\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:04 INFO 139730530932544] #quality_metric: host=algo-1, epoch=7, train mse <loss>=1.6360748597789185\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:04 INFO 139730530932544] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=1.0216090426619764\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079741.772607, \"EndTime\": 1659079744.6192236, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2845.9978103637695, \"count\": 1, \"min\": 2845.9978103637695, \"max\": 2845.9978103637695}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:04 INFO 139730530932544] #progress_metric: host=algo-1, completed 9.63855421686747 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079741.7731872, \"EndTime\": 1659079744.6195421, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1525656.0, \"count\": 1, \"min\": 1525656, \"max\": 1525656}, \"Total Batches Seen\": {\"sum\": 1529.0, \"count\": 1, \"min\": 1529, \"max\": 1529}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:04 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=66952.38998818431 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:04 INFO 139730530932544] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=1.30764555199352\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:04 INFO 139730530932544] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=1.7099368896484375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:04 INFO 139730530932544] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=1.063940185546875\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:07.613] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 2990, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:07 INFO 139730530932544] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=1.2701953103647143\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:07 INFO 139730530932544] #quality_metric: host=algo-1, epoch=8, train mse <loss>=1.6133961264725132\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:07 INFO 139730530932544] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=1.0128368146806488\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079744.6193247, \"EndTime\": 1659079747.6146557, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2994.7197437286377, \"count\": 1, \"min\": 2994.7197437286377, \"max\": 2994.7197437286377}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:07 INFO 139730530932544] #progress_metric: host=algo-1, completed 10.843373493975903 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079744.6199005, \"EndTime\": 1659079747.6151376, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1716238.0, \"count\": 1, \"min\": 1716238, \"max\": 1716238}, \"Total Batches Seen\": {\"sum\": 1720.0, \"count\": 1, \"min\": 1720, \"max\": 1720}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:07 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=63624.99886998922 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:07 INFO 139730530932544] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=1.2991849251459788\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:07 INFO 139730530932544] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=1.6878814697265625\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:07 INFO 139730530932544] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=1.05798583984375\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:10.250] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 2633, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:10 INFO 139730530932544] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=1.2608875900838221\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:10 INFO 139730530932544] #quality_metric: host=algo-1, epoch=9, train mse <loss>=1.5898375148273887\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:10 INFO 139730530932544] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=1.0036119167467688\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079747.6147785, \"EndTime\": 1659079750.2512627, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2635.8067989349365, \"count\": 1, \"min\": 2635.8067989349365, \"max\": 2635.8067989349365}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:10 INFO 139730530932544] #progress_metric: host=algo-1, completed 12.048192771084338 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079747.615418, \"EndTime\": 1659079750.2515628, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1906820.0, \"count\": 1, \"min\": 1906820, \"max\": 1906820}, \"Total Batches Seen\": {\"sum\": 1911.0, \"count\": 1, \"min\": 1911, \"max\": 1911}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:10 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72291.04830202248 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:10 INFO 139730530932544] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=1.2903076845847419\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:10 INFO 139730530932544] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=1.6648939208984375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:10 INFO 139730530932544] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=1.0517269287109374\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:12.872] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 2618, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:12 INFO 139730530932544] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=1.251138449229182\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:12 INFO 139730530932544] #quality_metric: host=algo-1, epoch=10, train mse <loss>=1.5653474191396024\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:12 INFO 139730530932544] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=0.993926980542887\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079750.2513556, \"EndTime\": 1659079752.8732822, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2621.0532188415527, \"count\": 1, \"min\": 2621.0532188415527, \"max\": 2621.0532188415527}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:12 INFO 139730530932544] #progress_metric: host=algo-1, completed 13.25301204819277 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079750.2521667, \"EndTime\": 1659079752.8737316, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2097402.0, \"count\": 1, \"min\": 2097402, \"max\": 2097402}, \"Total Batches Seen\": {\"sum\": 2102.0, \"count\": 1, \"min\": 2102, \"max\": 2102}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:12 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72693.00763734197 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:12 INFO 139730530932544] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=1.2809727215211297\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:12 INFO 139730530932544] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=1.64089111328125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:12 INFO 139730530932544] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=1.0449796142578125\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:15.500] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 2624, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:15 INFO 139730530932544] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=1.2409381391951104\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:15 INFO 139730530932544] #quality_metric: host=algo-1, epoch=11, train mse <loss>=1.5399274653090231\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:15 INFO 139730530932544] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=0.9837704061937582\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079752.8733845, \"EndTime\": 1659079755.5011623, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2627.0530223846436, \"count\": 1, \"min\": 2627.0530223846436, \"max\": 2627.0530223846436}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:15 INFO 139730530932544] #progress_metric: host=algo-1, completed 14.457831325301205 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079752.8740754, \"EndTime\": 1659079755.5013988, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2287984.0, \"count\": 1, \"min\": 2287984, \"max\": 2287984}, \"Total Batches Seen\": {\"sum\": 2293.0, \"count\": 1, \"min\": 2293, \"max\": 2293}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:15 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72534.82943846133 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:15 INFO 139730530932544] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=1.2711541549875796\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:15 INFO 139730530932544] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=1.6158328857421875\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:15 INFO 139730530932544] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=1.0375731201171876\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:18.162] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 2659, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:18 INFO 139730530932544] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=1.23029200483084\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:18 INFO 139730530932544] #quality_metric: host=algo-1, epoch=12, train mse <loss>=1.5136184171506872\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:18 INFO 139730530932544] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=0.9731371070102871\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079755.5012403, \"EndTime\": 1659079758.16414, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2662.4271869659424, \"count\": 1, \"min\": 2662.4271869659424, \"max\": 2662.4271869659424}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:18 INFO 139730530932544] #progress_metric: host=algo-1, completed 15.662650602409638 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079755.5016756, \"EndTime\": 1659079758.1644506, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2478566.0, \"count\": 1, \"min\": 2478566, \"max\": 2478566}, \"Total Batches Seen\": {\"sum\": 2484.0, \"count\": 1, \"min\": 2484, \"max\": 2484}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:18 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71568.61839472654 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:18 INFO 139730530932544] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=1.2608495458017335\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:18 INFO 139730530932544] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=1.5897415771484376\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:18 INFO 139730530932544] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=1.0295013427734374\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:20.805] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 2638, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:20 INFO 139730530932544] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=1.2192152693751634\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:20 INFO 139730530932544] #quality_metric: host=algo-1, epoch=13, train mse <loss>=1.4864858730775523\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:20 INFO 139730530932544] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=0.9620596201632036\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079758.164238, \"EndTime\": 1659079760.8068101, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2641.216993331909, \"count\": 1, \"min\": 2641.216993331909, \"max\": 2641.216993331909}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:20 INFO 139730530932544] #progress_metric: host=algo-1, completed 16.867469879518072 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079758.1655586, \"EndTime\": 1659079760.8070462, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2669148.0, \"count\": 1, \"min\": 2669148, \"max\": 2669148}, \"Total Batches Seen\": {\"sum\": 2675.0, \"count\": 1, \"min\": 2675, \"max\": 2675}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:20 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72145.04888164453 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:20 INFO 139730530932544] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=1.250076706630812\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:20 INFO 139730530932544] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=1.5626917724609375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:20 INFO 139730530932544] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=1.0208956298828125\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:23.459] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 2649, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:23 INFO 139730530932544] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=1.207728553835789\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:23 INFO 139730530932544] #quality_metric: host=algo-1, epoch=14, train mse <loss>=1.4586082597502863\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:23 INFO 139730530932544] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=0.9505707883185741\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079760.8068893, \"EndTime\": 1659079763.4607046, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2652.738094329834, \"count\": 1, \"min\": 2652.738094329834, \"max\": 2652.738094329834}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:23 INFO 139730530932544] #progress_metric: host=algo-1, completed 18.072289156626507 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079760.8079314, \"EndTime\": 1659079763.460951, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2859730.0, \"count\": 1, \"min\": 2859730, \"max\": 2859730}, \"Total Batches Seen\": {\"sum\": 2866.0, \"count\": 1, \"min\": 2866, \"max\": 2866}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:23 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71831.81870634963 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:23 INFO 139730530932544] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=1.2388624424717973\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:23 INFO 139730530932544] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=1.5347801513671875\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:23 INFO 139730530932544] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=1.0117720947265625\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:26.125] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 2661, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:26 INFO 139730530932544] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=1.1958558407757764\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:26 INFO 139730530932544] #quality_metric: host=algo-1, epoch=15, train mse <loss>=1.4300711919175393\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:26 INFO 139730530932544] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=0.9387146213391688\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079763.4607794, \"EndTime\": 1659079766.1262655, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2664.412498474121, \"count\": 1, \"min\": 2664.412498474121, \"max\": 2664.412498474121}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:26 INFO 139730530932544] #progress_metric: host=algo-1, completed 19.27710843373494 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079763.4618146, \"EndTime\": 1659079766.1266098, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3050312.0, \"count\": 1, \"min\": 3050312, \"max\": 3050312}, \"Total Batches Seen\": {\"sum\": 3057.0, \"count\": 1, \"min\": 3057, \"max\": 3057}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:26 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71513.8679031312 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:26 INFO 139730530932544] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=1.227234141350098\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:26 INFO 139730530932544] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=1.5061036376953125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:26 INFO 139730530932544] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=1.0021911010742188\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:28.792] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 2662, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:28 INFO 139730530932544] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=1.183623599467231\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:28 INFO 139730530932544] #quality_metric: host=algo-1, epoch=16, train mse <loss>=1.400964825215764\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:28 INFO 139730530932544] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=0.9265523499493824\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079766.1263638, \"EndTime\": 1659079768.7934368, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2665.708303451538, \"count\": 1, \"min\": 2665.708303451538, \"max\": 2665.708303451538}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:28 INFO 139730530932544] #progress_metric: host=algo-1, completed 20.481927710843372 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079766.1276977, \"EndTime\": 1659079768.7936995, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3240894.0, \"count\": 1, \"min\": 3240894, \"max\": 3240894}, \"Total Batches Seen\": {\"sum\": 3248.0, \"count\": 1, \"min\": 3248, \"max\": 3248}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:28 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71482.69164415168 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:28 INFO 139730530932544] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=1.2152184410117384\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:28 INFO 139730530932544] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=1.476755859375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:28 INFO 139730530932544] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=0.9922512817382813\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:31.438] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 2641, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:31 INFO 139730530932544] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=1.1710605713248106\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:31 INFO 139730530932544] #quality_metric: host=algo-1, epoch=17, train mse <loss>=1.371382861711592\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:31 INFO 139730530932544] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=0.9141648313512353\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079768.7935376, \"EndTime\": 1659079771.4395566, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2644.869089126587, \"count\": 1, \"min\": 2644.869089126587, \"max\": 2644.869089126587}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:31 INFO 139730530932544] #progress_metric: host=algo-1, completed 21.686746987951807 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079768.7946537, \"EndTime\": 1659079771.4397485, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3431476.0, \"count\": 1, \"min\": 3431476, \"max\": 3431476}, \"Total Batches Seen\": {\"sum\": 3439.0, \"count\": 1, \"min\": 3439, \"max\": 3439}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 19.0, \"count\": 1, \"min\": 19, \"max\": 19}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:31 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72047.34828205005 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:31 INFO 139730530932544] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=1.202841687421915\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:31 INFO 139730530932544] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=1.446828125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:31 INFO 139730530932544] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=0.9820053100585937\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:34.045] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 2603, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:34 INFO 139730530932544] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=1.15819717292236\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:34 INFO 139730530932544] #quality_metric: host=algo-1, epoch=18, train mse <loss>=1.3414206913653468\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:34 INFO 139730530932544] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=0.9016038776817122\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079771.4396203, \"EndTime\": 1659079774.0466013, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2605.9985160827637, \"count\": 1, \"min\": 2605.9985160827637, \"max\": 2605.9985160827637}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:34 INFO 139730530932544] #progress_metric: host=algo-1, completed 22.89156626506024 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079771.4405653, \"EndTime\": 1659079774.0469239, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3622058.0, \"count\": 1, \"min\": 3622058, \"max\": 3622058}, \"Total Batches Seen\": {\"sum\": 3630.0, \"count\": 1, \"min\": 3630, \"max\": 3630}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:34 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=73117.21436767778 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:34 INFO 139730530932544] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=1.1901312850210843\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:34 INFO 139730530932544] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=1.4164124755859375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:34 INFO 139730530932544] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=0.9716198120117188\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:36.676] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 2626, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:36 INFO 139730530932544] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=1.1450648086016915\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:36 INFO 139730530932544] #quality_metric: host=algo-1, epoch=19, train mse <loss>=1.3111734158980284\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:36 INFO 139730530932544] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=0.8888923122545812\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079774.0467093, \"EndTime\": 1659079776.6768231, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2629.498243331909, \"count\": 1, \"min\": 2629.498243331909, \"max\": 2629.498243331909}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:36 INFO 139730530932544] #progress_metric: host=algo-1, completed 24.096385542168676 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079774.0472906, \"EndTime\": 1659079776.6770532, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3812640.0, \"count\": 1, \"min\": 3812640, \"max\": 3812640}, \"Total Batches Seen\": {\"sum\": 3821.0, \"count\": 1, \"min\": 3821, \"max\": 3821}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 21.0, \"count\": 1, \"min\": 21, \"max\": 21}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:36 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72467.55245854794 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:36 INFO 139730530932544] #quality_metric: host=algo-1, epoch=20, batch=0 train rmse <loss>=1.1771156257093278\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:36 INFO 139730530932544] #quality_metric: host=algo-1, epoch=20, batch=0 train mse <loss>=1.3856011962890624\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:36 INFO 139730530932544] #quality_metric: host=algo-1, epoch=20, batch=0 train absolute_loss <loss>=0.9609154052734376\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:39.350] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 2670, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:39 INFO 139730530932544] #quality_metric: host=algo-1, epoch=20, train rmse <loss>=1.1316951321001534\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:39 INFO 139730530932544] #quality_metric: host=algo-1, epoch=20, train mse <loss>=1.2807338720191837\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:39 INFO 139730530932544] #quality_metric: host=algo-1, epoch=20, train absolute_loss <loss>=0.8760428607401424\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079776.6768994, \"EndTime\": 1659079779.3509617, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2673.482894897461, \"count\": 1, \"min\": 2673.482894897461, \"max\": 2673.482894897461}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:39 INFO 139730530932544] #progress_metric: host=algo-1, completed 25.301204819277107 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079776.6774404, \"EndTime\": 1659079779.3512821, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4003222.0, \"count\": 1, \"min\": 4003222, \"max\": 4003222}, \"Total Batches Seen\": {\"sum\": 4012.0, \"count\": 1, \"min\": 4012, \"max\": 4012}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 22.0, \"count\": 1, \"min\": 22, \"max\": 22}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:39 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71268.25372804582 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:39 INFO 139730530932544] #quality_metric: host=algo-1, epoch=21, batch=0 train rmse <loss>=1.1638237485862872\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:39 INFO 139730530932544] #quality_metric: host=algo-1, epoch=21, batch=0 train mse <loss>=1.3544857177734375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:39 INFO 139730530932544] #quality_metric: host=algo-1, epoch=21, batch=0 train absolute_loss <loss>=0.9498707275390625\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:41.981] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 2627, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:41 INFO 139730530932544] #quality_metric: host=algo-1, epoch=21, train rmse <loss>=1.118119622675825\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:41 INFO 139730530932544] #quality_metric: host=algo-1, epoch=21, train mse <loss>=1.2501914906127292\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:41 INFO 139730530932544] #quality_metric: host=algo-1, epoch=21, train absolute_loss <loss>=0.8630774037625777\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079779.351062, \"EndTime\": 1659079781.9825683, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2630.518913269043, \"count\": 1, \"min\": 2630.518913269043, \"max\": 2630.518913269043}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:41 INFO 139730530932544] #progress_metric: host=algo-1, completed 26.50602409638554 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079779.3520186, \"EndTime\": 1659079781.9827983, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4193804.0, \"count\": 1, \"min\": 4193804, \"max\": 4193804}, \"Total Batches Seen\": {\"sum\": 4203.0, \"count\": 1, \"min\": 4203, \"max\": 4203}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:41 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72439.81924165542 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:42 INFO 139730530932544] #quality_metric: host=algo-1, epoch=22, batch=0 train rmse <loss>=1.1502858213083933\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:42 INFO 139730530932544] #quality_metric: host=algo-1, epoch=22, batch=0 train mse <loss>=1.323157470703125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:42 INFO 139730530932544] #quality_metric: host=algo-1, epoch=22, batch=0 train absolute_loss <loss>=0.9386162719726563\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:44.595] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 2609, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:44 INFO 139730530932544] #quality_metric: host=algo-1, epoch=22, train rmse <loss>=1.1043693194372115\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:44 INFO 139730530932544] #quality_metric: host=algo-1, epoch=22, train mse <loss>=1.2196315937142097\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:44 INFO 139730530932544] #quality_metric: host=algo-1, epoch=22, train absolute_loss <loss>=0.8500219774495869\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079781.9826458, \"EndTime\": 1659079784.5958302, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2612.0777130126953, \"count\": 1, \"min\": 2612.0777130126953, \"max\": 2612.0777130126953}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:44 INFO 139730530932544] #progress_metric: host=algo-1, completed 27.710843373493976 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079781.9837227, \"EndTime\": 1659079784.596087, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4384386.0, \"count\": 1, \"min\": 4384386, \"max\": 4384386}, \"Total Batches Seen\": {\"sum\": 4394.0, \"count\": 1, \"min\": 4394, \"max\": 4394}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 24.0, \"count\": 1, \"min\": 24, \"max\": 24}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:44 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72950.3820535376 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:44 INFO 139730530932544] #quality_metric: host=algo-1, epoch=23, batch=0 train rmse <loss>=1.136532577108164\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:44 INFO 139730530932544] #quality_metric: host=algo-1, epoch=23, batch=0 train mse <loss>=1.291706298828125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:44 INFO 139730530932544] #quality_metric: host=algo-1, epoch=23, batch=0 train absolute_loss <loss>=0.9269967041015625\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:47.187] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 2589, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:47 INFO 139730530932544] #quality_metric: host=algo-1, epoch=23, train rmse <loss>=1.09047469682229\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:47 INFO 139730530932544] #quality_metric: host=algo-1, epoch=23, train mse <loss>=1.1891350644096654\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:47 INFO 139730530932544] #quality_metric: host=algo-1, epoch=23, train absolute_loss <loss>=0.8369085623057101\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079784.5959167, \"EndTime\": 1659079787.188896, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2592.515230178833, \"count\": 1, \"min\": 2592.515230178833, \"max\": 2592.515230178833}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:47 INFO 139730530932544] #progress_metric: host=algo-1, completed 28.91566265060241 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079784.5963445, \"EndTime\": 1659079787.1892045, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4574968.0, \"count\": 1, \"min\": 4574968, \"max\": 4574968}, \"Total Batches Seen\": {\"sum\": 4585.0, \"count\": 1, \"min\": 4585, \"max\": 4585}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 25.0, \"count\": 1, \"min\": 25, \"max\": 25}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:47 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=73497.97625839814 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:47 INFO 139730530932544] #quality_metric: host=algo-1, epoch=24, batch=0 train rmse <loss>=1.122595792561402\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:47 INFO 139730530932544] #quality_metric: host=algo-1, epoch=24, batch=0 train mse <loss>=1.2602213134765625\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:47 INFO 139730530932544] #quality_metric: host=algo-1, epoch=24, batch=0 train absolute_loss <loss>=0.9152115478515624\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:49.844] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 2651, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:49 INFO 139730530932544] #quality_metric: host=algo-1, epoch=24, train rmse <loss>=1.076465640833113\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:49 INFO 139730530932544] #quality_metric: host=algo-1, epoch=24, train mse <loss>=1.1587782758942449\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:49 INFO 139730530932544] #quality_metric: host=algo-1, epoch=24, train absolute_loss <loss>=0.823766256122689\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079787.1889925, \"EndTime\": 1659079789.8453453, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2654.9479961395264, \"count\": 1, \"min\": 2654.9479961395264, \"max\": 2654.9479961395264}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:49 INFO 139730530932544] #progress_metric: host=algo-1, completed 30.120481927710845 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079787.1903691, \"EndTime\": 1659079789.8456807, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4765550.0, \"count\": 1, \"min\": 4765550, \"max\": 4765550}, \"Total Batches Seen\": {\"sum\": 4776.0, \"count\": 1, \"min\": 4776, \"max\": 4776}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 26.0, \"count\": 1, \"min\": 26, \"max\": 26}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:49 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71769.09926471942 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:49 INFO 139730530932544] #quality_metric: host=algo-1, epoch=25, batch=0 train rmse <loss>=1.1085073631775073\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:49 INFO 139730530932544] #quality_metric: host=algo-1, epoch=25, batch=0 train mse <loss>=1.22878857421875\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:49 INFO 139730530932544] #quality_metric: host=algo-1, epoch=25, batch=0 train absolute_loss <loss>=0.903232421875\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:52.464] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 2615, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:52 INFO 139730530932544] #quality_metric: host=algo-1, epoch=25, train rmse <loss>=1.0623713378450594\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:52 INFO 139730530932544] #quality_metric: host=algo-1, epoch=25, train mse <loss>=1.1286328594747015\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:52 INFO 139730530932544] #quality_metric: host=algo-1, epoch=25, train absolute_loss <loss>=0.8105822178705825\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079789.845405, \"EndTime\": 1659079792.4653897, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2619.3134784698486, \"count\": 1, \"min\": 2619.3134784698486, \"max\": 2619.3134784698486}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:52 INFO 139730530932544] #progress_metric: host=algo-1, completed 31.325301204819276 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079789.8460371, \"EndTime\": 1659079792.4657595, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4956132.0, \"count\": 1, \"min\": 4956132, \"max\": 4956132}, \"Total Batches Seen\": {\"sum\": 4967.0, \"count\": 1, \"min\": 4967, \"max\": 4967}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 27.0, \"count\": 1, \"min\": 27, \"max\": 27}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:52 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72743.55465912148 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:52 INFO 139730530932544] #quality_metric: host=algo-1, epoch=26, batch=0 train rmse <loss>=1.0942993040283242\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:52 INFO 139730530932544] #quality_metric: host=algo-1, epoch=26, batch=0 train mse <loss>=1.197490966796875\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:52 INFO 139730530932544] #quality_metric: host=algo-1, epoch=26, batch=0 train absolute_loss <loss>=0.8910009155273437\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:55.102] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 2632, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:55 INFO 139730530932544] #quality_metric: host=algo-1, epoch=26, train rmse <loss>=1.0482202443202038\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:55 INFO 139730530932544] #quality_metric: host=algo-1, epoch=26, train mse <loss>=1.0987656806027077\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:55 INFO 139730530932544] #quality_metric: host=algo-1, epoch=26, train absolute_loss <loss>=0.7973267464363138\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079792.465498, \"EndTime\": 1659079795.1028447, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2635.94126701355, \"count\": 1, \"min\": 2635.94126701355, \"max\": 2635.94126701355}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:55 INFO 139730530932544] #progress_metric: host=algo-1, completed 32.53012048192771 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079792.4668658, \"EndTime\": 1659079795.1031532, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5146714.0, \"count\": 1, \"min\": 5146714, \"max\": 5146714}, \"Total Batches Seen\": {\"sum\": 5158.0, \"count\": 1, \"min\": 5158, \"max\": 5158}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:55 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72287.21739279844 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:55 INFO 139730530932544] #quality_metric: host=algo-1, epoch=27, batch=0 train rmse <loss>=1.0800031195701474\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:55 INFO 139730530932544] #quality_metric: host=algo-1, epoch=27, batch=0 train mse <loss>=1.16640673828125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:55 INFO 139730530932544] #quality_metric: host=algo-1, epoch=27, batch=0 train absolute_loss <loss>=0.8785382080078125\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:29:57.764] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 2658, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:57 INFO 139730530932544] #quality_metric: host=algo-1, epoch=27, train rmse <loss>=1.0340400097336158\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:57 INFO 139730530932544] #quality_metric: host=algo-1, epoch=27, train mse <loss>=1.069238741729896\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:57 INFO 139730530932544] #quality_metric: host=algo-1, epoch=27, train absolute_loss <loss>=0.7839964487764848\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079795.1029403, \"EndTime\": 1659079797.7651565, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2661.6244316101074, \"count\": 1, \"min\": 2661.6244316101074, \"max\": 2661.6244316101074}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:57 INFO 139730530932544] #progress_metric: host=algo-1, completed 33.734939759036145 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079795.1034935, \"EndTime\": 1659079797.7655027, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5337296.0, \"count\": 1, \"min\": 5337296, \"max\": 5337296}, \"Total Batches Seen\": {\"sum\": 5349.0, \"count\": 1, \"min\": 5349, \"max\": 5349}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 29.0, \"count\": 1, \"min\": 29, \"max\": 29}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:57 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71587.88518445846 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:57 INFO 139730530932544] #quality_metric: host=algo-1, epoch=28, batch=0 train rmse <loss>=1.06564985766462\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:57 INFO 139730530932544] #quality_metric: host=algo-1, epoch=28, batch=0 train mse <loss>=1.135609619140625\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:29:57 INFO 139730530932544] #quality_metric: host=algo-1, epoch=28, batch=0 train absolute_loss <loss>=0.865866943359375\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:00.411] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 2643, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:00 INFO 139730530932544] #quality_metric: host=algo-1, epoch=28, train rmse <loss>=1.019857489214356\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:00 INFO 139730530932544] #quality_metric: host=algo-1, epoch=28, train mse <loss>=1.04010929830661\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:00 INFO 139730530932544] #quality_metric: host=algo-1, epoch=28, train absolute_loss <loss>=0.7706197257316549\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079797.7652562, \"EndTime\": 1659079800.4125853, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2645.9619998931885, \"count\": 1, \"min\": 2645.9619998931885, \"max\": 2645.9619998931885}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:00 INFO 139730530932544] #progress_metric: host=algo-1, completed 34.93975903614458 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079797.7665875, \"EndTime\": 1659079800.4129136, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5527878.0, \"count\": 1, \"min\": 5527878, \"max\": 5527878}, \"Total Batches Seen\": {\"sum\": 5540.0, \"count\": 1, \"min\": 5540, \"max\": 5540}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:00 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72013.09716025504 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:00 INFO 139730530932544] #quality_metric: host=algo-1, epoch=29, batch=0 train rmse <loss>=1.0512695194568624\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:00 INFO 139730530932544] #quality_metric: host=algo-1, epoch=29, batch=0 train mse <loss>=1.1051676025390624\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:00 INFO 139730530932544] #quality_metric: host=algo-1, epoch=29, batch=0 train absolute_loss <loss>=0.853076904296875\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:03.292] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 2875, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:03 INFO 139730530932544] #quality_metric: host=algo-1, epoch=29, train rmse <loss>=1.00569872949936\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:03 INFO 139730530932544] #quality_metric: host=algo-1, epoch=29, train mse <loss>=1.011429934516627\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:03 INFO 139730530932544] #quality_metric: host=algo-1, epoch=29, train absolute_loss <loss>=0.7572082819913695\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079800.4126937, \"EndTime\": 1659079803.2935936, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2879.237413406372, \"count\": 1, \"min\": 2879.237413406372, \"max\": 2879.237413406372}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:03 INFO 139730530932544] #progress_metric: host=algo-1, completed 36.144578313253014 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079800.4143167, \"EndTime\": 1659079803.2939086, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5718460.0, \"count\": 1, \"min\": 5718460, \"max\": 5718460}, \"Total Batches Seen\": {\"sum\": 5731.0, \"count\": 1, \"min\": 5731, \"max\": 5731}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:03 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=66180.24181521697 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:03 INFO 139730530932544] #quality_metric: host=algo-1, epoch=30, batch=0 train rmse <loss>=1.0368911758457948\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:03 INFO 139730530932544] #quality_metric: host=algo-1, epoch=30, batch=0 train mse <loss>=1.075143310546875\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:03 INFO 139730530932544] #quality_metric: host=algo-1, epoch=30, batch=0 train absolute_loss <loss>=0.8402666625976563\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:06.260] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 2963, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:06 INFO 139730530932544] #quality_metric: host=algo-1, epoch=30, train rmse <loss>=0.9915889143696212\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:06 INFO 139730530932544] #quality_metric: host=algo-1, epoch=30, train mse <loss>=0.9832485751007239\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:06 INFO 139730530932544] #quality_metric: host=algo-1, epoch=30, train absolute_loss <loss>=0.7437913537150278\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079803.2936983, \"EndTime\": 1659079806.2617326, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2966.752767562866, \"count\": 1, \"min\": 2966.752767562866, \"max\": 2966.752767562866}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:06 INFO 139730530932544] #progress_metric: host=algo-1, completed 37.34939759036145 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079803.294945, \"EndTime\": 1659079806.262322, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 30, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5909042.0, \"count\": 1, \"min\": 5909042, \"max\": 5909042}, \"Total Batches Seen\": {\"sum\": 5922.0, \"count\": 1, \"min\": 5922, \"max\": 5922}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 32.0, \"count\": 1, \"min\": 32, \"max\": 32}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:06 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=64219.56001054045 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:06 INFO 139730530932544] #quality_metric: host=algo-1, epoch=31, batch=0 train rmse <loss>=1.0225426073220922\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:06 INFO 139730530932544] #quality_metric: host=algo-1, epoch=31, batch=0 train mse <loss>=1.0455933837890625\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:06 INFO 139730530932544] #quality_metric: host=algo-1, epoch=31, batch=0 train absolute_loss <loss>=0.8272821044921875\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:09.068] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 2802, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:09 INFO 139730530932544] #quality_metric: host=algo-1, epoch=31, train rmse <loss>=0.9775523174183794\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:09 INFO 139730530932544] #quality_metric: host=algo-1, epoch=31, train mse <loss>=0.9556085332900441\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:09 INFO 139730530932544] #quality_metric: host=algo-1, epoch=31, train absolute_loss <loss>=0.7303927487677929\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079806.2619593, \"EndTime\": 1659079809.0692916, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2806.283473968506, \"count\": 1, \"min\": 2806.283473968506, \"max\": 2806.283473968506}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:09 INFO 139730530932544] #progress_metric: host=algo-1, completed 38.55421686746988 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079806.2629755, \"EndTime\": 1659079809.0697389, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 31, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6099624.0, \"count\": 1, \"min\": 6099624, \"max\": 6099624}, \"Total Batches Seen\": {\"sum\": 6113.0, \"count\": 1, \"min\": 6113, \"max\": 6113}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:09 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=67896.66510560283 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:09 INFO 139730530932544] #quality_metric: host=algo-1, epoch=32, batch=0 train rmse <loss>=1.0082500564193049\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:09 INFO 139730530932544] #quality_metric: host=algo-1, epoch=32, batch=0 train mse <loss>=1.0165681762695313\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:09 INFO 139730530932544] #quality_metric: host=algo-1, epoch=32, batch=0 train absolute_loss <loss>=0.814361083984375\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:11.768] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 2695, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:11 INFO 139730530932544] #quality_metric: host=algo-1, epoch=32, train rmse <loss>=0.9636121228102357\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:11 INFO 139730530932544] #quality_metric: host=algo-1, epoch=32, train mse <loss>=0.9285483232268488\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:11 INFO 139730530932544] #quality_metric: host=algo-1, epoch=32, train absolute_loss <loss>=0.7170754621415862\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079809.069386, \"EndTime\": 1659079811.7692232, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2698.686122894287, \"count\": 1, \"min\": 2698.686122894287, \"max\": 2698.686122894287}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:11 INFO 139730530932544] #progress_metric: host=algo-1, completed 39.75903614457831 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079809.0704248, \"EndTime\": 1659079811.7695696, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 32, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6290206.0, \"count\": 1, \"min\": 6290206, \"max\": 6290206}, \"Total Batches Seen\": {\"sum\": 6304.0, \"count\": 1, \"min\": 6304, \"max\": 6304}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 34.0, \"count\": 1, \"min\": 34, \"max\": 34}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:11 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=70604.80937027231 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:11 INFO 139730530932544] #quality_metric: host=algo-1, epoch=33, batch=0 train rmse <loss>=0.9940380441918615\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:11 INFO 139730530932544] #quality_metric: host=algo-1, epoch=33, batch=0 train mse <loss>=0.9881116333007812\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:11 INFO 139730530932544] #quality_metric: host=algo-1, epoch=33, batch=0 train absolute_loss <loss>=0.8015650024414063\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:14.456] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 2684, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:14 INFO 139730530932544] #quality_metric: host=algo-1, epoch=33, train rmse <loss>=0.9497902695379039\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:14 INFO 139730530932544] #quality_metric: host=algo-1, epoch=33, train mse <loss>=0.9021015561088842\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:14 INFO 139730530932544] #quality_metric: host=algo-1, epoch=33, train absolute_loss <loss>=0.7038599150492882\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079811.769346, \"EndTime\": 1659079814.4572787, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2686.631917953491, \"count\": 1, \"min\": 2686.631917953491, \"max\": 2686.631917953491}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:14 INFO 139730530932544] #progress_metric: host=algo-1, completed 40.963855421686745 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079811.7706156, \"EndTime\": 1659079814.4575357, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 33, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6480788.0, \"count\": 1, \"min\": 6480788, \"max\": 6480788}, \"Total Batches Seen\": {\"sum\": 6495.0, \"count\": 1, \"min\": 6495, \"max\": 6495}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 35.0, \"count\": 1, \"min\": 35, \"max\": 35}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:14 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=70925.7219266881 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:14 INFO 139730530932544] #quality_metric: host=algo-1, epoch=34, batch=0 train rmse <loss>=0.979929165518403\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:14 INFO 139730530932544] #quality_metric: host=algo-1, epoch=34, batch=0 train mse <loss>=0.9602611694335937\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:14 INFO 139730530932544] #quality_metric: host=algo-1, epoch=34, batch=0 train absolute_loss <loss>=0.788843505859375\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:17.105] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 2645, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:17 INFO 139730530932544] #quality_metric: host=algo-1, epoch=34, train rmse <loss>=0.9361072717325878\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:17 INFO 139730530932544] #quality_metric: host=algo-1, epoch=34, train mse <loss>=0.876296824190629\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:17 INFO 139730530932544] #quality_metric: host=algo-1, epoch=34, train absolute_loss <loss>=0.6907654882301211\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079814.4573565, \"EndTime\": 1659079817.1074922, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2648.765802383423, \"count\": 1, \"min\": 2648.765802383423, \"max\": 2648.765802383423}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:17 INFO 139730530932544] #progress_metric: host=algo-1, completed 42.16867469879518 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079814.4586906, \"EndTime\": 1659079817.1078262, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 34, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6671370.0, \"count\": 1, \"min\": 6671370, \"max\": 6671370}, \"Total Batches Seen\": {\"sum\": 6686.0, \"count\": 1, \"min\": 6686, \"max\": 6686}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 36.0, \"count\": 1, \"min\": 36, \"max\": 36}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:17 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71937.06549948754 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:17 INFO 139730530932544] #quality_metric: host=algo-1, epoch=35, batch=0 train rmse <loss>=0.9659443052675999\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:17 INFO 139730530932544] #quality_metric: host=algo-1, epoch=35, batch=0 train mse <loss>=0.9330484008789063\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:17 INFO 139730530932544] #quality_metric: host=algo-1, epoch=35, batch=0 train absolute_loss <loss>=0.7761454467773438\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:19.770] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 2658, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:19 INFO 139730530932544] #quality_metric: host=algo-1, epoch=35, train rmse <loss>=0.9225820448731665\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:19 INFO 139730530932544] #quality_metric: host=algo-1, epoch=35, train mse <loss>=0.8511576295223535\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:19 INFO 139730530932544] #quality_metric: host=algo-1, epoch=35, train absolute_loss <loss>=0.6778013177841746\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079817.107615, \"EndTime\": 1659079819.7709997, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2661.761999130249, \"count\": 1, \"min\": 2661.761999130249, \"max\": 2661.761999130249}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:19 INFO 139730530932544] #progress_metric: host=algo-1, completed 43.373493975903614 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079817.1092086, \"EndTime\": 1659079819.7712898, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 35, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6861952.0, \"count\": 1, \"min\": 6861952, \"max\": 6861952}, \"Total Batches Seen\": {\"sum\": 6877.0, \"count\": 1, \"min\": 6877, \"max\": 6877}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:19 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71586.91711090633 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:19 INFO 139730530932544] #quality_metric: host=algo-1, epoch=36, batch=0 train rmse <loss>=0.9521025509776376\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:19 INFO 139730530932544] #quality_metric: host=algo-1, epoch=36, batch=0 train mse <loss>=0.906499267578125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:19 INFO 139730530932544] #quality_metric: host=algo-1, epoch=36, batch=0 train absolute_loss <loss>=0.763471923828125\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:22.550] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 2775, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:22 INFO 139730530932544] #quality_metric: host=algo-1, epoch=36, train rmse <loss>=0.9092318004967844\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:22 INFO 139730530932544] #quality_metric: host=algo-1, epoch=36, train mse <loss>=0.8267024670346245\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:22 INFO 139730530932544] #quality_metric: host=algo-1, epoch=36, train absolute_loss <loss>=0.6649889404935987\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079819.771086, \"EndTime\": 1659079822.5517476, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2779.3846130371094, \"count\": 1, \"min\": 2779.3846130371094, \"max\": 2779.3846130371094}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:22 INFO 139730530932544] #progress_metric: host=algo-1, completed 44.57831325301205 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079819.7723253, \"EndTime\": 1659079822.5520577, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 36, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7052534.0, \"count\": 1, \"min\": 7052534, \"max\": 7052534}, \"Total Batches Seen\": {\"sum\": 7068.0, \"count\": 1, \"min\": 7068, \"max\": 7068}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 38.0, \"count\": 1, \"min\": 38, \"max\": 38}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:22 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=68558.0283816033 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:22 INFO 139730530932544] #quality_metric: host=algo-1, epoch=37, batch=0 train rmse <loss>=0.9384208693477271\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:22 INFO 139730530932544] #quality_metric: host=algo-1, epoch=37, batch=0 train mse <loss>=0.8806337280273437\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:22 INFO 139730530932544] #quality_metric: host=algo-1, epoch=37, batch=0 train absolute_loss <loss>=0.7507982177734375\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:25.226] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 2671, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:25 INFO 139730530932544] #quality_metric: host=algo-1, epoch=37, train rmse <loss>=0.8960719148739681\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:25 INFO 139730530932544] #quality_metric: host=algo-1, epoch=37, train mse <loss>=0.8029448766258999\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:25 INFO 139730530932544] #quality_metric: host=algo-1, epoch=37, train absolute_loss <loss>=0.6523627482309391\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079822.5518477, \"EndTime\": 1659079825.2270873, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2674.0143299102783, \"count\": 1, \"min\": 2674.0143299102783, \"max\": 2674.0143299102783}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:25 INFO 139730530932544] #progress_metric: host=algo-1, completed 45.78313253012048 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079822.553043, \"EndTime\": 1659079825.2273214, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 37, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7243116.0, \"count\": 1, \"min\": 7243116, \"max\": 7243116}, \"Total Batches Seen\": {\"sum\": 7259.0, \"count\": 1, \"min\": 7259, \"max\": 7259}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 39.0, \"count\": 1, \"min\": 39, \"max\": 39}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:25 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71261.4491930255 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:25 INFO 139730530932544] #quality_metric: host=algo-1, epoch=38, batch=0 train rmse <loss>=0.9249145798291152\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:25 INFO 139730530932544] #quality_metric: host=algo-1, epoch=38, batch=0 train mse <loss>=0.8554669799804687\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:25 INFO 139730530932544] #quality_metric: host=algo-1, epoch=38, batch=0 train absolute_loss <loss>=0.738199462890625\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:27.894] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 2665, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:27 INFO 139730530932544] #quality_metric: host=algo-1, epoch=38, train rmse <loss>=0.8831158744345136\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:27 INFO 139730530932544] #quality_metric: host=algo-1, epoch=38, train mse <loss>=0.7798936476782354\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:27 INFO 139730530932544] #quality_metric: host=algo-1, epoch=38, train absolute_loss <loss>=0.6399333448160381\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079825.2271652, \"EndTime\": 1659079827.8955343, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2667.9165363311768, \"count\": 1, \"min\": 2667.9165363311768, \"max\": 2667.9165363311768}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:27 INFO 139730530932544] #progress_metric: host=algo-1, completed 46.98795180722892 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079825.2275817, \"EndTime\": 1659079827.8959196, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 38, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7433698.0, \"count\": 1, \"min\": 7433698, \"max\": 7433698}, \"Total Batches Seen\": {\"sum\": 7450.0, \"count\": 1, \"min\": 7450, \"max\": 7450}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 40.0, \"count\": 1, \"min\": 40, \"max\": 40}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:27 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71419.22095505298 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:27 INFO 139730530932544] #quality_metric: host=algo-1, epoch=39, batch=0 train rmse <loss>=0.9115970355773638\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:27 INFO 139730530932544] #quality_metric: host=algo-1, epoch=39, batch=0 train mse <loss>=0.8310091552734375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:27 INFO 139730530932544] #quality_metric: host=algo-1, epoch=39, batch=0 train absolute_loss <loss>=0.7257492065429687\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:30.465] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 2566, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:30 INFO 139730530932544] #quality_metric: host=algo-1, epoch=39, train rmse <loss>=0.8703752236616731\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:30 INFO 139730530932544] #quality_metric: host=algo-1, epoch=39, train mse <loss>=0.7575530299641074\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:30 INFO 139730530932544] #quality_metric: host=algo-1, epoch=39, train absolute_loss <loss>=0.6277284616200711\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079827.895633, \"EndTime\": 1659079830.4663131, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2570.0016021728516, \"count\": 1, \"min\": 2570.0016021728516, \"max\": 2570.0016021728516}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:30 INFO 139730530932544] #progress_metric: host=algo-1, completed 48.19277108433735 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079827.8962727, \"EndTime\": 1659079830.4666302, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 39, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7624280.0, \"count\": 1, \"min\": 7624280, \"max\": 7624280}, \"Total Batches Seen\": {\"sum\": 7641.0, \"count\": 1, \"min\": 7641, \"max\": 7641}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 41.0, \"count\": 1, \"min\": 41, \"max\": 41}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:30 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=74140.95343163035 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:30 INFO 139730530932544] #quality_metric: host=algo-1, epoch=40, batch=0 train rmse <loss>=0.8984797884069409\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:30 INFO 139730530932544] #quality_metric: host=algo-1, epoch=40, batch=0 train mse <loss>=0.8072659301757813\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:30 INFO 139730530932544] #quality_metric: host=algo-1, epoch=40, batch=0 train absolute_loss <loss>=0.7133748168945313\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:33.156] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 2686, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:33 INFO 139730530932544] #quality_metric: host=algo-1, epoch=40, train rmse <loss>=0.8578595823958803\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:33 INFO 139730530932544] #quality_metric: host=algo-1, epoch=40, train mse <loss>=0.7359230631084342\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:33 INFO 139730530932544] #quality_metric: host=algo-1, epoch=40, train absolute_loss <loss>=0.615772453268161\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079830.4664156, \"EndTime\": 1659079833.1580343, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2690.995931625366, \"count\": 1, \"min\": 2690.995931625366, \"max\": 2690.995931625366}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:33 INFO 139730530932544] #progress_metric: host=algo-1, completed 49.397590361445786 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079830.467004, \"EndTime\": 1659079833.1582768, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 40, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7814862.0, \"count\": 1, \"min\": 7814862, \"max\": 7814862}, \"Total Batches Seen\": {\"sum\": 7832.0, \"count\": 1, \"min\": 7832, \"max\": 7832}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 42.0, \"count\": 1, \"min\": 42, \"max\": 42}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:33 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=70811.32168934713 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:33 INFO 139730530932544] #quality_metric: host=algo-1, epoch=41, batch=0 train rmse <loss>=0.8855724970102321\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:33 INFO 139730530932544] #quality_metric: host=algo-1, epoch=41, batch=0 train mse <loss>=0.7842386474609375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:33 INFO 139730530932544] #quality_metric: host=algo-1, epoch=41, batch=0 train absolute_loss <loss>=0.7010673217773438\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:35.791] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 2631, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:35 INFO 139730530932544] #quality_metric: host=algo-1, epoch=41, train rmse <loss>=0.8455766366986227\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:35 INFO 139730530932544] #quality_metric: host=algo-1, epoch=41, train mse <loss>=0.7149998485305546\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:35 INFO 139730530932544] #quality_metric: host=algo-1, epoch=41, train absolute_loss <loss>=0.6040321399628804\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079833.158115, \"EndTime\": 1659079835.7926989, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2633.417844772339, \"count\": 1, \"min\": 2633.417844772339, \"max\": 2633.417844772339}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:35 INFO 139730530932544] #progress_metric: host=algo-1, completed 50.602409638554214 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079833.1592505, \"EndTime\": 1659079835.7929482, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 41, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8005444.0, \"count\": 1, \"min\": 8005444, \"max\": 8005444}, \"Total Batches Seen\": {\"sum\": 8023.0, \"count\": 1, \"min\": 8023, \"max\": 8023}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:35 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72359.46500193309 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:35 INFO 139730530932544] #quality_metric: host=algo-1, epoch=42, batch=0 train rmse <loss>=0.8728834263945093\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:35 INFO 139730530932544] #quality_metric: host=algo-1, epoch=42, batch=0 train mse <loss>=0.7619254760742188\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:35 INFO 139730530932544] #quality_metric: host=algo-1, epoch=42, batch=0 train absolute_loss <loss>=0.6889837646484375\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:38.483] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 2684, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:38 INFO 139730530932544] #quality_metric: host=algo-1, epoch=42, train rmse <loss>=0.8335322076678437\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:38 INFO 139730530932544] #quality_metric: host=algo-1, epoch=42, train mse <loss>=0.6947759412196294\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:38 INFO 139730530932544] #quality_metric: host=algo-1, epoch=42, train absolute_loss <loss>=0.5924936355670709\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079835.7927794, \"EndTime\": 1659079838.4838827, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2690.6230449676514, \"count\": 1, \"min\": 2690.6230449676514, \"max\": 2690.6230449676514}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:38 INFO 139730530932544] #progress_metric: host=algo-1, completed 51.80722891566265 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079835.7932208, \"EndTime\": 1659079838.4841912, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 42, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8196026.0, \"count\": 1, \"min\": 8196026, \"max\": 8196026}, \"Total Batches Seen\": {\"sum\": 8214.0, \"count\": 1, \"min\": 8214, \"max\": 8214}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 44.0, \"count\": 1, \"min\": 44, \"max\": 44}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:38 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=70818.58009923794 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:38 INFO 139730530932544] #quality_metric: host=algo-1, epoch=43, batch=0 train rmse <loss>=0.8604190745716408\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:38 INFO 139730530932544] #quality_metric: host=algo-1, epoch=43, batch=0 train mse <loss>=0.7403209838867187\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:38 INFO 139730530932544] #quality_metric: host=algo-1, epoch=43, batch=0 train absolute_loss <loss>=0.6770780029296875\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:41.119] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 2632, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:41 INFO 139730530932544] #quality_metric: host=algo-1, epoch=43, train rmse <loss>=0.8217303884518445\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:41 INFO 139730530932544] #quality_metric: host=algo-1, epoch=43, train mse <loss>=0.6752408313052193\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:41 INFO 139730530932544] #quality_metric: host=algo-1, epoch=43, train absolute_loss <loss>=0.5811615702843791\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079838.4839773, \"EndTime\": 1659079841.1200473, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2635.472059249878, \"count\": 1, \"min\": 2635.472059249878, \"max\": 2635.472059249878}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:41 INFO 139730530932544] #progress_metric: host=algo-1, completed 53.01204819277108 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079838.4845355, \"EndTime\": 1659079841.1203697, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 43, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8386608.0, \"count\": 1, \"min\": 8386608, \"max\": 8386608}, \"Total Batches Seen\": {\"sum\": 8405.0, \"count\": 1, \"min\": 8405, \"max\": 8405}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:41 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72299.73799519708 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:41 INFO 139730530932544] #quality_metric: host=algo-1, epoch=44, batch=0 train rmse <loss>=0.8481843473041216\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:41 INFO 139730530932544] #quality_metric: host=algo-1, epoch=44, batch=0 train mse <loss>=0.7194166870117188\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:41 INFO 139730530932544] #quality_metric: host=algo-1, epoch=44, batch=0 train absolute_loss <loss>=0.66522314453125\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:43.749] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 2625, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:43 INFO 139730530932544] #quality_metric: host=algo-1, epoch=44, train rmse <loss>=0.8101736016998455\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:43 INFO 139730530932544] #quality_metric: host=algo-1, epoch=44, train mse <loss>=0.6563812648912999\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:43 INFO 139730530932544] #quality_metric: host=algo-1, epoch=44, train absolute_loss <loss>=0.5700563002980816\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079841.1201534, \"EndTime\": 1659079843.7500222, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2629.2717456817627, \"count\": 1, \"min\": 2629.2717456817627, \"max\": 2629.2717456817627}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:43 INFO 139730530932544] #progress_metric: host=algo-1, completed 54.21686746987952 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079841.1207137, \"EndTime\": 1659079843.7503245, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 44, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8577190.0, \"count\": 1, \"min\": 8577190, \"max\": 8577190}, \"Total Batches Seen\": {\"sum\": 8596.0, \"count\": 1, \"min\": 8596, \"max\": 8596}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 46.0, \"count\": 1, \"min\": 46, \"max\": 46}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:43 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72470.85716730978 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:43 INFO 139730530932544] #quality_metric: host=algo-1, epoch=45, batch=0 train rmse <loss>=0.836182973596109\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:43 INFO 139730530932544] #quality_metric: host=algo-1, epoch=45, batch=0 train mse <loss>=0.6992019653320313\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:43 INFO 139730530932544] #quality_metric: host=algo-1, epoch=45, batch=0 train absolute_loss <loss>=0.6534974365234375\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:46.402] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 2650, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:46 INFO 139730530932544] #quality_metric: host=algo-1, epoch=45, train rmse <loss>=0.7988628068107506\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:46 INFO 139730530932544] #quality_metric: host=algo-1, epoch=45, train mse <loss>=0.6381817841055506\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:46 INFO 139730530932544] #quality_metric: host=algo-1, epoch=45, train absolute_loss <loss>=0.5591889496648499\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079843.7501092, \"EndTime\": 1659079846.404018, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2653.348445892334, \"count\": 1, \"min\": 2653.348445892334, \"max\": 2653.348445892334}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:46 INFO 139730530932544] #progress_metric: host=algo-1, completed 55.42168674698795 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079843.7506385, \"EndTime\": 1659079846.4043348, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 45, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8767772.0, \"count\": 1, \"min\": 8767772, \"max\": 8767772}, \"Total Batches Seen\": {\"sum\": 8787.0, \"count\": 1, \"min\": 8787, \"max\": 8787}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 47.0, \"count\": 1, \"min\": 47, \"max\": 47}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:46 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71812.90427073404 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:46 INFO 139730530932544] #quality_metric: host=algo-1, epoch=46, batch=0 train rmse <loss>=0.8244169637253499\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:46 INFO 139730530932544] #quality_metric: host=algo-1, epoch=46, batch=0 train mse <loss>=0.679663330078125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:46 INFO 139730530932544] #quality_metric: host=algo-1, epoch=46, batch=0 train absolute_loss <loss>=0.6418770751953125\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:49.031] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 2624, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:49 INFO 139730530932544] #quality_metric: host=algo-1, epoch=46, train rmse <loss>=0.7877976046095171\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:49 INFO 139730530932544] #quality_metric: host=algo-1, epoch=46, train mse <loss>=0.6206250658284931\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:49 INFO 139730530932544] #quality_metric: host=algo-1, epoch=46, train absolute_loss <loss>=0.5485709341957931\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079846.4040923, \"EndTime\": 1659079849.0323691, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2627.6490688323975, \"count\": 1, \"min\": 2627.6490688323975, \"max\": 2627.6490688323975}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:49 INFO 139730530932544] #progress_metric: host=algo-1, completed 56.626506024096386 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079846.4046865, \"EndTime\": 1659079849.0326004, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 46, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8958354.0, \"count\": 1, \"min\": 8958354, \"max\": 8958354}, \"Total Batches Seen\": {\"sum\": 8978.0, \"count\": 1, \"min\": 8978, \"max\": 8978}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 48.0, \"count\": 1, \"min\": 48, \"max\": 48}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:49 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72518.4376260338 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:49 INFO 139730530932544] #quality_metric: host=algo-1, epoch=47, batch=0 train rmse <loss>=0.812887077268808\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:49 INFO 139730530932544] #quality_metric: host=algo-1, epoch=47, batch=0 train mse <loss>=0.660785400390625\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:49 INFO 139730530932544] #quality_metric: host=algo-1, epoch=47, batch=0 train absolute_loss <loss>=0.6305108032226563\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:51.709] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 2674, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:51 INFO 139730530932544] #quality_metric: host=algo-1, epoch=47, train rmse <loss>=0.7769764128103143\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:51 INFO 139730530932544] #quality_metric: host=algo-1, epoch=47, train mse <loss>=0.6036923460635839\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:51 INFO 139730530932544] #quality_metric: host=algo-1, epoch=47, train absolute_loss <loss>=0.538209779749366\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079849.0324461, \"EndTime\": 1659079851.7104416, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2677.541494369507, \"count\": 1, \"min\": 2677.541494369507, \"max\": 2677.541494369507}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:51 INFO 139730530932544] #progress_metric: host=algo-1, completed 57.83132530120482 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079849.0328624, \"EndTime\": 1659079851.7107465, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 47, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9148936.0, \"count\": 1, \"min\": 9148936, \"max\": 9148936}, \"Total Batches Seen\": {\"sum\": 9169.0, \"count\": 1, \"min\": 9169, \"max\": 9169}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 49.0, \"count\": 1, \"min\": 49, \"max\": 49}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:51 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71164.68733314631 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:51 INFO 139730530932544] #quality_metric: host=algo-1, epoch=48, batch=0 train rmse <loss>=0.8015926910128087\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:51 INFO 139730530932544] #quality_metric: host=algo-1, epoch=48, batch=0 train mse <loss>=0.6425508422851562\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:51 INFO 139730530932544] #quality_metric: host=algo-1, epoch=48, batch=0 train absolute_loss <loss>=0.6193793334960938\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:54.304] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 2591, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:54 INFO 139730530932544] #quality_metric: host=algo-1, epoch=48, train rmse <loss>=0.7663965718220143\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:54 INFO 139730530932544] #quality_metric: host=algo-1, epoch=48, train mse <loss>=0.5873637053005358\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:54 INFO 139730530932544] #quality_metric: host=algo-1, epoch=48, train absolute_loss <loss>=0.5281252899968811\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079851.7105417, \"EndTime\": 1659079854.3056273, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2594.4173336029053, \"count\": 1, \"min\": 2594.4173336029053, \"max\": 2594.4173336029053}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:54 INFO 139730530932544] #progress_metric: host=algo-1, completed 59.036144578313255 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079851.7111726, \"EndTime\": 1659079854.305936, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 48, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9339518.0, \"count\": 1, \"min\": 9339518, \"max\": 9339518}, \"Total Batches Seen\": {\"sum\": 9360.0, \"count\": 1, \"min\": 9360, \"max\": 9360}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 50.0, \"count\": 1, \"min\": 50, \"max\": 50}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:54 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=73444.10159733066 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:54 INFO 139730530932544] #quality_metric: host=algo-1, epoch=49, batch=0 train rmse <loss>=0.7905320087976159\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:54 INFO 139730530932544] #quality_metric: host=algo-1, epoch=49, batch=0 train mse <loss>=0.6249408569335938\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:54 INFO 139730530932544] #quality_metric: host=algo-1, epoch=49, batch=0 train absolute_loss <loss>=0.6083765258789062\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:56.960] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 2651, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:56 INFO 139730530932544] #quality_metric: host=algo-1, epoch=49, train rmse <loss>=0.7560545942237141\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:56 INFO 139730530932544] #quality_metric: host=algo-1, epoch=49, train mse <loss>=0.571618549446785\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:56 INFO 139730530932544] #quality_metric: host=algo-1, epoch=49, train absolute_loss <loss>=0.5183254546320251\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079854.305726, \"EndTime\": 1659079856.9608731, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2654.256820678711, \"count\": 1, \"min\": 2654.256820678711, \"max\": 2654.256820678711}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:56 INFO 139730530932544] #progress_metric: host=algo-1, completed 60.24096385542169 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079854.3065846, \"EndTime\": 1659079856.9611135, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 49, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9530100.0, \"count\": 1, \"min\": 9530100, \"max\": 9530100}, \"Total Batches Seen\": {\"sum\": 9551.0, \"count\": 1, \"min\": 9551, \"max\": 9551}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 51.0, \"count\": 1, \"min\": 51, \"max\": 51}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:56 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71791.43997279077 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:56 INFO 139730530932544] #quality_metric: host=algo-1, epoch=50, batch=0 train rmse <loss>=0.7797019819546841\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:56 INFO 139730530932544] #quality_metric: host=algo-1, epoch=50, batch=0 train mse <loss>=0.6079351806640625\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:56 INFO 139730530932544] #quality_metric: host=algo-1, epoch=50, batch=0 train absolute_loss <loss>=0.597553466796875\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:30:59.586] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 102, \"duration\": 2619, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:59 INFO 139730530932544] #quality_metric: host=algo-1, epoch=50, train rmse <loss>=0.7459462345131095\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:59 INFO 139730530932544] #quality_metric: host=algo-1, epoch=50, train mse <loss>=0.556435784784287\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:59 INFO 139730530932544] #quality_metric: host=algo-1, epoch=50, train absolute_loss <loss>=0.5088123073078575\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079856.9609551, \"EndTime\": 1659079859.5870285, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2625.620126724243, \"count\": 1, \"min\": 2625.620126724243, \"max\": 2625.620126724243}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:59 INFO 139730530932544] #progress_metric: host=algo-1, completed 61.44578313253012 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079856.961376, \"EndTime\": 1659079859.5872772, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 50, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9720682.0, \"count\": 1, \"min\": 9720682, \"max\": 9720682}, \"Total Batches Seen\": {\"sum\": 9742.0, \"count\": 1, \"min\": 9742, \"max\": 9742}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 52.0, \"count\": 1, \"min\": 52, \"max\": 52}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:59 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72574.13151265841 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:59 INFO 139730530932544] #quality_metric: host=algo-1, epoch=51, batch=0 train rmse <loss>=0.7690986252181835\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:59 INFO 139730530932544] #quality_metric: host=algo-1, epoch=51, batch=0 train mse <loss>=0.5915126953125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:30:59 INFO 139730530932544] #quality_metric: host=algo-1, epoch=51, batch=0 train absolute_loss <loss>=0.5869618530273437\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:02.388] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 104, \"duration\": 2798, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:02 INFO 139730530932544] #quality_metric: host=algo-1, epoch=51, train rmse <loss>=0.7360667087152565\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:02 INFO 139730530932544] #quality_metric: host=algo-1, epoch=51, train mse <loss>=0.5417941996789103\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:02 INFO 139730530932544] #quality_metric: host=algo-1, epoch=51, train absolute_loss <loss>=0.499586209282201\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079859.5871096, \"EndTime\": 1659079862.388827, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2801.2542724609375, \"count\": 1, \"min\": 2801.2542724609375, \"max\": 2801.2542724609375}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:02 INFO 139730530932544] #progress_metric: host=algo-1, completed 62.65060240963855 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079859.5875368, \"EndTime\": 1659079862.3891308, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 51, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9911264.0, \"count\": 1, \"min\": 9911264, \"max\": 9911264}, \"Total Batches Seen\": {\"sum\": 9933.0, \"count\": 1, \"min\": 9933, \"max\": 9933}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 53.0, \"count\": 1, \"min\": 53, \"max\": 53}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:02 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=68022.27890519169 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:02 INFO 139730530932544] #quality_metric: host=algo-1, epoch=52, batch=0 train rmse <loss>=0.7587174043142645\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:02 INFO 139730530932544] #quality_metric: host=algo-1, epoch=52, batch=0 train mse <loss>=0.575652099609375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:02 INFO 139730530932544] #quality_metric: host=algo-1, epoch=52, batch=0 train absolute_loss <loss>=0.576606689453125\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:05.128] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 106, \"duration\": 2734, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:05 INFO 139730530932544] #quality_metric: host=algo-1, epoch=52, train rmse <loss>=0.7264108601890793\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:05 INFO 139730530932544] #quality_metric: host=algo-1, epoch=52, train mse <loss>=0.5276727378006381\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:05 INFO 139730530932544] #quality_metric: host=algo-1, epoch=52, train absolute_loss <loss>=0.49062910453436887\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079862.3889284, \"EndTime\": 1659079865.1287289, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2737.966299057007, \"count\": 1, \"min\": 2737.966299057007, \"max\": 2737.966299057007}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:05 INFO 139730530932544] #progress_metric: host=algo-1, completed 63.855421686746986 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079862.3907335, \"EndTime\": 1659079865.1289053, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 52, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10101846.0, \"count\": 1, \"min\": 10101846, \"max\": 10101846}, \"Total Batches Seen\": {\"sum\": 10124.0, \"count\": 1, \"min\": 10124, \"max\": 10124}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:05 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=69598.73271613591 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:05 INFO 139730530932544] #quality_metric: host=algo-1, epoch=53, batch=0 train rmse <loss>=0.7485532921910103\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:05 INFO 139730530932544] #quality_metric: host=algo-1, epoch=53, batch=0 train mse <loss>=0.56033203125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:05 INFO 139730530932544] #quality_metric: host=algo-1, epoch=53, batch=0 train absolute_loss <loss>=0.5664517822265625\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:08.066] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 108, \"duration\": 2934, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:08 INFO 139730530932544] #quality_metric: host=algo-1, epoch=53, train rmse <loss>=0.7169733040893801\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:08 INFO 139730530932544] #quality_metric: host=algo-1, epoch=53, train mse <loss>=0.5140507187768427\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:08 INFO 139730530932544] #quality_metric: host=algo-1, epoch=53, train absolute_loss <loss>=0.4819297982260819\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079865.1287894, \"EndTime\": 1659079868.0672677, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2937.2098445892334, \"count\": 1, \"min\": 2937.2098445892334, \"max\": 2937.2098445892334}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:08 INFO 139730530932544] #progress_metric: host=algo-1, completed 65.06024096385542 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079865.130024, \"EndTime\": 1659079868.0676048, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 53, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10292428.0, \"count\": 1, \"min\": 10292428, \"max\": 10292428}, \"Total Batches Seen\": {\"sum\": 10315.0, \"count\": 1, \"min\": 10315, \"max\": 10315}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 55.0, \"count\": 1, \"min\": 55, \"max\": 55}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:08 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=64873.6764733977 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:08 INFO 139730530932544] #quality_metric: host=algo-1, epoch=54, batch=0 train rmse <loss>=0.7386006666827608\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:08 INFO 139730530932544] #quality_metric: host=algo-1, epoch=54, batch=0 train mse <loss>=0.5455309448242187\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:08 INFO 139730530932544] #quality_metric: host=algo-1, epoch=54, batch=0 train absolute_loss <loss>=0.556494873046875\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:10.685] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 110, \"duration\": 2614, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:10 INFO 139730530932544] #quality_metric: host=algo-1, epoch=54, train rmse <loss>=0.7077485677826776\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:10 INFO 139730530932544] #quality_metric: host=algo-1, epoch=54, train mse <loss>=0.5009080351984314\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:10 INFO 139730530932544] #quality_metric: host=algo-1, epoch=54, train absolute_loss <loss>=0.4734862956900871\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079868.0673757, \"EndTime\": 1659079870.6864116, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2617.375612258911, \"count\": 1, \"min\": 2617.375612258911, \"max\": 2617.375612258911}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:10 INFO 139730530932544] #progress_metric: host=algo-1, completed 66.26506024096386 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079868.069006, \"EndTime\": 1659079870.6866658, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 54, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10483010.0, \"count\": 1, \"min\": 10483010, \"max\": 10483010}, \"Total Batches Seen\": {\"sum\": 10506.0, \"count\": 1, \"min\": 10506, \"max\": 10506}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 56.0, \"count\": 1, \"min\": 56, \"max\": 56}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:10 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72802.75102991506 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:10 INFO 139730530932544] #quality_metric: host=algo-1, epoch=55, batch=0 train rmse <loss>=0.7288543741588361\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:10 INFO 139730530932544] #quality_metric: host=algo-1, epoch=55, batch=0 train mse <loss>=0.5312286987304687\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:10 INFO 139730530932544] #quality_metric: host=algo-1, epoch=55, batch=0 train absolute_loss <loss>=0.5467788696289062\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:13.357] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 112, \"duration\": 2667, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:13 INFO 139730530932544] #quality_metric: host=algo-1, epoch=55, train rmse <loss>=0.6987311802313411\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:13 INFO 139730530932544] #quality_metric: host=algo-1, epoch=55, train mse <loss>=0.4882252622274828\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:13 INFO 139730530932544] #quality_metric: host=algo-1, epoch=55, train absolute_loss <loss>=0.46529550282742965\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079870.686489, \"EndTime\": 1659079873.3581958, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2670.4158782958984, \"count\": 1, \"min\": 2670.4158782958984, \"max\": 2670.4158782958984}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:13 INFO 139730530932544] #progress_metric: host=algo-1, completed 67.46987951807229 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079870.6877487, \"EndTime\": 1659079873.3584697, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 55, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10673592.0, \"count\": 1, \"min\": 10673592, \"max\": 10673592}, \"Total Batches Seen\": {\"sum\": 10697.0, \"count\": 1, \"min\": 10697, \"max\": 10697}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 57.0, \"count\": 1, \"min\": 57, \"max\": 57}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:13 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71356.39793639598 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:13 INFO 139730530932544] #quality_metric: host=algo-1, epoch=56, batch=0 train rmse <loss>=0.7193092253813724\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:13 INFO 139730530932544] #quality_metric: host=algo-1, epoch=56, batch=0 train mse <loss>=0.51740576171875\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:13 INFO 139730530932544] #quality_metric: host=algo-1, epoch=56, batch=0 train absolute_loss <loss>=0.5373361206054688\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:16.026] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 114, \"duration\": 2664, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:16 INFO 139730530932544] #quality_metric: host=algo-1, epoch=56, train rmse <loss>=0.6899157782697543\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:16 INFO 139730530932544] #quality_metric: host=algo-1, epoch=56, train mse <loss>=0.4759837811055608\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:16 INFO 139730530932544] #quality_metric: host=algo-1, epoch=56, train absolute_loss <loss>=0.45735317577741535\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079873.3582928, \"EndTime\": 1659079876.0274158, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2667.6459312438965, \"count\": 1, \"min\": 2667.6459312438965, \"max\": 2667.6459312438965}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:16 INFO 139730530932544] #progress_metric: host=algo-1, completed 68.67469879518072 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079873.3597338, \"EndTime\": 1659079876.0277193, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 56, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10864174.0, \"count\": 1, \"min\": 10864174, \"max\": 10864174}, \"Total Batches Seen\": {\"sum\": 10888.0, \"count\": 1, \"min\": 10888, \"max\": 10888}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 58.0, \"count\": 1, \"min\": 58, \"max\": 58}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:16 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71428.07887517055 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:16 INFO 139730530932544] #quality_metric: host=algo-1, epoch=57, batch=0 train rmse <loss>=0.7099598789968038\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:16 INFO 139730530932544] #quality_metric: host=algo-1, epoch=57, batch=0 train mse <loss>=0.5040430297851562\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:16 INFO 139730530932544] #quality_metric: host=algo-1, epoch=57, batch=0 train absolute_loss <loss>=0.52815185546875\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:18.620] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 116, \"duration\": 2587, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:18 INFO 139730530932544] #quality_metric: host=algo-1, epoch=57, train rmse <loss>=0.681297061027045\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:18 INFO 139730530932544] #quality_metric: host=algo-1, epoch=57, train mse <loss>=0.4641656853640891\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:18 INFO 139730530932544] #quality_metric: host=algo-1, epoch=57, train absolute_loss <loss>=0.4496396636164001\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079876.0275114, \"EndTime\": 1659079878.6220846, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2593.135118484497, \"count\": 1, \"min\": 2593.135118484497, \"max\": 2593.135118484497}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:18 INFO 139730530932544] #progress_metric: host=algo-1, completed 69.87951807228916 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079876.0289145, \"EndTime\": 1659079878.6223247, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 57, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11054756.0, \"count\": 1, \"min\": 11054756, \"max\": 11054756}, \"Total Batches Seen\": {\"sum\": 11079.0, \"count\": 1, \"min\": 11079, \"max\": 11079}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 59.0, \"count\": 1, \"min\": 59, \"max\": 59}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:18 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=73483.23357288471 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:18 INFO 139730530932544] #quality_metric: host=algo-1, epoch=58, batch=0 train rmse <loss>=0.7008016954584384\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:18 INFO 139730530932544] #quality_metric: host=algo-1, epoch=58, batch=0 train mse <loss>=0.4911230163574219\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:18 INFO 139730530932544] #quality_metric: host=algo-1, epoch=58, batch=0 train absolute_loss <loss>=0.51916357421875\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:21.259] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 118, \"duration\": 2634, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:21 INFO 139730530932544] #quality_metric: host=algo-1, epoch=58, train rmse <loss>=0.6728698509127018\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:21 INFO 139730530932544] #quality_metric: host=algo-1, epoch=58, train mse <loss>=0.45275383626728155\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:21 INFO 139730530932544] #quality_metric: host=algo-1, epoch=58, train absolute_loss <loss>=0.44214296638528716\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079878.6221638, \"EndTime\": 1659079881.26023, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2636.8303298950195, \"count\": 1, \"min\": 2636.8303298950195, \"max\": 2636.8303298950195}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:21 INFO 139730530932544] #progress_metric: host=algo-1, completed 71.08433734939759 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079878.6233687, \"EndTime\": 1659079881.2604642, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 58, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11245338.0, \"count\": 1, \"min\": 11245338, \"max\": 11245338}, \"Total Batches Seen\": {\"sum\": 11270.0, \"count\": 1, \"min\": 11270, \"max\": 11270}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 60.0, \"count\": 1, \"min\": 60, \"max\": 60}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:21 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72266.28531247286 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:21 INFO 139730530932544] #quality_metric: host=algo-1, epoch=59, batch=0 train rmse <loss>=0.691830091664436\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:21 INFO 139730530932544] #quality_metric: host=algo-1, epoch=59, batch=0 train mse <loss>=0.47862887573242185\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:21 INFO 139730530932544] #quality_metric: host=algo-1, epoch=59, batch=0 train absolute_loss <loss>=0.5103391723632813\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:23.928] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 120, \"duration\": 2662, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:23 INFO 139730530932544] #quality_metric: host=algo-1, epoch=59, train rmse <loss>=0.6646290708184421\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:23 INFO 139730530932544] #quality_metric: host=algo-1, epoch=59, train mse <loss>=0.44173180177698584\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:23 INFO 139730530932544] #quality_metric: host=algo-1, epoch=59, train absolute_loss <loss>=0.43485421800863056\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079881.260308, \"EndTime\": 1659079883.9288578, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2667.024612426758, \"count\": 1, \"min\": 2667.024612426758, \"max\": 2667.024612426758}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:23 INFO 139730530932544] #progress_metric: host=algo-1, completed 72.28915662650603 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079881.2617931, \"EndTime\": 1659079883.929181, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 59, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11435920.0, \"count\": 1, \"min\": 11435920, \"max\": 11435920}, \"Total Batches Seen\": {\"sum\": 11461.0, \"count\": 1, \"min\": 11461, \"max\": 11461}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 61.0, \"count\": 1, \"min\": 61, \"max\": 61}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:23 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71443.98780295209 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:23 INFO 139730530932544] #quality_metric: host=algo-1, epoch=60, batch=0 train rmse <loss>=0.6830404903982176\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:23 INFO 139730530932544] #quality_metric: host=algo-1, epoch=60, batch=0 train mse <loss>=0.4665443115234375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:23 INFO 139730530932544] #quality_metric: host=algo-1, epoch=60, batch=0 train absolute_loss <loss>=0.5017369384765625\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:26.572] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 122, \"duration\": 2639, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:26 INFO 139730530932544] #quality_metric: host=algo-1, epoch=60, train rmse <loss>=0.6565697069002431\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:26 INFO 139730530932544] #quality_metric: host=algo-1, epoch=60, train mse <loss>=0.4310837800190711\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:26 INFO 139730530932544] #quality_metric: host=algo-1, epoch=60, train absolute_loss <loss>=0.42776160179258016\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079883.92897, \"EndTime\": 1659079886.5727572, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2642.024040222168, \"count\": 1, \"min\": 2642.024040222168, \"max\": 2642.024040222168}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:26 INFO 139730530932544] #progress_metric: host=algo-1, completed 73.49397590361446 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079883.9306982, \"EndTime\": 1659079886.5729918, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 60, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11626502.0, \"count\": 1, \"min\": 11626502, \"max\": 11626502}, \"Total Batches Seen\": {\"sum\": 11652.0, \"count\": 1, \"min\": 11652, \"max\": 11652}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 62.0, \"count\": 1, \"min\": 62, \"max\": 62}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:26 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72123.34655915397 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:26 INFO 139730530932544] #quality_metric: host=algo-1, epoch=61, batch=0 train rmse <loss>=0.6744289214714828\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:26 INFO 139730530932544] #quality_metric: host=algo-1, epoch=61, batch=0 train mse <loss>=0.4548543701171875\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:26 INFO 139730530932544] #quality_metric: host=algo-1, epoch=61, batch=0 train absolute_loss <loss>=0.4933608093261719\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:29.204] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 124, \"duration\": 2628, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:29 INFO 139730530932544] #quality_metric: host=algo-1, epoch=61, train rmse <loss>=0.6486868344506906\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:29 INFO 139730530932544] #quality_metric: host=algo-1, epoch=61, train mse <loss>=0.42079460918965766\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:29 INFO 139730530932544] #quality_metric: host=algo-1, epoch=61, train absolute_loss <loss>=0.42085873796552886\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079886.5728345, \"EndTime\": 1659079889.2054763, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2631.211519241333, \"count\": 1, \"min\": 2631.211519241333, \"max\": 2631.211519241333}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:29 INFO 139730530932544] #progress_metric: host=algo-1, completed 74.6987951807229 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079886.5742311, \"EndTime\": 1659079889.2058535, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 61, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11817084.0, \"count\": 1, \"min\": 11817084, \"max\": 11817084}, \"Total Batches Seen\": {\"sum\": 11843.0, \"count\": 1, \"min\": 11843, \"max\": 11843}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 63.0, \"count\": 1, \"min\": 63, \"max\": 63}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:29 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72417.02075388061 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:29 INFO 139730530932544] #quality_metric: host=algo-1, epoch=62, batch=0 train rmse <loss>=0.6659912248096348\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:29 INFO 139730530932544] #quality_metric: host=algo-1, epoch=62, batch=0 train mse <loss>=0.4435443115234375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:29 INFO 139730530932544] #quality_metric: host=algo-1, epoch=62, batch=0 train absolute_loss <loss>=0.48514852905273437\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:31.853] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 126, \"duration\": 2643, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:31 INFO 139730530932544] #quality_metric: host=algo-1, epoch=62, train rmse <loss>=0.6409755968732965\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:31 INFO 139730530932544] #quality_metric: host=algo-1, epoch=62, train mse <loss>=0.4108497157870787\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:31 INFO 139730530932544] #quality_metric: host=algo-1, epoch=62, train absolute_loss <loss>=0.41413966233817695\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079889.205613, \"EndTime\": 1659079891.8550513, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2647.855043411255, \"count\": 1, \"min\": 2647.855043411255, \"max\": 2647.855043411255}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:31 INFO 139730530932544] #progress_metric: host=algo-1, completed 75.90361445783132 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079889.2071552, \"EndTime\": 1659079891.855368, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 62, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12007666.0, \"count\": 1, \"min\": 12007666, \"max\": 12007666}, \"Total Batches Seen\": {\"sum\": 12034.0, \"count\": 1, \"min\": 12034, \"max\": 12034}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 64.0, \"count\": 1, \"min\": 64, \"max\": 64}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:31 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71961.44786325433 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:31 INFO 139730530932544] #quality_metric: host=algo-1, epoch=63, batch=0 train rmse <loss>=0.6577233739354971\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:31 INFO 139730530932544] #quality_metric: host=algo-1, epoch=63, batch=0 train mse <loss>=0.43260003662109375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:31 INFO 139730530932544] #quality_metric: host=algo-1, epoch=63, batch=0 train absolute_loss <loss>=0.4770789794921875\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:34.421] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 128, \"duration\": 2561, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:34 INFO 139730530932544] #quality_metric: host=algo-1, epoch=63, train rmse <loss>=0.6334312522766747\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:34 INFO 139730530932544] #quality_metric: host=algo-1, epoch=63, train mse <loss>=0.4012351513607964\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:34 INFO 139730530932544] #quality_metric: host=algo-1, epoch=63, train absolute_loss <loss>=0.40759848853305997\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079891.855148, \"EndTime\": 1659079894.4225845, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2565.53316116333, \"count\": 1, \"min\": 2565.53316116333, \"max\": 2565.53316116333}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:34 INFO 139730530932544] #progress_metric: host=algo-1, completed 77.10843373493977 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079891.8569915, \"EndTime\": 1659079894.423103, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 63, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12198248.0, \"count\": 1, \"min\": 12198248, \"max\": 12198248}, \"Total Batches Seen\": {\"sum\": 12225.0, \"count\": 1, \"min\": 12225, \"max\": 12225}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 65.0, \"count\": 1, \"min\": 65, \"max\": 65}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:34 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=74263.88382278576 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:34 INFO 139730530932544] #quality_metric: host=algo-1, epoch=64, batch=0 train rmse <loss>=0.649621401346885\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:34 INFO 139730530932544] #quality_metric: host=algo-1, epoch=64, batch=0 train mse <loss>=0.4220079650878906\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:34 INFO 139730530932544] #quality_metric: host=algo-1, epoch=64, batch=0 train absolute_loss <loss>=0.4692311096191406\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:37.013] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 130, \"duration\": 2585, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:37 INFO 139730530932544] #quality_metric: host=algo-1, epoch=64, train rmse <loss>=0.6260491924704931\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:37 INFO 139730530932544] #quality_metric: host=algo-1, epoch=64, train mse <loss>=0.3919375913929565\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:37 INFO 139730530932544] #quality_metric: host=algo-1, epoch=64, train absolute_loss <loss>=0.40123427402036976\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079894.4227028, \"EndTime\": 1659079897.0142007, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2589.9713039398193, \"count\": 1, \"min\": 2589.9713039398193, \"max\": 2589.9713039398193}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:37 INFO 139730530932544] #progress_metric: host=algo-1, completed 78.3132530120482 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079894.4241958, \"EndTime\": 1659079897.0144353, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 64, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12388830.0, \"count\": 1, \"min\": 12388830, \"max\": 12388830}, \"Total Batches Seen\": {\"sum\": 12416.0, \"count\": 1, \"min\": 12416, \"max\": 12416}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:37 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=73573.36305823235 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:37 INFO 139730530932544] #quality_metric: host=algo-1, epoch=65, batch=0 train rmse <loss>=0.6416816029317154\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:37 INFO 139730530932544] #quality_metric: host=algo-1, epoch=65, batch=0 train mse <loss>=0.41175527954101565\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:37 INFO 139730530932544] #quality_metric: host=algo-1, epoch=65, batch=0 train absolute_loss <loss>=0.4615588073730469\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:39.601] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 132, \"duration\": 2584, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:39 INFO 139730530932544] #quality_metric: host=algo-1, epoch=65, train rmse <loss>=0.618824940010169\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:39 INFO 139730530932544] #quality_metric: host=algo-1, epoch=65, train mse <loss>=0.3829443063785892\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:39 INFO 139730530932544] #quality_metric: host=algo-1, epoch=65, train absolute_loss <loss>=0.3950360264004213\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079897.0142806, \"EndTime\": 1659079899.6023276, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2586.8403911590576, \"count\": 1, \"min\": 2586.8403911590576, \"max\": 2586.8403911590576}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:39 INFO 139730530932544] #progress_metric: host=algo-1, completed 79.51807228915662 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079897.015453, \"EndTime\": 1659079899.6026218, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 65, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12579412.0, \"count\": 1, \"min\": 12579412, \"max\": 12579412}, \"Total Batches Seen\": {\"sum\": 12607.0, \"count\": 1, \"min\": 12607, \"max\": 12607}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 67.0, \"count\": 1, \"min\": 67, \"max\": 67}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:39 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=73660.73393495461 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:39 INFO 139730530932544] #quality_metric: host=algo-1, epoch=66, batch=0 train rmse <loss>=0.6338999144679702\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:39 INFO 139730530932544] #quality_metric: host=algo-1, epoch=66, batch=0 train mse <loss>=0.4018291015625\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:39 INFO 139730530932544] #quality_metric: host=algo-1, epoch=66, batch=0 train absolute_loss <loss>=0.454069580078125\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:42.287] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 134, \"duration\": 2682, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:42 INFO 139730530932544] #quality_metric: host=algo-1, epoch=66, train rmse <loss>=0.6117541775982831\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:42 INFO 139730530932544] #quality_metric: host=algo-1, epoch=66, train mse <loss>=0.37424317380895167\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:42 INFO 139730530932544] #quality_metric: host=algo-1, epoch=66, train absolute_loss <loss>=0.3889978904524399\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079899.6024237, \"EndTime\": 1659079902.2898488, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2686.074733734131, \"count\": 1, \"min\": 2686.074733734131, \"max\": 2686.074733734131}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:42 INFO 139730530932544] #progress_metric: host=algo-1, completed 80.72289156626506 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079899.60374, \"EndTime\": 1659079902.290137, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 66, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12769994.0, \"count\": 1, \"min\": 12769994, \"max\": 12769994}, \"Total Batches Seen\": {\"sum\": 12798.0, \"count\": 1, \"min\": 12798, \"max\": 12798}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 68.0, \"count\": 1, \"min\": 68, \"max\": 68}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:42 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=70939.15397979027 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:42 INFO 139730530932544] #quality_metric: host=algo-1, epoch=67, batch=0 train rmse <loss>=0.6262724595601468\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:42 INFO 139730530932544] #quality_metric: host=algo-1, epoch=67, batch=0 train mse <loss>=0.39221719360351565\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:42 INFO 139730530932544] #quality_metric: host=algo-1, epoch=67, batch=0 train absolute_loss <loss>=0.44678756713867185\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:44.945] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 136, \"duration\": 2652, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:44 INFO 139730530932544] #quality_metric: host=algo-1, epoch=67, train rmse <loss>=0.6048327665192281\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:44 INFO 139730530932544] #quality_metric: host=algo-1, epoch=67, train mse <loss>=0.3658226754553031\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:44 INFO 139730530932544] #quality_metric: host=algo-1, epoch=67, train absolute_loss <loss>=0.3831154468796016\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079902.2899225, \"EndTime\": 1659079904.9465244, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2655.2422046661377, \"count\": 1, \"min\": 2655.2422046661377, \"max\": 2655.2422046661377}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:44 INFO 139730530932544] #progress_metric: host=algo-1, completed 81.92771084337349 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079902.2912471, \"EndTime\": 1659079904.9468212, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 67, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12960576.0, \"count\": 1, \"min\": 12960576, \"max\": 12960576}, \"Total Batches Seen\": {\"sum\": 12989.0, \"count\": 1, \"min\": 12989, \"max\": 12989}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 69.0, \"count\": 1, \"min\": 69, \"max\": 69}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:44 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71762.6690594773 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:44 INFO 139730530932544] #quality_metric: host=algo-1, epoch=68, batch=0 train rmse <loss>=0.6187952999910517\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:44 INFO 139730530932544] #quality_metric: host=algo-1, epoch=68, batch=0 train mse <loss>=0.38290762329101563\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:44 INFO 139730530932544] #quality_metric: host=algo-1, epoch=68, batch=0 train absolute_loss <loss>=0.43966583251953123\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:47.580] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 138, \"duration\": 2629, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:47 INFO 139730530932544] #quality_metric: host=algo-1, epoch=68, train rmse <loss>=0.5980567373580228\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:47 INFO 139730530932544] #quality_metric: host=algo-1, epoch=68, train mse <loss>=0.35767186109932303\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:47 INFO 139730530932544] #quality_metric: host=algo-1, epoch=68, train absolute_loss <loss>=0.37737902736164514\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079904.94662, \"EndTime\": 1659079907.5807114, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2632.6165199279785, \"count\": 1, \"min\": 2632.6165199279785, \"max\": 2632.6165199279785}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:47 INFO 139730530932544] #progress_metric: host=algo-1, completed 83.13253012048193 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079904.9480646, \"EndTime\": 1659079907.5809402, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 68, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13151158.0, \"count\": 1, \"min\": 13151158, \"max\": 13151158}, \"Total Batches Seen\": {\"sum\": 13180.0, \"count\": 1, \"min\": 13180, \"max\": 13180}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 70.0, \"count\": 1, \"min\": 70, \"max\": 70}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:47 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72382.19448758663 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:47 INFO 139730530932544] #quality_metric: host=algo-1, epoch=69, batch=0 train rmse <loss>=0.6114644167162602\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:47 INFO 139730530932544] #quality_metric: host=algo-1, epoch=69, batch=0 train mse <loss>=0.37388873291015623\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:47 INFO 139730530932544] #quality_metric: host=algo-1, epoch=69, batch=0 train absolute_loss <loss>=0.4327216796875\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:50.216] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 140, \"duration\": 2632, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:50 INFO 139730530932544] #quality_metric: host=algo-1, epoch=69, train rmse <loss>=0.5914222735345246\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:50 INFO 139730530932544] #quality_metric: host=algo-1, epoch=69, train mse <loss>=0.34978030563274604\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:50 INFO 139730530932544] #quality_metric: host=algo-1, epoch=69, train absolute_loss <loss>=0.3717851012864038\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079907.5807881, \"EndTime\": 1659079910.2171125, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2634.889602661133, \"count\": 1, \"min\": 2634.889602661133, \"max\": 2634.889602661133}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:50 INFO 139730530932544] #progress_metric: host=algo-1, completed 84.33734939759036 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079907.5821867, \"EndTime\": 1659079910.217419, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 69, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13341740.0, \"count\": 1, \"min\": 13341740, \"max\": 13341740}, \"Total Batches Seen\": {\"sum\": 13371.0, \"count\": 1, \"min\": 13371, \"max\": 13371}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:50 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72316.02453515744 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:50 INFO 139730530932544] #quality_metric: host=algo-1, epoch=70, batch=0 train rmse <loss>=0.6042757399746204\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:50 INFO 139730530932544] #quality_metric: host=algo-1, epoch=70, batch=0 train mse <loss>=0.365149169921875\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:50 INFO 139730530932544] #quality_metric: host=algo-1, epoch=70, batch=0 train absolute_loss <loss>=0.4259129333496094\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:52.872] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 142, \"duration\": 2652, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:52 INFO 139730530932544] #quality_metric: host=algo-1, epoch=70, train rmse <loss>=0.5849256823341735\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:52 INFO 139730530932544] #quality_metric: host=algo-1, epoch=70, train mse <loss>=0.3421380538540985\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:52 INFO 139730530932544] #quality_metric: host=algo-1, epoch=70, train absolute_loss <loss>=0.3663334230752516\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079910.2172096, \"EndTime\": 1659079912.8734055, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2654.70027923584, \"count\": 1, \"min\": 2654.70027923584, \"max\": 2654.70027923584}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:52 INFO 139730530932544] #progress_metric: host=algo-1, completed 85.5421686746988 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079910.2186737, \"EndTime\": 1659079912.8736675, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 70, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13532322.0, \"count\": 1, \"min\": 13532322, \"max\": 13532322}, \"Total Batches Seen\": {\"sum\": 13562.0, \"count\": 1, \"min\": 13562, \"max\": 13562}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:52 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=71779.1205687311 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:52 INFO 139730530932544] #quality_metric: host=algo-1, epoch=71, batch=0 train rmse <loss>=0.5972255903439828\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:52 INFO 139730530932544] #quality_metric: host=algo-1, epoch=71, batch=0 train mse <loss>=0.3566784057617188\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:52 INFO 139730530932544] #quality_metric: host=algo-1, epoch=71, batch=0 train absolute_loss <loss>=0.41927078247070315\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:55.487] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 144, \"duration\": 2610, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:55 INFO 139730530932544] #quality_metric: host=algo-1, epoch=71, train rmse <loss>=0.5785634493872239\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:55 INFO 139730530932544] #quality_metric: host=algo-1, epoch=71, train mse <loss>=0.33473566496684287\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:55 INFO 139730530932544] #quality_metric: host=algo-1, epoch=71, train absolute_loss <loss>=0.3610201233868824\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079912.873482, \"EndTime\": 1659079915.4877372, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2612.9400730133057, \"count\": 1, \"min\": 2612.9400730133057, \"max\": 2612.9400730133057}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:55 INFO 139730530932544] #progress_metric: host=algo-1, completed 86.74698795180723 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079912.8747663, \"EndTime\": 1659079915.4879644, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 71, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13722904.0, \"count\": 1, \"min\": 13722904, \"max\": 13722904}, \"Total Batches Seen\": {\"sum\": 13753.0, \"count\": 1, \"min\": 13753, \"max\": 13753}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 73.0, \"count\": 1, \"min\": 73, \"max\": 73}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:55 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72927.254459338 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:55 INFO 139730530932544] #quality_metric: host=algo-1, epoch=72, batch=0 train rmse <loss>=0.5903099358070301\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:55 INFO 139730530932544] #quality_metric: host=algo-1, epoch=72, batch=0 train mse <loss>=0.3484658203125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:55 INFO 139730530932544] #quality_metric: host=algo-1, epoch=72, batch=0 train absolute_loss <loss>=0.4128096008300781\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:31:58.071] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 146, \"duration\": 2578, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:58 INFO 139730530932544] #quality_metric: host=algo-1, epoch=72, train rmse <loss>=0.5723321697043823\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:58 INFO 139730530932544] #quality_metric: host=algo-1, epoch=72, train mse <loss>=0.32756411247852585\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:58 INFO 139730530932544] #quality_metric: host=algo-1, epoch=72, train absolute_loss <loss>=0.3558453260491656\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079915.4878128, \"EndTime\": 1659079918.0721943, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2582.96537399292, \"count\": 1, \"min\": 2582.96537399292, \"max\": 2582.96537399292}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:58 INFO 139730530932544] #progress_metric: host=algo-1, completed 87.95180722891567 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079915.4891925, \"EndTime\": 1659079918.0724895, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 72, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13913486.0, \"count\": 1, \"min\": 13913486, \"max\": 13913486}, \"Total Batches Seen\": {\"sum\": 13944.0, \"count\": 1, \"min\": 13944, \"max\": 13944}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 74.0, \"count\": 1, \"min\": 74, \"max\": 74}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:58 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=73770.39125680801 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:58 INFO 139730530932544] #quality_metric: host=algo-1, epoch=73, batch=0 train rmse <loss>=0.5835251382023422\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:58 INFO 139730530932544] #quality_metric: host=algo-1, epoch=73, batch=0 train mse <loss>=0.3405015869140625\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:31:58 INFO 139730530932544] #quality_metric: host=algo-1, epoch=73, batch=0 train absolute_loss <loss>=0.40652883911132814\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:32:00.669] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 148, \"duration\": 2593, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:00 INFO 139730530932544] #quality_metric: host=algo-1, epoch=73, train rmse <loss>=0.5662285729484445\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:00 INFO 139730530932544] #quality_metric: host=algo-1, epoch=73, train mse <loss>=0.32061479682323196\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:00 INFO 139730530932544] #quality_metric: host=algo-1, epoch=73, train absolute_loss <loss>=0.3508072549710099\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079918.0722873, \"EndTime\": 1659079920.6704235, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2596.566915512085, \"count\": 1, \"min\": 2596.566915512085, \"max\": 2596.566915512085}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:00 INFO 139730530932544] #progress_metric: host=algo-1, completed 89.1566265060241 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079918.0738256, \"EndTime\": 1659079920.6706579, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 73, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14104068.0, \"count\": 1, \"min\": 14104068, \"max\": 14104068}, \"Total Batches Seen\": {\"sum\": 14135.0, \"count\": 1, \"min\": 14135, \"max\": 14135}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:00 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=73386.76180519062 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:00 INFO 139730530932544] #quality_metric: host=algo-1, epoch=74, batch=0 train rmse <loss>=0.5768675619949792\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:00 INFO 139730530932544] #quality_metric: host=algo-1, epoch=74, batch=0 train mse <loss>=0.33277618408203125\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:00 INFO 139730530932544] #quality_metric: host=algo-1, epoch=74, batch=0 train absolute_loss <loss>=0.4004022521972656\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:32:03.490] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 150, \"duration\": 2817, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:03 INFO 139730530932544] #quality_metric: host=algo-1, epoch=74, train rmse <loss>=0.5602494994040068\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:03 INFO 139730530932544] #quality_metric: host=algo-1, epoch=74, train mse <loss>=0.31387950158244027\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:03 INFO 139730530932544] #quality_metric: host=algo-1, epoch=74, train absolute_loss <loss>=0.3459020555106757\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079920.6705008, \"EndTime\": 1659079923.4912908, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2820.3377723693848, \"count\": 1, \"min\": 2820.3377723693848, \"max\": 2820.3377723693848}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:03 INFO 139730530932544] #progress_metric: host=algo-1, completed 90.36144578313252 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079920.6709156, \"EndTime\": 1659079923.4918518, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 74, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14294650.0, \"count\": 1, \"min\": 14294650, \"max\": 14294650}, \"Total Batches Seen\": {\"sum\": 14326.0, \"count\": 1, \"min\": 14326, \"max\": 14326}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 76.0, \"count\": 1, \"min\": 76, \"max\": 76}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:03 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=67553.12624042512 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:03 INFO 139730530932544] #quality_metric: host=algo-1, epoch=75, batch=0 train rmse <loss>=0.5703338234455464\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:03 INFO 139730530932544] #quality_metric: host=algo-1, epoch=75, batch=0 train mse <loss>=0.32528067016601564\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:03 INFO 139730530932544] #quality_metric: host=algo-1, epoch=75, batch=0 train absolute_loss <loss>=0.39442245483398436\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:32:06.528] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 152, \"duration\": 3033, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:06 INFO 139730530932544] #quality_metric: host=algo-1, epoch=75, train rmse <loss>=0.5543919291805048\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:06 INFO 139730530932544] #quality_metric: host=algo-1, epoch=75, train mse <loss>=0.30735041114048184\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:06 INFO 139730530932544] #quality_metric: host=algo-1, epoch=75, train absolute_loss <loss>=0.3411234020612627\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079923.491508, \"EndTime\": 1659079926.5287921, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3036.3264083862305, \"count\": 1, \"min\": 3036.3264083862305, \"max\": 3036.3264083862305}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:06 INFO 139730530932544] #progress_metric: host=algo-1, completed 91.56626506024097 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079923.4924328, \"EndTime\": 1659079926.529022, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 75, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14485232.0, \"count\": 1, \"min\": 14485232, \"max\": 14485232}, \"Total Batches Seen\": {\"sum\": 14517.0, \"count\": 1, \"min\": 14517, \"max\": 14517}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 77.0, \"count\": 1, \"min\": 77, \"max\": 77}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:06 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=62759.11115270492 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:06 INFO 139730530932544] #quality_metric: host=algo-1, epoch=76, batch=0 train rmse <loss>=0.5639204883125563\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:06 INFO 139730530932544] #quality_metric: host=algo-1, epoch=76, batch=0 train mse <loss>=0.3180063171386719\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:06 INFO 139730530932544] #quality_metric: host=algo-1, epoch=76, batch=0 train absolute_loss <loss>=0.3886027526855469\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:32:09.267] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 154, \"duration\": 2736, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:09 INFO 139730530932544] #quality_metric: host=algo-1, epoch=76, train rmse <loss>=0.5486529465162321\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:09 INFO 139730530932544] #quality_metric: host=algo-1, epoch=76, train mse <loss>=0.3010200557209434\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:09 INFO 139730530932544] #quality_metric: host=algo-1, epoch=76, train absolute_loss <loss>=0.33646636962890625\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079926.528869, \"EndTime\": 1659079929.2684267, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2739.116907119751, \"count\": 1, \"min\": 2739.116907119751, \"max\": 2739.116907119751}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:09 INFO 139730530932544] #progress_metric: host=algo-1, completed 92.7710843373494 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079926.5292714, \"EndTime\": 1659079929.2687466, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 76, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14675814.0, \"count\": 1, \"min\": 14675814, \"max\": 14675814}, \"Total Batches Seen\": {\"sum\": 14708.0, \"count\": 1, \"min\": 14708, \"max\": 14708}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 78.0, \"count\": 1, \"min\": 78, \"max\": 78}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:09 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=69564.81417197161 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:09 INFO 139730530932544] #quality_metric: host=algo-1, epoch=77, batch=0 train rmse <loss>=0.5576244595081863\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:09 INFO 139730530932544] #quality_metric: host=algo-1, epoch=77, batch=0 train mse <loss>=0.3109450378417969\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:09 INFO 139730530932544] #quality_metric: host=algo-1, epoch=77, batch=0 train absolute_loss <loss>=0.3829012451171875\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:32:11.879] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 156, \"duration\": 2608, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:11 INFO 139730530932544] #quality_metric: host=algo-1, epoch=77, train rmse <loss>=0.5430297465467829\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:11 INFO 139730530932544] #quality_metric: host=algo-1, epoch=77, train mse <loss>=0.29488130563466336\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:11 INFO 139730530932544] #quality_metric: host=algo-1, epoch=77, train absolute_loss <loss>=0.33193147150009716\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079929.2685235, \"EndTime\": 1659079931.880754, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2611.6116046905518, \"count\": 1, \"min\": 2611.6116046905518, \"max\": 2611.6116046905518}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:11 INFO 139730530932544] #progress_metric: host=algo-1, completed 93.97590361445783 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079929.269102, \"EndTime\": 1659079931.8810287, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 77, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14866396.0, \"count\": 1, \"min\": 14866396, \"max\": 14866396}, \"Total Batches Seen\": {\"sum\": 14899.0, \"count\": 1, \"min\": 14899, \"max\": 14899}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 79.0, \"count\": 1, \"min\": 79, \"max\": 79}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:11 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72960.3031274236 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:11 INFO 139730530932544] #quality_metric: host=algo-1, epoch=78, batch=0 train rmse <loss>=0.5514427266820616\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:11 INFO 139730530932544] #quality_metric: host=algo-1, epoch=78, batch=0 train mse <loss>=0.30408908081054686\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:11 INFO 139730530932544] #quality_metric: host=algo-1, epoch=78, batch=0 train absolute_loss <loss>=0.37731802368164064\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:32:14.483] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 158, \"duration\": 2598, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:14 INFO 139730530932544] #quality_metric: host=algo-1, epoch=78, train rmse <loss>=0.537519688883722\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:14 INFO 139730530932544] #quality_metric: host=algo-1, epoch=78, train mse <loss>=0.28892741593765336\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:14 INFO 139730530932544] #quality_metric: host=algo-1, epoch=78, train absolute_loss <loss>=0.3275150067394316\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079931.8808498, \"EndTime\": 1659079934.4843314, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2602.933645248413, \"count\": 1, \"min\": 2602.933645248413, \"max\": 2602.933645248413}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:14 INFO 139730530932544] #progress_metric: host=algo-1, completed 95.18072289156626 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079931.8813686, \"EndTime\": 1659079934.4846036, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 78, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15056978.0, \"count\": 1, \"min\": 15056978, \"max\": 15056978}, \"Total Batches Seen\": {\"sum\": 15090.0, \"count\": 1, \"min\": 15090, \"max\": 15090}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 80.0, \"count\": 1, \"min\": 80, \"max\": 80}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:14 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=73205.32806613692 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:14 INFO 139730530932544] #quality_metric: host=algo-1, epoch=79, batch=0 train rmse <loss>=0.5453721817716692\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:14 INFO 139730530932544] #quality_metric: host=algo-1, epoch=79, batch=0 train mse <loss>=0.2974308166503906\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:14 INFO 139730530932544] #quality_metric: host=algo-1, epoch=79, batch=0 train absolute_loss <loss>=0.3718723754882812\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:32:17.084] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 160, \"duration\": 2597, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:17 INFO 139730530932544] #quality_metric: host=algo-1, epoch=79, train rmse <loss>=0.5321201987883613\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:17 INFO 139730530932544] #quality_metric: host=algo-1, epoch=79, train mse <loss>=0.2831519059585651\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:17 INFO 139730530932544] #quality_metric: host=algo-1, epoch=79, train absolute_loss <loss>=0.3232126953764112\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079934.4844182, \"EndTime\": 1659079937.086159, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2601.212739944458, \"count\": 1, \"min\": 2601.212739944458, \"max\": 2601.212739944458}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:17 INFO 139730530932544] #progress_metric: host=algo-1, completed 96.3855421686747 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079934.4849164, \"EndTime\": 1659079937.0866032, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 79, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15247560.0, \"count\": 1, \"min\": 15247560, \"max\": 15247560}, \"Total Batches Seen\": {\"sum\": 15281.0, \"count\": 1, \"min\": 15281, \"max\": 15281}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:17 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=73248.97125695804 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:17 INFO 139730530932544] #quality_metric: host=algo-1, epoch=80, batch=0 train rmse <loss>=0.5394100159277756\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:17 INFO 139730530932544] #quality_metric: host=algo-1, epoch=80, batch=0 train mse <loss>=0.29096316528320315\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:17 INFO 139730530932544] #quality_metric: host=algo-1, epoch=80, batch=0 train absolute_loss <loss>=0.3665609130859375\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:32:19.705] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 162, \"duration\": 2616, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:19 INFO 139730530932544] #quality_metric: host=algo-1, epoch=80, train rmse <loss>=0.5268288732751095\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:19 INFO 139730530932544] #quality_metric: host=algo-1, epoch=80, train mse <loss>=0.27754866171632137\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:19 INFO 139730530932544] #quality_metric: host=algo-1, epoch=80, train absolute_loss <loss>=0.31902254713767486\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079937.0862339, \"EndTime\": 1659079939.7064312, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2619.4517612457275, \"count\": 1, \"min\": 2619.4517612457275, \"max\": 2619.4517612457275}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:19 INFO 139730530932544] #progress_metric: host=algo-1, completed 97.59036144578313 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079937.0869462, \"EndTime\": 1659079939.7066813, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 80, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15438142.0, \"count\": 1, \"min\": 15438142, \"max\": 15438142}, \"Total Batches Seen\": {\"sum\": 15472.0, \"count\": 1, \"min\": 15472, \"max\": 15472}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 82.0, \"count\": 1, \"min\": 82, \"max\": 82}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:19 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72744.62708842158 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:19 INFO 139730530932544] #quality_metric: host=algo-1, epoch=81, batch=0 train rmse <loss>=0.5335532561501592\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:19 INFO 139730530932544] #quality_metric: host=algo-1, epoch=81, batch=0 train mse <loss>=0.2846790771484375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:19 INFO 139730530932544] #quality_metric: host=algo-1, epoch=81, batch=0 train absolute_loss <loss>=0.3613709411621094\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:32:22.326] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 164, \"duration\": 2617, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:22 INFO 139730530932544] #quality_metric: host=algo-1, epoch=81, train rmse <loss>=0.5216433814062221\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:22 INFO 139730530932544] #quality_metric: host=algo-1, epoch=81, train mse <loss>=0.27211181736491735\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:22 INFO 139730530932544] #quality_metric: host=algo-1, epoch=81, train absolute_loss <loss>=0.3149406365199863\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079939.706517, \"EndTime\": 1659079942.3269928, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2620.01371383667, \"count\": 1, \"min\": 2620.01371383667, \"max\": 2620.01371383667}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:22 INFO 139730530932544] #progress_metric: host=algo-1, completed 98.79518072289157 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079939.7069478, \"EndTime\": 1659079942.3272226, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 81, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15628724.0, \"count\": 1, \"min\": 15628724, \"max\": 15628724}, \"Total Batches Seen\": {\"sum\": 15663.0, \"count\": 1, \"min\": 15663, \"max\": 15663}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 83.0, \"count\": 1, \"min\": 83, \"max\": 83}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:22 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=72730.0659342819 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:22 INFO 139730530932544] #quality_metric: host=algo-1, epoch=82, batch=0 train rmse <loss>=0.5277992245962237\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:22 INFO 139730530932544] #quality_metric: host=algo-1, epoch=82, batch=0 train mse <loss>=0.278572021484375\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:22 INFO 139730530932544] #quality_metric: host=algo-1, epoch=82, batch=0 train absolute_loss <loss>=0.35629165649414063\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:32:24.897] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 166, \"duration\": 2567, \"num_examples\": 191, \"num_bytes\": 12900036}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:24 INFO 139730530932544] #quality_metric: host=algo-1, epoch=82, train rmse <loss>=0.5165615741109113\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:24 INFO 139730530932544] #quality_metric: host=algo-1, epoch=82, train mse <loss>=0.26683585984794256\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:24 INFO 139730530932544] #quality_metric: host=algo-1, epoch=82, train absolute_loss <loss>=0.310964068347871\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:24 INFO 139730530932544] #quality_metric: host=algo-1, train rmse <loss>=0.5165615741109113\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:24 INFO 139730530932544] #quality_metric: host=algo-1, train mse <loss>=0.26683585984794256\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:24 INFO 139730530932544] #quality_metric: host=algo-1, train absolute_loss <loss>=0.310964068347871\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079942.3270695, \"EndTime\": 1659079944.8990705, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2570.6028938293457, \"count\": 1, \"min\": 2570.6028938293457, \"max\": 2570.6028938293457}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:24 INFO 139730530932544] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079942.328433, \"EndTime\": 1659079944.8993707, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 82, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15819306.0, \"count\": 1, \"min\": 15819306, \"max\": 15819306}, \"Total Batches Seen\": {\"sum\": 15854.0, \"count\": 1, \"min\": 15854, \"max\": 15854}, \"Max Records Seen Between Resets\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 84.0, \"count\": 1, \"min\": 84, \"max\": 84}, \"Number of Records Since Last Reset\": {\"sum\": 190582.0, \"count\": 1, \"min\": 190582, \"max\": 190582}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:24 INFO 139730530932544] #throughput_metric: host=algo-1, train throughput=74124.88627104714 records/second\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:24 WARNING 139730530932544] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:24 INFO 139730530932544] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079944.8991644, \"EndTime\": 1659079944.949399, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 49.574851989746094, \"count\": 1, \"min\": 49.574851989746094, \"max\": 49.574851989746094}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:25 INFO 139730530932544] Saved checkpoint to \"/tmp/tmp6k4_nf_z/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:32:25.392] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 223861, \"num_examples\": 1, \"num_bytes\": 67668}\u001b[0m\n",
      "\u001b[34m[2022-07-29 07:32:27.896] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 2504, \"num_examples\": 48, \"num_bytes\": 3224812}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079945.3919852, \"EndTime\": 1659079947.897226, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 47646.0, \"count\": 1, \"min\": 47646, \"max\": 47646}, \"Total Batches Seen\": {\"sum\": 48.0, \"count\": 1, \"min\": 48, \"max\": 48}, \"Max Records Seen Between Resets\": {\"sum\": 47646.0, \"count\": 1, \"min\": 47646, \"max\": 47646}, \"Max Batches Seen Between Resets\": {\"sum\": 48.0, \"count\": 1, \"min\": 48, \"max\": 48}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 47646.0, \"count\": 1, \"min\": 47646, \"max\": 47646}, \"Number of Batches Since Last Reset\": {\"sum\": 48.0, \"count\": 1, \"min\": 48, \"max\": 48}}}\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:27 INFO 139730530932544] #test_score (algo-1) : ('rmse', 1.4468496730832734)\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:27 INFO 139730530932544] #test_score (algo-1) : ('mse', 2.093373976501175)\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:27 INFO 139730530932544] #test_score (algo-1) : ('absolute_loss', 1.3337657457534309)\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:27 INFO 139730530932544] #quality_metric: host=algo-1, test rmse <loss>=1.4468496730832734\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:27 INFO 139730530932544] #quality_metric: host=algo-1, test mse <loss>=2.093373976501175\u001b[0m\n",
      "\u001b[34m[07/29/2022 07:32:27 INFO 139730530932544] #quality_metric: host=algo-1, test absolute_loss <loss>=1.3337657457534309\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1659079944.9495952, \"EndTime\": 1659079947.8991332, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 30.645370483398438, \"count\": 1, \"min\": 30.645370483398438, \"max\": 30.645370483398438}, \"totaltime\": {\"sum\": 226421.63491249084, \"count\": 1, \"min\": 226421.63491249084, \"max\": 226421.63491249084}}}\u001b[0m\n",
      "\n",
      "2022-07-29 07:32:52 Uploading - Uploading generated training model\n",
      "2022-07-29 07:32:52 Completed - Training job completed\n",
      "Training seconds: 353\n",
      "Billable seconds: 353\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train':train_file_location, \n",
    "               'test':test_file_location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "import json\n",
    "\n",
    "class fm_json_serializer(JSONSerializer):\n",
    "    def serialize(self, data):\n",
    "        js = {\"instances\": []}\n",
    "        for row in data:\n",
    "            js[\"instances\"].append({\"features\": row.tolist()})\n",
    "        return json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bb373cb2baaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m predictor = estimator.deploy(initial_instance_count = 1,\n\u001b[0m\u001b[1;32m      2\u001b[0m                              \u001b[0minstance_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ml.m5.xlarge\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                              \u001b[0mendpoint_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                              \u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm_json_serializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                              \u001b[0mdeserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDeserializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'estimator' is not defined"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count = 1,\n",
    "                             instance_type = \"ml.m5.xlarge\",\n",
    "                             endpoint_name = job_name,\n",
    "                             serializer = fm_json_serializer(),\n",
    "                             deserializer = JSONDeserializer(),\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0009V1YR8</td>\n",
       "      <td>2869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0000YUXI0</td>\n",
       "      <td>2143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000142FVW</td>\n",
       "      <td>1558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00021DVCQ</td>\n",
       "      <td>1051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0002JKPA4</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16334</th>\n",
       "      <td>B0006Q05XU</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16335</th>\n",
       "      <td>B0006Q05NK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16336</th>\n",
       "      <td>B0006Q041S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16337</th>\n",
       "      <td>B0006Q03VE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16338</th>\n",
       "      <td>B0006TV9IC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16339 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ProductId  UserId\n",
       "0      B0009V1YR8    2869\n",
       "1      B0000YUXI0    2143\n",
       "2      B000142FVW    1558\n",
       "3      B00021DVCQ    1051\n",
       "4      B0002JKPA4    1046\n",
       "...           ...     ...\n",
       "16334  B0006Q05XU       1\n",
       "16335  B0006Q05NK       1\n",
       "16336  B0006Q041S       1\n",
       "16337  B0006Q03VE       1\n",
       "16338  B0006TV9IC       1\n",
       "\n",
       "[16339 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending = ratings.copy()\n",
    "trending = (trending.groupby([\"ProductId\"])\n",
    "            .nunique()[\"UserId\"]\n",
    "            .sort_values(ascending=False)\n",
    "            .reset_index()            \n",
    "           )            \n",
    "trending = trending.rename(columns={'customer_id': 'unique_customers'})\n",
    "trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-9f75955ba987>\", line 1, in <module>\n",
      "    result = predictor.predict(X.toarray())\n",
      "NameError: name 'predictor' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/opt/conda/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9f75955ba987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NameError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2102\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "result = predictor.predict(X.toarray())\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = ohe.inverse_transform(ohe_features)[:, 1]\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_recommended = np.take_along_axis(products, index_array, axis=0)[: -3 - 1 : -1]\n",
    "top_3_recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the array to dataframe.\n",
    "df_3 = pd.DataFrame(top_3_recommended, columns=[\"product_id\"])\n",
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9dbbcf45efe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
